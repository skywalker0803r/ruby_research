{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SFOPprediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gwQbv_YPWDTt",
        "v4lmrQEKWDUw"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/ruby_research/blob/main/SFOPprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTXRNj8PW-8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d8a157-382e-4c4d-be09-29ad58d6ea59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3MtssUy6CPq"
      },
      "source": [
        "#!pip install git+https://github.com/jonbarron/robust_loss_pytorch\n",
        "import robust_loss_pytorch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from copy import deepcopy"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ha0h4_WQWDSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f5a7b0-4efd-48b5-ecce-9a6b90072a8d"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import tensor\n",
        "from torch.nn import Linear,ReLU,Sigmoid,Tanh\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from math import sqrt\n",
        "import joblib\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import warnings;warnings.simplefilter('ignore')\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "root = '/gdrive/My Drive/for Ruby'\n",
        "excel_list=os.listdir(root)\n",
        "excel_list"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['淡水河流域.csv', '淡水河流域final_0429.ipynb', '驗證淡水河流域03_15.ipynb', '2.xlsx']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlDEZklNW89Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3232d0da-3e62-4e62-a5ca-bd7132276b7f"
      },
      "source": [
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BnkYQueWDSj"
      },
      "source": [
        "# some function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzVD6cnCWDSj"
      },
      "source": [
        "def mape(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def get_group_col(df,name):\n",
        "    condition = df.columns.str.contains(name)\n",
        "    return df.columns[condition].tolist()\n",
        "\n",
        "def split_data(df,x_col,y_col):\n",
        "  df = shuffle(df).astype('float32')\n",
        "  X,Y = df[x_col],df[y_col]\n",
        "  sp1 = int(len(df)*0.8)\n",
        "  sp2 = int(len(df)*0.9)\n",
        "  data = {}\n",
        "  data['X_train'],data['Y_train'] = X.iloc[:sp1,:],Y.iloc[:sp1,:]\n",
        "  data['X_vaild'],data['Y_vaild'] = X.iloc[sp1:sp2,:],Y.iloc[sp1:sp2,:]\n",
        "  data['X_test'],data['Y_test'] = X.iloc[sp2:,:],Y.iloc[sp2:,:]\n",
        "  return data\n",
        "\n",
        "def show_metrics(y_pred,y_real):\n",
        "  res = pd.DataFrame(index=y_pred.columns,columns=['R2','MSE','MAPE'])\n",
        "  for i in y_pred.columns:\n",
        "    res.loc[i,'R2'] = r2_score(y_real[i],y_pred[i])\n",
        "    res.loc[i,'MSE'] = mean_squared_error(y_real[i],y_pred[i])\n",
        "    res.loc[i,'MAPE'] = mape(y_real[i],y_pred[i])\n",
        "  res.loc['AVG'] = res.mean(axis=0)\n",
        "  return res\n",
        "\n",
        "def init_weights(m):\n",
        "  if hasattr(m,'weight'):\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "  if hasattr(m,'bias'):\n",
        "    m.bias.data.fill_(0)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFNtBmqeWDSm"
      },
      "source": [
        "# Part1：預測塔頂塔底組成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AtQ4T0aWDSn"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EFZLabUWDSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "5f25bb80-6096-403f-b9b1-0cba76196eb3"
      },
      "source": [
        "df = pd.read_excel(root+'/2.xlsx') #讀取excel檔\n",
        "df = df.drop(['Unnamed: 1', 'Unnamed: 2'], axis=1)\n",
        "df = df.drop(index=1)\n",
        "col_name = df.iloc[0,:]\n",
        "df.columns = col_name\n",
        "df = df.iloc[1:,:] \n",
        "df.index = df.iloc[:,0].values\n",
        "df = df.drop(df.columns[0],axis=1)\n",
        "print(df.shape)\n",
        "for i in df.columns:\n",
        "    df[i] = pd.to_numeric(df[i],errors='coerce')\n",
        "\n",
        "df['Condenser Duty'] = df['Condenser Duty'].apply(lambda x: x*-1)\n",
        "df.head()"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1458, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F.TEMP.MIXED</th>\n",
              "      <th>Feed Flow</th>\n",
              "      <th>F.FLOW.BENZENE</th>\n",
              "      <th>F.FLOW.TOLUENE</th>\n",
              "      <th>Total stage</th>\n",
              "      <th>Reflux ratio</th>\n",
              "      <th>D/F</th>\n",
              "      <th>Feed stage</th>\n",
              "      <th>Stage-2 Efficiencies</th>\n",
              "      <th>Stage-45 Efficiencies</th>\n",
              "      <th>Condenser Temperature</th>\n",
              "      <th>Condenser Duty</th>\n",
              "      <th>D stream BENZENE</th>\n",
              "      <th>D stream TOLUENE</th>\n",
              "      <th>Reboiler Temp</th>\n",
              "      <th>Reboiler Duty</th>\n",
              "      <th>W stream BENZENE</th>\n",
              "      <th>W stream TOLUENE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Case 1</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>40</td>\n",
              "      <td>60</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.961772</td>\n",
              "      <td>5712.749075</td>\n",
              "      <td>0.991645</td>\n",
              "      <td>0.008355</td>\n",
              "      <td>112.480976</td>\n",
              "      <td>5503.283448</td>\n",
              "      <td>0.146149</td>\n",
              "      <td>0.853851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 2</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.990896</td>\n",
              "      <td>5809.514269</td>\n",
              "      <td>0.989946</td>\n",
              "      <td>0.010054</td>\n",
              "      <td>106.774195</td>\n",
              "      <td>3042.561970</td>\n",
              "      <td>0.284634</td>\n",
              "      <td>0.715366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 3</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>83.029809</td>\n",
              "      <td>5906.674859</td>\n",
              "      <td>0.987682</td>\n",
              "      <td>0.012318</td>\n",
              "      <td>101.915000</td>\n",
              "      <td>593.089652</td>\n",
              "      <td>0.425427</td>\n",
              "      <td>0.574573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 4</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>40</td>\n",
              "      <td>60</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>19</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.845927</td>\n",
              "      <td>5708.665107</td>\n",
              "      <td>0.998416</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>112.594861</td>\n",
              "      <td>5500.205696</td>\n",
              "      <td>0.143621</td>\n",
              "      <td>0.856379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 5</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>19</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.851761</td>\n",
              "      <td>5804.515753</td>\n",
              "      <td>0.998074</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>106.894313</td>\n",
              "      <td>3038.549282</td>\n",
              "      <td>0.281451</td>\n",
              "      <td>0.718549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0       F.TEMP.MIXED  Feed Flow  ...  W stream BENZENE  W stream TOLUENE\n",
              "Case 1           103         50  ...          0.146149          0.853851\n",
              "Case 2           103         50  ...          0.284634          0.715366\n",
              "Case 3           103         50  ...          0.425427          0.574573\n",
              "Case 4           103         50  ...          0.143621          0.856379\n",
              "Case 5           103         50  ...          0.281451          0.718549\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvKtkQ773Vu3"
      },
      "source": [
        "class part(object):\n",
        "  def __init__(self,df,x_col,y_col,hidden_size=256,lr=0.01,max_epochs=500,robust_loss=False):\n",
        "    \n",
        "    # config\n",
        "    self.robust_loss = robust_loss\n",
        "    self.x_col = x_col\n",
        "    self.y_col = y_col\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lr = lr\n",
        "    self.max_epochs = max_epochs\n",
        "    self.ss_x = MinMaxScaler().fit(df[x_col])\n",
        "    self.ss_y = MinMaxScaler().fit(df[y_col])\n",
        "    \n",
        "    # model\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(len(self.x_col),self.hidden_size),nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size,self.hidden_size),nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size,len(self.y_col)),nn.Sigmoid(),\n",
        "                  ).apply(init_weights)\n",
        "    \n",
        "    # loss_function\n",
        "    if self.robust_loss == True:\n",
        "      adaptive = robust_loss_pytorch.adaptive.AdaptiveLossFunction(\n",
        "          num_dims = len(self.y_col),\n",
        "          float_dtype = np.float32,\n",
        "          device = 'cpu')\n",
        "      params = list(self.net.parameters())+list(adaptive.parameters())\n",
        "      self.loss_fn = lambda y_i,y:torch.mean(adaptive.lossfun((y_i - y)))\n",
        "    else:\n",
        "      params = list(self.net.parameters())\n",
        "      self.loss_fn = lambda y_i,y:torch.mean((y_i-y)**2)\n",
        "    \n",
        "    # optimizer\n",
        "    self.optimizer = torch.optim.Adam(params,lr=self.lr)\n",
        "    \n",
        "    # dataset\n",
        "    self.data = split_data(df,self.x_col,self.y_col)\n",
        "    \n",
        "    self.train_data = TensorDataset(\n",
        "        torch.FloatTensor(self.ss_x.transform(self.data['X_train'])),\n",
        "        torch.FloatTensor(self.ss_y.transform(self.data['Y_train'])),\n",
        "        )\n",
        "    self.train_iter = DataLoader(self.train_data,batch_size=64)\n",
        "    \n",
        "    self.vaild_data = TensorDataset(\n",
        "        torch.FloatTensor(self.ss_x.transform(self.data['X_vaild'])),\n",
        "        torch.FloatTensor(self.ss_y.transform(self.data['Y_vaild'])),\n",
        "        )\n",
        "    self.vaild_iter = DataLoader(self.vaild_data,batch_size=64)\n",
        "\n",
        "  def train_step(self):\n",
        "    self.net.train()\n",
        "    total_loss = 0\n",
        "    for t,(x,y) in enumerate(self.train_iter):\n",
        "      y_hat = self.net(x)\n",
        "      loss = self.loss_fn(y_hat,y)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      self.optimizer.zero_grad()\n",
        "      total_loss += loss.item()\n",
        "    return total_loss/t\n",
        "  \n",
        "  def valid_step(self):\n",
        "    self.net.eval()\n",
        "    total_loss = 0\n",
        "    for t,(x,y) in enumerate(self.vaild_iter):\n",
        "      y_hat = self.net(x)\n",
        "      loss = self.loss_fn(y_hat,y)\n",
        "      total_loss += loss.item()\n",
        "    return total_loss/t\n",
        "\n",
        "  \n",
        "  def train(self):   \n",
        "    history = {\n",
        "        'train_loss':[],\n",
        "        'valid_loss':[]\n",
        "        }\n",
        "    current_loss = np.inf\n",
        "    best_model = None\n",
        "    \n",
        "    for i in range(self.max_epochs):\n",
        "      history['train_loss'].append(self.train_step())\n",
        "      history['valid_loss'].append(self.valid_step())\n",
        "      print(\"epoch:{} train_loss:{} valid_loss:{}\".format(\n",
        "          i,\n",
        "          history['train_loss'][-1],\n",
        "          history['valid_loss'][-1]))\n",
        "      \n",
        "      if history['valid_loss'][-1] <= current_loss:\n",
        "        best_model = deepcopy(self.net.eval())\n",
        "        current_loss = history['valid_loss'][-1]\n",
        "        print('save best model')\n",
        "    \n",
        "    self.net = best_model\n",
        "    return best_model\n",
        "\n",
        "  def test(self):\n",
        "    predict = self.net(torch.FloatTensor(self.ss_x.transform(self.data['X_test'])))\n",
        "    predict = self.ss_y.inverse_transform(predict.detach().numpy())\n",
        "    predict = pd.DataFrame(predict,columns=self.y_col)\n",
        "    res = show_metrics(predict,self.data['Y_test'])\n",
        "    return res"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBMLJH3e8YNC"
      },
      "source": [
        "# PART1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2A5AzvG9i-7",
        "outputId": "2f4aed54-11fd-4ae3-856e-50100337e873"
      },
      "source": [
        "part1 = part(df,df.columns[:10],df.columns[[12,13,16,17]])\n",
        "part1.train()"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.04849706036556098 valid_loss:0.012787146028131247\n",
            "save best model\n",
            "epoch:1 train_loss:0.008403990120213065 valid_loss:0.008509476610925049\n",
            "save best model\n",
            "epoch:2 train_loss:0.007122678902103669 valid_loss:0.00478197552729398\n",
            "save best model\n",
            "epoch:3 train_loss:0.008374484411130348 valid_loss:0.004135293536819518\n",
            "save best model\n",
            "epoch:4 train_loss:0.007135403420155247 valid_loss:0.005118321627378464\n",
            "epoch:5 train_loss:0.004087934522734334 valid_loss:0.0026826912944670767\n",
            "save best model\n",
            "epoch:6 train_loss:0.0033349245527966153 valid_loss:0.0023121022968553007\n",
            "save best model\n",
            "epoch:7 train_loss:0.0030016003972074636 valid_loss:0.0021124045306351036\n",
            "save best model\n",
            "epoch:8 train_loss:0.00290153186102139 valid_loss:0.002183698510634713\n",
            "epoch:9 train_loss:0.002824062402295466 valid_loss:0.002160378237022087\n",
            "epoch:10 train_loss:0.002747308557445649 valid_loss:0.0021355104399845004\n",
            "epoch:11 train_loss:0.002669029859437918 valid_loss:0.0021063952444819734\n",
            "save best model\n",
            "epoch:12 train_loss:0.00264892586629786 valid_loss:0.0021208592515904456\n",
            "epoch:13 train_loss:0.0026424385384113216 valid_loss:0.002056230281596072\n",
            "save best model\n",
            "epoch:14 train_loss:0.002643236636585142 valid_loss:0.0020326748926891014\n",
            "save best model\n",
            "epoch:15 train_loss:0.002710322846218737 valid_loss:0.0023111055634217337\n",
            "epoch:16 train_loss:0.002643032098906891 valid_loss:0.0021934452233836055\n",
            "epoch:17 train_loss:0.0026060308369374573 valid_loss:0.002176577487261966\n",
            "epoch:18 train_loss:0.00253973117772451 valid_loss:0.00201792165171355\n",
            "save best model\n",
            "epoch:19 train_loss:0.00247192260859366 valid_loss:0.001971367441001348\n",
            "save best model\n",
            "epoch:20 train_loss:0.002459510730760586 valid_loss:0.0019043471329496242\n",
            "save best model\n",
            "epoch:21 train_loss:0.0024443963355022585 valid_loss:0.0018682200825423934\n",
            "save best model\n",
            "epoch:22 train_loss:0.0024470789455032596 valid_loss:0.0018983051704708487\n",
            "epoch:23 train_loss:0.002472012994177122 valid_loss:0.0018605815712362528\n",
            "save best model\n",
            "epoch:24 train_loss:0.0024970227661671946 valid_loss:0.0018563516059657559\n",
            "save best model\n",
            "epoch:25 train_loss:0.0025656221615564492 valid_loss:0.001920943715958856\n",
            "epoch:26 train_loss:0.0026898684292165046 valid_loss:0.0020780804625246674\n",
            "epoch:27 train_loss:0.0026307781566477693 valid_loss:0.0020733491546707228\n",
            "epoch:28 train_loss:0.002560669403060779 valid_loss:0.0019490698614390567\n",
            "epoch:29 train_loss:0.0021997758416950498 valid_loss:0.0017801642534323037\n",
            "save best model\n",
            "epoch:30 train_loss:0.0012656315084313974 valid_loss:0.0007412192935589701\n",
            "save best model\n",
            "epoch:31 train_loss:0.0005117178120094144 valid_loss:0.0006130651745479554\n",
            "save best model\n",
            "epoch:32 train_loss:0.0003126251071484552 valid_loss:0.0003059650262002833\n",
            "save best model\n",
            "epoch:33 train_loss:0.00019434512533836014 valid_loss:0.0002717255993047729\n",
            "save best model\n",
            "epoch:34 train_loss:0.00015892779204781013 valid_loss:0.00026418681954964995\n",
            "save best model\n",
            "epoch:35 train_loss:0.0001421034350844113 valid_loss:0.0002431583488942124\n",
            "save best model\n",
            "epoch:36 train_loss:0.00013321482411912357 valid_loss:0.00023736836010357365\n",
            "save best model\n",
            "epoch:37 train_loss:0.0001276863893306452 valid_loss:0.00023015104306978174\n",
            "save best model\n",
            "epoch:38 train_loss:0.0001230114903592039 valid_loss:0.00022779725986765698\n",
            "save best model\n",
            "epoch:39 train_loss:0.00011980732334551349 valid_loss:0.00022612446991843171\n",
            "save best model\n",
            "epoch:40 train_loss:0.00011746217589663704 valid_loss:0.00022517557590617798\n",
            "save best model\n",
            "epoch:41 train_loss:0.00011567259495374553 valid_loss:0.00022543297382071614\n",
            "epoch:42 train_loss:0.00011431638621514948 valid_loss:0.00022471375996246934\n",
            "save best model\n",
            "epoch:43 train_loss:0.00011306605069370966 valid_loss:0.00022409812663681805\n",
            "save best model\n",
            "epoch:44 train_loss:0.00011201611368960585 valid_loss:0.000225906496780226\n",
            "epoch:45 train_loss:0.0001114991368417072 valid_loss:0.00022655530119664036\n",
            "epoch:46 train_loss:0.00011109954059267895 valid_loss:0.00023175302703748457\n",
            "epoch:47 train_loss:0.00011246184112678748 valid_loss:0.00023180133575806394\n",
            "epoch:48 train_loss:0.0001128216898299191 valid_loss:0.00023933346164994873\n",
            "epoch:49 train_loss:0.00011574659432274832 valid_loss:0.00023995640731300227\n",
            "epoch:50 train_loss:0.00011573669169390794 valid_loss:0.0002552751357143279\n",
            "epoch:51 train_loss:0.00012283774978843413 valid_loss:0.00025958689366234466\n",
            "epoch:52 train_loss:0.00011978934682904057 valid_loss:0.00027090472576674074\n",
            "epoch:53 train_loss:0.00012522883515783987 valid_loss:0.00027518295974005014\n",
            "epoch:54 train_loss:0.0001244348380977398 valid_loss:0.0002817963577399496\n",
            "epoch:55 train_loss:0.00013018054616825085 valid_loss:0.00027875851446879096\n",
            "epoch:56 train_loss:0.00013076701614206994 valid_loss:0.0002655452371982392\n",
            "epoch:57 train_loss:0.00014007608388055814 valid_loss:0.00029707697831327096\n",
            "epoch:58 train_loss:0.00013806960714646266 valid_loss:0.00022385070769814774\n",
            "save best model\n",
            "epoch:59 train_loss:0.00015296193810677828 valid_loss:0.0004884437876171432\n",
            "epoch:60 train_loss:0.00017265866740166934 valid_loss:0.0003761912594200112\n",
            "epoch:61 train_loss:0.00018303272382682835 valid_loss:0.0006193822919158265\n",
            "epoch:62 train_loss:0.0001781835219137267 valid_loss:0.00022987102056504227\n",
            "epoch:63 train_loss:0.0001442587781639304 valid_loss:0.0002656073156686034\n",
            "epoch:64 train_loss:0.000137166627205766 valid_loss:0.00027350816162652336\n",
            "epoch:65 train_loss:0.00014329484353462854 valid_loss:0.00028332781948847696\n",
            "epoch:66 train_loss:0.00014871365500665788 valid_loss:0.000258158386714058\n",
            "epoch:67 train_loss:0.0001620034492791294 valid_loss:0.00024315056725754403\n",
            "epoch:68 train_loss:0.00016940701910546826 valid_loss:0.0003989085671491921\n",
            "epoch:69 train_loss:0.0002375094255613577 valid_loss:0.00018857308532460593\n",
            "save best model\n",
            "epoch:70 train_loss:0.00019517336740035616 valid_loss:0.00019178576258127578\n",
            "epoch:71 train_loss:9.856727623021773e-05 valid_loss:0.00015729745791759342\n",
            "save best model\n",
            "epoch:72 train_loss:7.436685933094446e-05 valid_loss:0.0001497686043876456\n",
            "save best model\n",
            "epoch:73 train_loss:6.867749910573669e-05 valid_loss:0.00012126141882617958\n",
            "save best model\n",
            "epoch:74 train_loss:6.799331660861046e-05 valid_loss:0.00010739725075836759\n",
            "save best model\n",
            "epoch:75 train_loss:6.698105158243884e-05 valid_loss:0.00012467341912270058\n",
            "epoch:76 train_loss:6.960659498468481e-05 valid_loss:0.00011015049494744744\n",
            "epoch:77 train_loss:7.599738869935714e-05 valid_loss:0.00010045079761766829\n",
            "save best model\n",
            "epoch:78 train_loss:6.0879219795929705e-05 valid_loss:8.800566865829751e-05\n",
            "save best model\n",
            "epoch:79 train_loss:5.120923899287138e-05 valid_loss:7.747335621388629e-05\n",
            "save best model\n",
            "epoch:80 train_loss:4.5854383491435634e-05 valid_loss:7.25659920135513e-05\n",
            "save best model\n",
            "epoch:81 train_loss:4.3333216328594266e-05 valid_loss:7.977260793268215e-05\n",
            "epoch:82 train_loss:4.418478364540432e-05 valid_loss:7.196973092504777e-05\n",
            "save best model\n",
            "epoch:83 train_loss:4.4916551663239566e-05 valid_loss:6.314704296528362e-05\n",
            "save best model\n",
            "epoch:84 train_loss:4.131013555605831e-05 valid_loss:6.347290400299244e-05\n",
            "epoch:85 train_loss:3.8987148172964226e-05 valid_loss:7.370106868620496e-05\n",
            "epoch:86 train_loss:3.851766081829232e-05 valid_loss:7.155295315897092e-05\n",
            "epoch:87 train_loss:3.600041779666046e-05 valid_loss:5.423537368187681e-05\n",
            "save best model\n",
            "epoch:88 train_loss:3.48815034511871e-05 valid_loss:5.383402276493143e-05\n",
            "save best model\n",
            "epoch:89 train_loss:3.0403105256482377e-05 valid_loss:6.057925111235818e-05\n",
            "epoch:90 train_loss:2.6494029498280725e-05 valid_loss:5.401112684921827e-05\n",
            "epoch:91 train_loss:2.5123773715070758e-05 valid_loss:5.599922951660119e-05\n",
            "epoch:92 train_loss:2.7797446162165012e-05 valid_loss:7.066250873322133e-05\n",
            "epoch:93 train_loss:3.443201760294162e-05 valid_loss:8.49725583975669e-05\n",
            "epoch:94 train_loss:4.3814479189071186e-05 valid_loss:0.00017601176659809425\n",
            "epoch:95 train_loss:7.006265034053488e-05 valid_loss:0.0002901678453781642\n",
            "epoch:96 train_loss:9.03099302781306e-05 valid_loss:6.922926331753843e-05\n",
            "epoch:97 train_loss:7.524704597017262e-05 valid_loss:0.0002548664851929061\n",
            "epoch:98 train_loss:7.630621045488321e-05 valid_loss:8.227445141528733e-05\n",
            "epoch:99 train_loss:3.8847194193496965e-05 valid_loss:5.494213473866694e-05\n",
            "epoch:100 train_loss:2.9374188418134712e-05 valid_loss:6.4407346144435e-05\n",
            "epoch:101 train_loss:2.613970473753903e-05 valid_loss:8.120305938064121e-05\n",
            "epoch:102 train_loss:3.1293265919885016e-05 valid_loss:7.120342706912197e-05\n",
            "epoch:103 train_loss:3.0872139581737836e-05 valid_loss:7.996615750016645e-05\n",
            "epoch:104 train_loss:3.3468224753758274e-05 valid_loss:6.542998016811907e-05\n",
            "epoch:105 train_loss:3.785257048447319e-05 valid_loss:8.587039883423131e-05\n",
            "epoch:106 train_loss:3.484565271113146e-05 valid_loss:6.447243322327267e-05\n",
            "epoch:107 train_loss:3.3277862308346405e-05 valid_loss:6.345192014123313e-05\n",
            "epoch:108 train_loss:2.8995001887071543e-05 valid_loss:5.0285522775084246e-05\n",
            "save best model\n",
            "epoch:109 train_loss:2.9741192646623757e-05 valid_loss:7.105886834324338e-05\n",
            "epoch:110 train_loss:2.75339974046397e-05 valid_loss:6.277815009525511e-05\n",
            "epoch:111 train_loss:3.392653530277635e-05 valid_loss:5.272911857900908e-05\n",
            "epoch:112 train_loss:2.7238310142113027e-05 valid_loss:4.315007845434593e-05\n",
            "save best model\n",
            "epoch:113 train_loss:3.155259663698315e-05 valid_loss:5.330121803126531e-05\n",
            "epoch:114 train_loss:2.553531862758973e-05 valid_loss:7.246214772749227e-05\n",
            "epoch:115 train_loss:3.216783731356069e-05 valid_loss:5.625477024295833e-05\n",
            "epoch:116 train_loss:2.474310061491754e-05 valid_loss:5.605803744401783e-05\n",
            "epoch:117 train_loss:3.325683130444506e-05 valid_loss:4.266537962394068e-05\n",
            "save best model\n",
            "epoch:118 train_loss:2.6800941062295653e-05 valid_loss:3.3354473089275416e-05\n",
            "save best model\n",
            "epoch:119 train_loss:3.417613359286204e-05 valid_loss:3.5273286812298466e-05\n",
            "epoch:120 train_loss:2.6383094235724355e-05 valid_loss:6.981424667173997e-05\n",
            "epoch:121 train_loss:3.568747570170672e-05 valid_loss:0.00011107154205092229\n",
            "epoch:122 train_loss:3.453464074078106e-05 valid_loss:0.0001531136076664552\n",
            "epoch:123 train_loss:4.747677192224526e-05 valid_loss:7.014018410700373e-05\n",
            "epoch:124 train_loss:4.9609848348255684e-05 valid_loss:9.631932516640518e-05\n",
            "epoch:125 train_loss:7.437466350287043e-05 valid_loss:7.156374431360746e-05\n",
            "epoch:126 train_loss:4.11240095369673e-05 valid_loss:0.000251390112680383\n",
            "epoch:127 train_loss:6.626901474899366e-05 valid_loss:7.802782965882216e-05\n",
            "epoch:128 train_loss:6.37586489473405e-05 valid_loss:0.00023239799338625744\n",
            "epoch:129 train_loss:9.168309995604634e-05 valid_loss:0.00022567120322491974\n",
            "epoch:130 train_loss:0.00013707320775008865 valid_loss:0.00024545355699956417\n",
            "epoch:131 train_loss:0.00015832293805336425 valid_loss:0.0001352787876385264\n",
            "epoch:132 train_loss:0.00011449429803178646 valid_loss:0.0001401472582074348\n",
            "epoch:133 train_loss:6.177556861075573e-05 valid_loss:0.0001321614472544752\n",
            "epoch:134 train_loss:5.214311800551109e-05 valid_loss:0.00016401354878325947\n",
            "epoch:135 train_loss:7.551167386231504e-05 valid_loss:0.00023913603945402429\n",
            "epoch:136 train_loss:0.00010613238100631861 valid_loss:0.00025049568284885027\n",
            "epoch:137 train_loss:0.00010594195524997001 valid_loss:0.00020562115241773427\n",
            "epoch:138 train_loss:0.00012599177433811646 valid_loss:0.00013165067502995953\n",
            "epoch:139 train_loss:8.361259885229326e-05 valid_loss:0.0001016625919874059\n",
            "epoch:140 train_loss:5.7691469111078833e-05 valid_loss:0.00014385041868081316\n",
            "epoch:141 train_loss:4.380197636540591e-05 valid_loss:6.270510766626103e-05\n",
            "epoch:142 train_loss:3.930549468754584e-05 valid_loss:3.484399985609343e-05\n",
            "epoch:143 train_loss:3.751022227839308e-05 valid_loss:6.485656558652408e-05\n",
            "epoch:144 train_loss:4.834871399200185e-05 valid_loss:5.7977902542916127e-05\n",
            "epoch:145 train_loss:5.004216462920239e-05 valid_loss:5.87434242333984e-05\n",
            "epoch:146 train_loss:5.2426199545152485e-05 valid_loss:5.5468404752900824e-05\n",
            "epoch:147 train_loss:4.161159530566591e-05 valid_loss:4.32666129199788e-05\n",
            "epoch:148 train_loss:3.326408068460296e-05 valid_loss:4.923596861772239e-05\n",
            "epoch:149 train_loss:2.6122657901497507e-05 valid_loss:5.4626045312033966e-05\n",
            "epoch:150 train_loss:2.2501498026233297e-05 valid_loss:5.228822737990413e-05\n",
            "epoch:151 train_loss:2.0808006865991047e-05 valid_loss:4.951245773554547e-05\n",
            "epoch:152 train_loss:2.0773569025954606e-05 valid_loss:4.5507835238822736e-05\n",
            "epoch:153 train_loss:2.169542348282347e-05 valid_loss:4.8358880121668335e-05\n",
            "epoch:154 train_loss:2.1752359771198826e-05 valid_loss:4.66986730316421e-05\n",
            "epoch:155 train_loss:2.157266756815564e-05 valid_loss:4.509597692958778e-05\n",
            "epoch:156 train_loss:2.111574316485429e-05 valid_loss:3.8999000025796704e-05\n",
            "epoch:157 train_loss:2.1147244675982318e-05 valid_loss:3.4629068977665156e-05\n",
            "epoch:158 train_loss:1.9142291547622233e-05 valid_loss:2.678211785678286e-05\n",
            "save best model\n",
            "epoch:159 train_loss:1.657224551207845e-05 valid_loss:2.6065315068990458e-05\n",
            "save best model\n",
            "epoch:160 train_loss:1.5065092712676334e-05 valid_loss:3.2662900594004896e-05\n",
            "epoch:161 train_loss:1.55432496487467e-05 valid_loss:4.964799154549837e-05\n",
            "epoch:162 train_loss:1.9219238007887423e-05 valid_loss:7.409142926917411e-05\n",
            "epoch:163 train_loss:2.4786422424464643e-05 valid_loss:8.877844993548933e-05\n",
            "epoch:164 train_loss:2.9598472742185953e-05 valid_loss:7.950662075018045e-05\n",
            "epoch:165 train_loss:2.9662679985954634e-05 valid_loss:6.791773375880439e-05\n",
            "epoch:166 train_loss:2.8065176088097764e-05 valid_loss:4.8945888920570724e-05\n",
            "epoch:167 train_loss:2.506490464939917e-05 valid_loss:4.868022824666696e-05\n",
            "epoch:168 train_loss:2.4981500195685334e-05 valid_loss:4.7816905862418935e-05\n",
            "epoch:169 train_loss:2.42533194775913e-05 valid_loss:4.1817516830633394e-05\n",
            "epoch:170 train_loss:2.2031386379239848e-05 valid_loss:5.4073379942565225e-05\n",
            "epoch:171 train_loss:2.128833453854087e-05 valid_loss:5.159676948096603e-05\n",
            "epoch:172 train_loss:1.8951962324030723e-05 valid_loss:4.0925812299974496e-05\n",
            "epoch:173 train_loss:1.708214762806569e-05 valid_loss:3.773083381020115e-05\n",
            "epoch:174 train_loss:1.8784996680349446e-05 valid_loss:4.872740464634262e-05\n",
            "epoch:175 train_loss:1.951331048783484e-05 valid_loss:5.363174295780482e-05\n",
            "epoch:176 train_loss:2.176139251888445e-05 valid_loss:6.648120051977457e-05\n",
            "epoch:177 train_loss:2.2732118244069472e-05 valid_loss:7.625230682606343e-05\n",
            "epoch:178 train_loss:2.3528288693341892e-05 valid_loss:7.018342694209423e-05\n",
            "epoch:179 train_loss:2.1736075521200997e-05 valid_loss:7.897997966210824e-05\n",
            "epoch:180 train_loss:2.3850094673131633e-05 valid_loss:7.374196684395429e-05\n",
            "epoch:181 train_loss:2.0839286359356873e-05 valid_loss:7.378089685516898e-05\n",
            "epoch:182 train_loss:2.1219918911204633e-05 valid_loss:5.612504628516035e-05\n",
            "epoch:183 train_loss:1.9197773831870614e-05 valid_loss:6.0751757700927556e-05\n",
            "epoch:184 train_loss:2.043821698154918e-05 valid_loss:5.045909074397059e-05\n",
            "epoch:185 train_loss:2.0970736538098816e-05 valid_loss:6.472925815614872e-05\n",
            "epoch:186 train_loss:2.949425884758562e-05 valid_loss:6.893416775710648e-05\n",
            "epoch:187 train_loss:2.603502212473864e-05 valid_loss:5.647089892590884e-05\n",
            "epoch:188 train_loss:3.588247929858173e-05 valid_loss:6.122792365204077e-05\n",
            "epoch:189 train_loss:3.1034781740244296e-05 valid_loss:4.145084949414013e-05\n",
            "epoch:190 train_loss:1.9179039605256145e-05 valid_loss:3.502379786368692e-05\n",
            "epoch:191 train_loss:1.5694856655399133e-05 valid_loss:5.48959978914354e-05\n",
            "epoch:192 train_loss:1.9645856557164938e-05 valid_loss:5.213163331063697e-05\n",
            "epoch:193 train_loss:1.953291307977957e-05 valid_loss:7.510308205382898e-05\n",
            "epoch:194 train_loss:2.432159534590836e-05 valid_loss:9.642237091611605e-05\n",
            "epoch:195 train_loss:3.337337314709051e-05 valid_loss:0.00013769957513432018\n",
            "epoch:196 train_loss:4.651982994295799e-05 valid_loss:0.0001750528535922058\n",
            "epoch:197 train_loss:6.917399342556665e-05 valid_loss:0.00020642211893573403\n",
            "epoch:198 train_loss:8.577847458784365e-05 valid_loss:6.371264589688508e-05\n",
            "epoch:199 train_loss:7.508911029516539e-05 valid_loss:0.00013621518155559897\n",
            "epoch:200 train_loss:5.9344866207943094e-05 valid_loss:5.8540303143672645e-05\n",
            "epoch:201 train_loss:2.921350803969997e-05 valid_loss:3.225263435524539e-05\n",
            "epoch:202 train_loss:1.981570070104984e-05 valid_loss:6.151853904157178e-05\n",
            "epoch:203 train_loss:2.0252579815860372e-05 valid_loss:1.462969885324128e-05\n",
            "save best model\n",
            "epoch:204 train_loss:2.9308547002276304e-05 valid_loss:9.450099787500221e-05\n",
            "epoch:205 train_loss:3.59741012895635e-05 valid_loss:3.990443019574741e-05\n",
            "epoch:206 train_loss:1.6661302045880195e-05 valid_loss:4.072790943610016e-05\n",
            "epoch:207 train_loss:1.6221667364233224e-05 valid_loss:2.5349775114591466e-05\n",
            "epoch:208 train_loss:1.4735217544310015e-05 valid_loss:4.192164487903938e-05\n",
            "epoch:209 train_loss:2.015738538021752e-05 valid_loss:3.1368066629511304e-05\n",
            "epoch:210 train_loss:1.6522117625249342e-05 valid_loss:3.04959044115094e-05\n",
            "epoch:211 train_loss:1.3546346306409558e-05 valid_loss:1.550243450765265e-05\n",
            "epoch:212 train_loss:1.062205607619641e-05 valid_loss:3.959330842917552e-05\n",
            "epoch:213 train_loss:1.1963102375981785e-05 valid_loss:2.14732544918661e-05\n",
            "epoch:214 train_loss:9.835374814631197e-06 valid_loss:3.128710068267537e-05\n",
            "epoch:215 train_loss:9.805278599136122e-06 valid_loss:2.4439063508907566e-05\n",
            "epoch:216 train_loss:8.774376409645709e-06 valid_loss:3.332261258037761e-05\n",
            "epoch:217 train_loss:9.011965024304422e-06 valid_loss:3.067113584620529e-05\n",
            "epoch:218 train_loss:8.777845879295557e-06 valid_loss:3.667116197902942e-05\n",
            "epoch:219 train_loss:9.348319685563587e-06 valid_loss:3.6453681786952075e-05\n",
            "epoch:220 train_loss:1.0482487596163992e-05 valid_loss:4.2548097553662956e-05\n",
            "epoch:221 train_loss:1.2291544307016819e-05 valid_loss:5.201512249186635e-05\n",
            "epoch:222 train_loss:1.4909996252754354e-05 valid_loss:6.703945928165922e-05\n",
            "epoch:223 train_loss:1.8025055977785894e-05 valid_loss:6.726636820530985e-05\n",
            "epoch:224 train_loss:2.001139134538082e-05 valid_loss:4.5442695409292355e-05\n",
            "epoch:225 train_loss:1.7855659355821747e-05 valid_loss:4.87146198793198e-05\n",
            "epoch:226 train_loss:2.2648677360040085e-05 valid_loss:9.083253098651767e-05\n",
            "epoch:227 train_loss:3.53419598266353e-05 valid_loss:8.643659566587303e-05\n",
            "epoch:228 train_loss:2.799578088444024e-05 valid_loss:3.542424201441463e-05\n",
            "epoch:229 train_loss:2.1185665900702588e-05 valid_loss:5.632047395920381e-05\n",
            "epoch:230 train_loss:1.6642881392827905e-05 valid_loss:3.278103940829169e-05\n",
            "epoch:231 train_loss:1.1351436973604399e-05 valid_loss:4.557356623990927e-05\n",
            "epoch:232 train_loss:1.3217573445621787e-05 valid_loss:4.40361491200747e-05\n",
            "epoch:233 train_loss:1.4149576044373032e-05 valid_loss:3.143467711197445e-05\n",
            "epoch:234 train_loss:1.2197472945748208e-05 valid_loss:3.261906113039004e-05\n",
            "epoch:235 train_loss:1.0162258654923386e-05 valid_loss:2.8126512916060165e-05\n",
            "epoch:236 train_loss:8.715664560238818e-06 valid_loss:3.275643666711403e-05\n",
            "epoch:237 train_loss:9.429522631560556e-06 valid_loss:4.0851747144188266e-05\n",
            "epoch:238 train_loss:1.1877511294894955e-05 valid_loss:4.129535864194622e-05\n",
            "epoch:239 train_loss:1.3263812181523665e-05 valid_loss:3.228589957871009e-05\n",
            "epoch:240 train_loss:1.2261949147311194e-05 valid_loss:2.6144344701606315e-05\n",
            "epoch:241 train_loss:1.0933907383837828e-05 valid_loss:3.149158601445379e-05\n",
            "epoch:242 train_loss:1.0510425441781183e-05 valid_loss:3.321625536045758e-05\n",
            "epoch:243 train_loss:1.0061175241086554e-05 valid_loss:2.9562012059614062e-05\n",
            "epoch:244 train_loss:9.894402460809539e-06 valid_loss:3.342334503031452e-05\n",
            "epoch:245 train_loss:1.3534559356129546e-05 valid_loss:5.728669566451572e-05\n",
            "epoch:246 train_loss:1.9003705549241407e-05 valid_loss:5.0041066970152315e-05\n",
            "epoch:247 train_loss:1.979847163763932e-05 valid_loss:3.044496497750515e-05\n",
            "epoch:248 train_loss:1.5521912423032012e-05 valid_loss:3.706606003106572e-05\n",
            "epoch:249 train_loss:1.2655076640536814e-05 valid_loss:1.9817287011392182e-05\n",
            "epoch:250 train_loss:1.3294284283599862e-05 valid_loss:3.228787591069704e-05\n",
            "epoch:251 train_loss:1.346618341813155e-05 valid_loss:2.562060535638011e-05\n",
            "epoch:252 train_loss:1.0570271468976796e-05 valid_loss:3.358970252520521e-05\n",
            "epoch:253 train_loss:1.2457953845215445e-05 valid_loss:2.8698246751446277e-05\n",
            "epoch:254 train_loss:1.585663934141242e-05 valid_loss:3.0125003377179382e-05\n",
            "epoch:255 train_loss:2.0399468465054975e-05 valid_loss:3.549287930582068e-05\n",
            "epoch:256 train_loss:1.885421321882556e-05 valid_loss:4.509085192694329e-05\n",
            "epoch:257 train_loss:1.7432766122106437e-05 valid_loss:2.2384241674444638e-05\n",
            "epoch:258 train_loss:1.8574864902297526e-05 valid_loss:2.0781237253686413e-05\n",
            "epoch:259 train_loss:2.099020230161841e-05 valid_loss:3.4000897358055227e-05\n",
            "epoch:260 train_loss:2.623945511004422e-05 valid_loss:4.2496526475588325e-05\n",
            "epoch:261 train_loss:2.8071363784773792e-05 valid_loss:6.619800115004182e-05\n",
            "epoch:262 train_loss:4.4668937739010696e-05 valid_loss:5.117279670230346e-05\n",
            "epoch:263 train_loss:3.754045928872074e-05 valid_loss:4.2944566303049214e-05\n",
            "epoch:264 train_loss:6.552715806012404e-05 valid_loss:9.367104576085694e-05\n",
            "epoch:265 train_loss:3.498629111062554e-05 valid_loss:3.374189464011579e-05\n",
            "epoch:266 train_loss:2.5843726840927655e-05 valid_loss:2.722658246057108e-05\n",
            "epoch:267 train_loss:3.247225443677356e-05 valid_loss:4.619774608727312e-05\n",
            "epoch:268 train_loss:3.500663471337854e-05 valid_loss:0.00011388595157768577\n",
            "epoch:269 train_loss:4.134075258358886e-05 valid_loss:3.274695609434275e-05\n",
            "epoch:270 train_loss:3.59195621765846e-05 valid_loss:5.2422095905058086e-05\n",
            "epoch:271 train_loss:2.923310017245563e-05 valid_loss:3.874762387567898e-05\n",
            "epoch:272 train_loss:2.2019841556660442e-05 valid_loss:4.093116422154708e-05\n",
            "epoch:273 train_loss:1.5997124592104228e-05 valid_loss:1.4735356671735644e-05\n",
            "epoch:274 train_loss:1.2834343856916854e-05 valid_loss:2.2801137220085366e-05\n",
            "epoch:275 train_loss:1.124472916874058e-05 valid_loss:4.779971732205013e-05\n",
            "epoch:276 train_loss:1.050296681468252e-05 valid_loss:2.2874715341458796e-05\n",
            "epoch:277 train_loss:1.44690785267206e-05 valid_loss:2.9480849661922548e-05\n",
            "epoch:278 train_loss:9.668924046006092e-06 valid_loss:2.7762937406805577e-05\n",
            "epoch:279 train_loss:8.347603233637023e-06 valid_loss:2.2836234620626783e-05\n",
            "epoch:280 train_loss:8.65482909123077e-06 valid_loss:3.2693515095161274e-05\n",
            "epoch:281 train_loss:8.863467175817479e-06 valid_loss:1.914897256938275e-05\n",
            "epoch:282 train_loss:1.0088121345890815e-05 valid_loss:1.715470307317446e-05\n",
            "epoch:283 train_loss:8.900904251479207e-06 valid_loss:3.3449764941906324e-05\n",
            "epoch:284 train_loss:9.573995814409702e-06 valid_loss:2.5652588647062657e-05\n",
            "epoch:285 train_loss:1.0219708833068984e-05 valid_loss:2.2429260752687696e-05\n",
            "epoch:286 train_loss:1.1380620612221213e-05 valid_loss:2.1961860511510167e-05\n",
            "epoch:287 train_loss:1.0776441968118888e-05 valid_loss:2.67643890765612e-05\n",
            "epoch:288 train_loss:1.4412257365216243e-05 valid_loss:3.014606090800953e-05\n",
            "epoch:289 train_loss:1.821613260391233e-05 valid_loss:3.561914763849927e-05\n",
            "epoch:290 train_loss:2.0330356316359637e-05 valid_loss:2.08416604436934e-05\n",
            "epoch:291 train_loss:1.7815583684447727e-05 valid_loss:3.084140462306095e-05\n",
            "epoch:292 train_loss:1.8242860177350747e-05 valid_loss:5.614239489659667e-05\n",
            "epoch:293 train_loss:2.2283769491574883e-05 valid_loss:2.8033116905135103e-05\n",
            "epoch:294 train_loss:1.6846485777932685e-05 valid_loss:1.3255607427709037e-05\n",
            "save best model\n",
            "epoch:295 train_loss:1.4433347258899528e-05 valid_loss:2.8750248475262197e-05\n",
            "epoch:296 train_loss:1.3009080753868653e-05 valid_loss:1.7638227063798695e-05\n",
            "epoch:297 train_loss:1.2774157261851036e-05 valid_loss:1.8108744825440226e-05\n",
            "epoch:298 train_loss:9.680701699229152e-06 valid_loss:1.7600945739104645e-05\n",
            "epoch:299 train_loss:6.940378448739972e-06 valid_loss:2.0466329260671046e-05\n",
            "epoch:300 train_loss:7.650928940468779e-06 valid_loss:1.2248320899743703e-05\n",
            "save best model\n",
            "epoch:301 train_loss:8.112490869886338e-06 valid_loss:1.532256328573567e-05\n",
            "epoch:302 train_loss:7.044208069196935e-06 valid_loss:2.535865678510163e-05\n",
            "epoch:303 train_loss:7.68914093088016e-06 valid_loss:1.2955587408214342e-05\n",
            "epoch:304 train_loss:7.840454663386885e-06 valid_loss:9.276737955588032e-06\n",
            "save best model\n",
            "epoch:305 train_loss:6.609932484025194e-06 valid_loss:1.7327079604001483e-05\n",
            "epoch:306 train_loss:6.607674815010493e-06 valid_loss:3.4396766750433017e-05\n",
            "epoch:307 train_loss:9.056473737069205e-06 valid_loss:2.9176504995120922e-05\n",
            "epoch:308 train_loss:1.1106499667019105e-05 valid_loss:1.8808068489306606e-05\n",
            "epoch:309 train_loss:8.844212301381856e-06 valid_loss:1.977607985281793e-05\n",
            "epoch:310 train_loss:1.2646035000014106e-05 valid_loss:2.1760022264061263e-05\n",
            "epoch:311 train_loss:1.211862998691989e-05 valid_loss:4.219423044560244e-05\n",
            "epoch:312 train_loss:1.3115840829414083e-05 valid_loss:4.004857055406319e-05\n",
            "epoch:313 train_loss:1.0535235838283876e-05 valid_loss:2.537471937102964e-05\n",
            "epoch:314 train_loss:1.1880465788433665e-05 valid_loss:2.6800920750247315e-05\n",
            "epoch:315 train_loss:1.77114290838492e-05 valid_loss:3.514130276016658e-05\n",
            "epoch:316 train_loss:2.128796917430817e-05 valid_loss:9.177696665574331e-05\n",
            "epoch:317 train_loss:3.240923860580046e-05 valid_loss:0.00010377156104368623\n",
            "epoch:318 train_loss:5.046285256563957e-05 valid_loss:8.2888229371747e-05\n",
            "epoch:319 train_loss:4.207536267131218e-05 valid_loss:3.876341725117527e-05\n",
            "epoch:320 train_loss:3.7025817922161273e-05 valid_loss:8.610938493802678e-05\n",
            "epoch:321 train_loss:5.195250903650756e-05 valid_loss:6.418289740395267e-05\n",
            "epoch:322 train_loss:0.019669137777984562 valid_loss:0.022960588335990906\n",
            "epoch:323 train_loss:0.009502208452128494 valid_loss:0.005977026477921754\n",
            "epoch:324 train_loss:0.0017679880127414232 valid_loss:0.0007491960423067212\n",
            "epoch:325 train_loss:0.0006126382633940213 valid_loss:0.0005488271272042766\n",
            "epoch:326 train_loss:0.00038888893242175173 valid_loss:0.0003873455571010709\n",
            "epoch:327 train_loss:0.0002733959445322398 valid_loss:0.0002928191825048998\n",
            "epoch:328 train_loss:0.00022346475371806364 valid_loss:0.00028226387075847015\n",
            "epoch:329 train_loss:0.00020303871133364737 valid_loss:0.00021619055041810498\n",
            "epoch:330 train_loss:0.0001670607990591735 valid_loss:0.0002422993493382819\n",
            "epoch:331 train_loss:0.00015940137948038883 valid_loss:0.0001725889705994632\n",
            "epoch:332 train_loss:0.00012087468763234533 valid_loss:0.00018396794257569127\n",
            "epoch:333 train_loss:0.0001210250399405292 valid_loss:0.00014703053602715954\n",
            "epoch:334 train_loss:0.00010068320201147192 valid_loss:0.0001492813680670224\n",
            "epoch:335 train_loss:9.599236525698668e-05 valid_loss:0.00013022402345086448\n",
            "epoch:336 train_loss:8.873003066077622e-05 valid_loss:0.00013501542707672343\n",
            "epoch:337 train_loss:8.512803510206545e-05 valid_loss:0.00012134139615227468\n",
            "epoch:338 train_loss:7.936419478937751e-05 valid_loss:0.00012132479423598852\n",
            "epoch:339 train_loss:7.952358636329236e-05 valid_loss:0.00011334377268212847\n",
            "epoch:340 train_loss:7.443759194656095e-05 valid_loss:0.00011197619460290298\n",
            "epoch:341 train_loss:7.388545933887751e-05 valid_loss:0.00010671737618395127\n",
            "epoch:342 train_loss:7.008121742223416e-05 valid_loss:0.0001058920897776261\n",
            "epoch:343 train_loss:6.985447816987289e-05 valid_loss:0.00010062480396300089\n",
            "epoch:344 train_loss:6.53954416520719e-05 valid_loss:9.692764979263302e-05\n",
            "epoch:345 train_loss:6.49956403119884e-05 valid_loss:9.422470066056121e-05\n",
            "epoch:346 train_loss:5.9939537802872816e-05 valid_loss:9.139467147178948e-05\n",
            "epoch:347 train_loss:6.008589985463509e-05 valid_loss:9.152212442131713e-05\n",
            "epoch:348 train_loss:5.7107099312108607e-05 valid_loss:8.888356569514144e-05\n",
            "epoch:349 train_loss:5.5063871918213815e-05 valid_loss:8.514655928593129e-05\n",
            "epoch:350 train_loss:5.2213337059785976e-05 valid_loss:8.25910537969321e-05\n",
            "epoch:351 train_loss:5.017207202702897e-05 valid_loss:8.198498471756466e-05\n",
            "epoch:352 train_loss:4.730722866952419e-05 valid_loss:7.952854684845079e-05\n",
            "epoch:353 train_loss:4.416028542032614e-05 valid_loss:7.680835733481217e-05\n",
            "epoch:354 train_loss:3.8876457033944054e-05 valid_loss:6.972490700718481e-05\n",
            "epoch:355 train_loss:3.382232158502221e-05 valid_loss:6.371937161020469e-05\n",
            "epoch:356 train_loss:3.0020772909564483e-05 valid_loss:6.0462967667263e-05\n",
            "epoch:357 train_loss:2.8742354010723324e-05 valid_loss:6.13143783994019e-05\n",
            "epoch:358 train_loss:2.7318372455435263e-05 valid_loss:5.394744766817894e-05\n",
            "epoch:359 train_loss:2.442221097630358e-05 valid_loss:5.6464857152604964e-05\n",
            "epoch:360 train_loss:2.4337549272483255e-05 valid_loss:5.32561725776759e-05\n",
            "epoch:361 train_loss:2.4319295890664864e-05 valid_loss:5.41687822988024e-05\n",
            "epoch:362 train_loss:2.6018986571014262e-05 valid_loss:4.942159921483835e-05\n",
            "epoch:363 train_loss:2.2493648884847062e-05 valid_loss:4.49817453045398e-05\n",
            "epoch:364 train_loss:2.0178413352469863e-05 valid_loss:4.201194860797841e-05\n",
            "epoch:365 train_loss:1.7621972397642417e-05 valid_loss:4.387544231576612e-05\n",
            "epoch:366 train_loss:1.7520300970217148e-05 valid_loss:4.576145875034854e-05\n",
            "epoch:367 train_loss:1.911539074070687e-05 valid_loss:4.45520645371289e-05\n",
            "epoch:368 train_loss:1.8866988966692588e-05 valid_loss:3.758079219551291e-05\n",
            "epoch:369 train_loss:1.6763241597396296e-05 valid_loss:3.703604579641251e-05\n",
            "epoch:370 train_loss:1.6169721372231532e-05 valid_loss:3.313967135909479e-05\n",
            "epoch:371 train_loss:1.505916818839776e-05 valid_loss:3.312757917228737e-05\n",
            "epoch:372 train_loss:1.477302723489831e-05 valid_loss:3.477243171801092e-05\n",
            "epoch:373 train_loss:1.4208670412093246e-05 valid_loss:3.580488146326388e-05\n",
            "epoch:374 train_loss:1.7294333499901564e-05 valid_loss:3.7646706914529204e-05\n",
            "epoch:375 train_loss:1.724674699390663e-05 valid_loss:2.9937624276499264e-05\n",
            "epoch:376 train_loss:1.4324636569856213e-05 valid_loss:2.801714163069846e-05\n",
            "epoch:377 train_loss:1.5520883026612057e-05 valid_loss:2.8399336770235095e-05\n",
            "epoch:378 train_loss:1.3692888463386529e-05 valid_loss:3.0180135581758805e-05\n",
            "epoch:379 train_loss:1.3911220700416985e-05 valid_loss:3.137936164421262e-05\n",
            "epoch:380 train_loss:1.5195568658378357e-05 valid_loss:2.8726984055538196e-05\n",
            "epoch:381 train_loss:1.2597052369124463e-05 valid_loss:2.4374333406740334e-05\n",
            "epoch:382 train_loss:1.3728970492997581e-05 valid_loss:2.3811193841538625e-05\n",
            "epoch:383 train_loss:1.3117573808408957e-05 valid_loss:2.5474610993114766e-05\n",
            "epoch:384 train_loss:1.1285152848156738e-05 valid_loss:2.751371221165755e-05\n",
            "epoch:385 train_loss:1.310312056072386e-05 valid_loss:2.5961284791264916e-05\n",
            "epoch:386 train_loss:1.1796887671759274e-05 valid_loss:2.1705117433157284e-05\n",
            "epoch:387 train_loss:1.0778923814945705e-05 valid_loss:2.114657718266244e-05\n",
            "epoch:388 train_loss:1.2976403253459364e-05 valid_loss:2.0414887785591418e-05\n",
            "epoch:389 train_loss:1.0885606153957875e-05 valid_loss:2.524001774872886e-05\n",
            "epoch:390 train_loss:1.220574447163219e-05 valid_loss:2.929201855295105e-05\n",
            "epoch:391 train_loss:1.3912572639027429e-05 valid_loss:2.1291562006808817e-05\n",
            "epoch:392 train_loss:1.0694295484528186e-05 valid_loss:1.9435941339907004e-05\n",
            "epoch:393 train_loss:1.4352029375509624e-05 valid_loss:2.0075466181879165e-05\n",
            "epoch:394 train_loss:1.0953965468413824e-05 valid_loss:2.3486517420678865e-05\n",
            "epoch:395 train_loss:1.1693421861814892e-05 valid_loss:3.094929570579552e-05\n",
            "epoch:396 train_loss:1.5875216781245803e-05 valid_loss:2.7225692974752747e-05\n",
            "epoch:397 train_loss:1.129685001109869e-05 valid_loss:1.7584232409717515e-05\n",
            "epoch:398 train_loss:1.2565573367990308e-05 valid_loss:1.862029102994711e-05\n",
            "epoch:399 train_loss:1.1526217791571173e-05 valid_loss:1.811734455259284e-05\n",
            "epoch:400 train_loss:9.135456290702374e-06 valid_loss:2.590709527794388e-05\n",
            "epoch:401 train_loss:1.0523078597341535e-05 valid_loss:2.116669611496036e-05\n",
            "epoch:402 train_loss:9.453624443267472e-06 valid_loss:1.5850822137508658e-05\n",
            "epoch:403 train_loss:1.0026538044864234e-05 valid_loss:1.7112339264713228e-05\n",
            "epoch:404 train_loss:8.65484397157464e-06 valid_loss:1.623955904506147e-05\n",
            "epoch:405 train_loss:7.422200332661709e-06 valid_loss:1.854356287367409e-05\n",
            "epoch:406 train_loss:8.254774709510255e-06 valid_loss:2.0855548882536823e-05\n",
            "epoch:407 train_loss:8.104723456704556e-06 valid_loss:1.5658918073313544e-05\n",
            "epoch:408 train_loss:7.608201030961936e-06 valid_loss:1.4202135844243458e-05\n",
            "epoch:409 train_loss:8.65009059857079e-06 valid_loss:1.5187474218691932e-05\n",
            "epoch:410 train_loss:8.609227140570712e-06 valid_loss:1.5114387906578486e-05\n",
            "epoch:411 train_loss:7.068756682807968e-06 valid_loss:1.91699023162073e-05\n",
            "epoch:412 train_loss:8.674643949133395e-06 valid_loss:2.3696131847827928e-05\n",
            "epoch:413 train_loss:9.168686725994727e-06 valid_loss:1.6550152395211626e-05\n",
            "epoch:414 train_loss:7.190930268229244e-06 valid_loss:1.3832805507263402e-05\n",
            "epoch:415 train_loss:8.455252277094081e-06 valid_loss:1.6120133295771666e-05\n",
            "epoch:416 train_loss:1.1829874653004583e-05 valid_loss:1.4517017689286149e-05\n",
            "epoch:417 train_loss:8.676802382170637e-06 valid_loss:2.2933159470994724e-05\n",
            "epoch:418 train_loss:9.97331274750953e-06 valid_loss:2.22369685616286e-05\n",
            "epoch:419 train_loss:1.171229829803148e-05 valid_loss:2.554455477365991e-05\n",
            "epoch:420 train_loss:9.343539760367195e-06 valid_loss:1.4667808272861294e-05\n",
            "epoch:421 train_loss:8.845569899070446e-06 valid_loss:1.5277347301889677e-05\n",
            "epoch:422 train_loss:1.4507792646630454e-05 valid_loss:1.691970533101994e-05\n",
            "epoch:423 train_loss:9.702103776968821e-06 valid_loss:2.3367483663605526e-05\n",
            "epoch:424 train_loss:1.0846767256427685e-05 valid_loss:2.2216731849766802e-05\n",
            "epoch:425 train_loss:9.32844725159359e-06 valid_loss:1.4369332802743884e-05\n",
            "epoch:426 train_loss:7.498894622888959e-06 valid_loss:1.6464830878248904e-05\n",
            "epoch:427 train_loss:8.735978149666658e-06 valid_loss:1.7736590052663814e-05\n",
            "epoch:428 train_loss:7.340835408184729e-06 valid_loss:1.6640758531139e-05\n",
            "epoch:429 train_loss:7.456437136473444e-06 valid_loss:1.633753618079936e-05\n",
            "epoch:430 train_loss:6.182772659081416e-06 valid_loss:1.7847892650024733e-05\n",
            "epoch:431 train_loss:6.999140484569782e-06 valid_loss:1.2275000699446537e-05\n",
            "epoch:432 train_loss:6.298417222044211e-06 valid_loss:1.7834644950198708e-05\n",
            "epoch:433 train_loss:7.160357805939081e-06 valid_loss:1.3920705896453e-05\n",
            "epoch:434 train_loss:6.862605156735905e-06 valid_loss:1.6936146948864916e-05\n",
            "epoch:435 train_loss:6.264014864933011e-06 valid_loss:1.7297904605584336e-05\n",
            "epoch:436 train_loss:6.188923142265897e-06 valid_loss:1.298197707910731e-05\n",
            "epoch:437 train_loss:5.357088778307823e-06 valid_loss:1.7130186506619793e-05\n",
            "epoch:438 train_loss:5.832947964437254e-06 valid_loss:1.2375186543067684e-05\n",
            "epoch:439 train_loss:6.096103618347115e-06 valid_loss:1.4296651443146402e-05\n",
            "epoch:440 train_loss:5.600111914342658e-06 valid_loss:1.3947430488769896e-05\n",
            "epoch:441 train_loss:6.15329424312626e-06 valid_loss:1.238162508343521e-05\n",
            "epoch:442 train_loss:5.542195102255694e-06 valid_loss:1.7848504057838e-05\n",
            "epoch:443 train_loss:5.868679705953481e-06 valid_loss:1.1126110621262342e-05\n",
            "epoch:444 train_loss:5.0904246664787124e-06 valid_loss:1.644708777348569e-05\n",
            "epoch:445 train_loss:4.785587293554272e-06 valid_loss:1.277056662729592e-05\n",
            "epoch:446 train_loss:5.428232618164151e-06 valid_loss:1.2730083653877955e-05\n",
            "epoch:447 train_loss:5.633639009122109e-06 valid_loss:1.8694823893383727e-05\n",
            "epoch:448 train_loss:5.354880525171919e-06 valid_loss:1.3153002782928525e-05\n",
            "epoch:449 train_loss:6.097218387266265e-06 valid_loss:1.3690488913198351e-05\n",
            "epoch:450 train_loss:6.108946321445627e-06 valid_loss:2.0353318859633873e-05\n",
            "epoch:451 train_loss:6.325667439139377e-06 valid_loss:1.3190758409109549e-05\n",
            "epoch:452 train_loss:6.262611754613721e-06 valid_loss:1.88905032700859e-05\n",
            "epoch:453 train_loss:6.726523666758213e-06 valid_loss:1.9746517409657827e-05\n",
            "epoch:454 train_loss:6.355395865082553e-06 valid_loss:1.4861342606309336e-05\n",
            "epoch:455 train_loss:6.491603610609471e-06 valid_loss:2.0708163447125116e-05\n",
            "epoch:456 train_loss:7.763127314319718e-06 valid_loss:2.1388940240285592e-05\n",
            "epoch:457 train_loss:7.560799392397004e-06 valid_loss:1.6214999504882144e-05\n",
            "epoch:458 train_loss:8.604302239392484e-06 valid_loss:2.5026810817507794e-05\n",
            "epoch:459 train_loss:9.11442546364722e-06 valid_loss:2.120118006132543e-05\n",
            "epoch:460 train_loss:1.0296329908972742e-05 valid_loss:1.5804653685336234e-05\n",
            "epoch:461 train_loss:1.1586153378731171e-05 valid_loss:3.619711833380279e-05\n",
            "epoch:462 train_loss:1.0980940740207896e-05 valid_loss:1.5711233118054224e-05\n",
            "epoch:463 train_loss:9.701263580710576e-06 valid_loss:1.7740856264936156e-05\n",
            "epoch:464 train_loss:9.082880246246026e-06 valid_loss:1.668016693656682e-05\n",
            "epoch:465 train_loss:9.968411215292386e-06 valid_loss:1.551086984363792e-05\n",
            "epoch:466 train_loss:9.059922414659619e-06 valid_loss:1.5655790775781497e-05\n",
            "epoch:467 train_loss:8.044047010318738e-06 valid_loss:1.1050574357795995e-05\n",
            "epoch:468 train_loss:8.549139364630617e-06 valid_loss:2.121103102581401e-05\n",
            "epoch:469 train_loss:1.6105838818071385e-05 valid_loss:2.0174831206531962e-05\n",
            "epoch:470 train_loss:1.82328924691117e-05 valid_loss:4.473885019251611e-05\n",
            "epoch:471 train_loss:2.236824527951992e-05 valid_loss:5.3152798500377685e-05\n",
            "epoch:472 train_loss:3.0557894964052444e-05 valid_loss:6.815929918957409e-05\n",
            "epoch:473 train_loss:2.8077435672457796e-05 valid_loss:5.102234717924148e-05\n",
            "epoch:474 train_loss:2.5169263734723143e-05 valid_loss:2.7619064894679468e-05\n",
            "epoch:475 train_loss:1.788924403930044e-05 valid_loss:2.2491815343528287e-05\n",
            "epoch:476 train_loss:1.3647879288530223e-05 valid_loss:2.6334068934374955e-05\n",
            "epoch:477 train_loss:1.2819854987355939e-05 valid_loss:3.2134500088432105e-05\n",
            "epoch:478 train_loss:1.0602023646950127e-05 valid_loss:2.6116782009921735e-05\n",
            "epoch:479 train_loss:1.067302658460297e-05 valid_loss:1.582364211571985e-05\n",
            "epoch:480 train_loss:9.619284368353772e-06 valid_loss:1.9569904452509945e-05\n",
            "epoch:481 train_loss:1.0293668891689675e-05 valid_loss:1.4296562312665628e-05\n",
            "epoch:482 train_loss:9.758729018156171e-06 valid_loss:1.5360593351942953e-05\n",
            "epoch:483 train_loss:1.0618353245364335e-05 valid_loss:1.5103740679478506e-05\n",
            "epoch:484 train_loss:1.0710259655550342e-05 valid_loss:1.650559534027707e-05\n",
            "epoch:485 train_loss:1.0661901771729592e-05 valid_loss:1.925721971929306e-05\n",
            "epoch:486 train_loss:8.932588949998413e-06 valid_loss:1.4411526080948533e-05\n",
            "epoch:487 train_loss:7.710860194897072e-06 valid_loss:1.2187789479867206e-05\n",
            "epoch:488 train_loss:8.96942866448727e-06 valid_loss:1.3367055771595915e-05\n",
            "epoch:489 train_loss:9.079282739953163e-06 valid_loss:1.5685920743635506e-05\n",
            "epoch:490 train_loss:1.0319196260550396e-05 valid_loss:2.192372039644397e-05\n",
            "epoch:491 train_loss:1.2670870925527803e-05 valid_loss:1.9679930119309574e-05\n",
            "epoch:492 train_loss:9.59391950851164e-06 valid_loss:1.8219186813439592e-05\n",
            "epoch:493 train_loss:1.1189501770382372e-05 valid_loss:1.6764859765316942e-05\n",
            "epoch:494 train_loss:1.1448616280378903e-05 valid_loss:3.1143366868491285e-05\n",
            "epoch:495 train_loss:1.503272799002136e-05 valid_loss:3.8027207665436435e-05\n",
            "epoch:496 train_loss:1.4948825739540755e-05 valid_loss:3.311800583105651e-05\n",
            "epoch:497 train_loss:1.1773759069910739e-05 valid_loss:1.904131704577594e-05\n",
            "epoch:498 train_loss:8.069875181920199e-06 valid_loss:1.2671702279476449e-05\n",
            "epoch:499 train_loss:7.062783033183627e-06 valid_loss:1.2587993069246295e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "4ud5NnbW-pOM",
        "outputId": "e2b562a3-e4a9-49ba-e835-9691c676dbc5"
      },
      "source": [
        "res = part1.test()\n",
        "res"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D stream BENZENE</th>\n",
              "      <td>0.999908</td>\n",
              "      <td>4.07981e-07</td>\n",
              "      <td>0.0448104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D stream TOLUENE</th>\n",
              "      <td>0.999923</td>\n",
              "      <td>3.42494e-07</td>\n",
              "      <td>92.3445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W stream BENZENE</th>\n",
              "      <td>0.999884</td>\n",
              "      <td>2.00349e-06</td>\n",
              "      <td>22429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W stream TOLUENE</th>\n",
              "      <td>0.999921</td>\n",
              "      <td>1.36085e-06</td>\n",
              "      <td>0.09871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999909</td>\n",
              "      <td>1.02871e-06</td>\n",
              "      <td>5630.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        R2          MSE       MAPE\n",
              "0                                                 \n",
              "D stream BENZENE  0.999908  4.07981e-07  0.0448104\n",
              "D stream TOLUENE  0.999923  3.42494e-07    92.3445\n",
              "W stream BENZENE  0.999884  2.00349e-06      22429\n",
              "W stream TOLUENE  0.999921  1.36085e-06    0.09871\n",
              "AVG               0.999909  1.02871e-06    5630.38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aadwibjClcc"
      },
      "source": [
        "# PART2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udm6e1rUC4LO",
        "outputId": "cdb38192-2e14-41eb-a6db-506992fa05d4"
      },
      "source": [
        "part2 = part(df,df.columns[:10],df.columns[[11,15]])\n",
        "part2.train()"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.026806106583939657 valid_loss:0.0117783488240093\n",
            "save best model\n",
            "epoch:1 train_loss:0.003927192605462753 valid_loss:0.004447267972864211\n",
            "save best model\n",
            "epoch:2 train_loss:0.0013055351737421006 valid_loss:0.0020785971428267658\n",
            "save best model\n",
            "epoch:3 train_loss:0.0007248069903451122 valid_loss:0.0012114523851778358\n",
            "save best model\n",
            "epoch:4 train_loss:0.0004338614364516818 valid_loss:0.0010358991858083755\n",
            "save best model\n",
            "epoch:5 train_loss:0.0003161315350250031 valid_loss:0.0008402751554967836\n",
            "save best model\n",
            "epoch:6 train_loss:0.00024670276818344265 valid_loss:0.0007117091881809756\n",
            "save best model\n",
            "epoch:7 train_loss:0.00020625937092214977 valid_loss:0.0006133210699772462\n",
            "save best model\n",
            "epoch:8 train_loss:0.00016020504598499328 valid_loss:0.0005056451045675203\n",
            "save best model\n",
            "epoch:9 train_loss:0.0001399035823447371 valid_loss:0.0004198568931315094\n",
            "save best model\n",
            "epoch:10 train_loss:0.00011736053278986624 valid_loss:0.000402075813326519\n",
            "save best model\n",
            "epoch:11 train_loss:0.00010315147523619494 valid_loss:0.0004909816052531824\n",
            "epoch:12 train_loss:0.00010759915646000688 valid_loss:0.0002790189209918026\n",
            "save best model\n",
            "epoch:13 train_loss:0.0001943040220390281 valid_loss:0.0010655981895979494\n",
            "epoch:14 train_loss:0.0003355105776184549 valid_loss:0.0005023414414608851\n",
            "epoch:15 train_loss:0.00031492545854740054 valid_loss:0.00046834217209834605\n",
            "epoch:16 train_loss:0.0001897536017673297 valid_loss:0.00043930744868703187\n",
            "epoch:17 train_loss:0.0001486987679931594 valid_loss:0.00029509048181353137\n",
            "epoch:18 train_loss:9.969489959379037e-05 valid_loss:0.0003776981830014847\n",
            "epoch:19 train_loss:0.00011319751077583835 valid_loss:0.00022348362108459696\n",
            "save best model\n",
            "epoch:20 train_loss:7.771883449297295e-05 valid_loss:0.00044821247865911573\n",
            "epoch:21 train_loss:0.00013297231150014946 valid_loss:0.0002796948901959695\n",
            "epoch:22 train_loss:0.00011228313188540697 valid_loss:0.0005231019167695194\n",
            "epoch:23 train_loss:0.000123196232986326 valid_loss:0.00048393495671916753\n",
            "epoch:24 train_loss:0.00018968722623766452 valid_loss:0.00104769880999811\n",
            "epoch:25 train_loss:0.00034716602830384445 valid_loss:0.0016892546555027366\n",
            "epoch:26 train_loss:0.0007112622293384953 valid_loss:0.0007670586055610329\n",
            "epoch:27 train_loss:0.00021906767869950272 valid_loss:0.00038239461719058454\n",
            "epoch:28 train_loss:0.00011547868234629277 valid_loss:0.00022983124290476553\n",
            "epoch:29 train_loss:7.770271966162707e-05 valid_loss:0.000215187763387803\n",
            "save best model\n",
            "epoch:30 train_loss:5.8512992028328073e-05 valid_loss:0.0001975040722754784\n",
            "save best model\n",
            "epoch:31 train_loss:5.019711802055503e-05 valid_loss:0.0001326404162682593\n",
            "save best model\n",
            "epoch:32 train_loss:3.582244961661571e-05 valid_loss:0.0001665411746216705\n",
            "epoch:33 train_loss:3.648037803335077e-05 valid_loss:0.000132731989651802\n",
            "epoch:34 train_loss:3.0355213059212678e-05 valid_loss:0.0001123167821788229\n",
            "save best model\n",
            "epoch:35 train_loss:2.621067084065645e-05 valid_loss:0.00011324816841806751\n",
            "epoch:36 train_loss:2.4745712557382325e-05 valid_loss:0.00012597270324476995\n",
            "epoch:37 train_loss:2.3994274695521905e-05 valid_loss:0.00012796710325346794\n",
            "epoch:38 train_loss:2.2874256728755427e-05 valid_loss:0.00011689354505506344\n",
            "epoch:39 train_loss:2.1981681483238288e-05 valid_loss:9.552801020618062e-05\n",
            "save best model\n",
            "epoch:40 train_loss:2.110259459995076e-05 valid_loss:7.999392801139038e-05\n",
            "save best model\n",
            "epoch:41 train_loss:2.2256004942593994e-05 valid_loss:7.98137762103579e-05\n",
            "save best model\n",
            "epoch:42 train_loss:2.3740693753400894e-05 valid_loss:8.66105328896083e-05\n",
            "epoch:43 train_loss:2.332247716670584e-05 valid_loss:0.00010814238703460433\n",
            "epoch:44 train_loss:2.3559391037350804e-05 valid_loss:0.00013739319911110215\n",
            "epoch:45 train_loss:2.6986822098883244e-05 valid_loss:0.00017487112199887633\n",
            "epoch:46 train_loss:3.0838102197271335e-05 valid_loss:0.00022447348965215497\n",
            "epoch:47 train_loss:3.932286623845963e-05 valid_loss:0.00026616141985869035\n",
            "epoch:48 train_loss:5.010894589455953e-05 valid_loss:0.0003494833945296705\n",
            "epoch:49 train_loss:9.646877232525084e-05 valid_loss:0.0003742880071513355\n",
            "epoch:50 train_loss:0.00016721369239449914 valid_loss:0.00011603625534917228\n",
            "epoch:51 train_loss:0.00020805375152121997 valid_loss:0.0004241301503498107\n",
            "epoch:52 train_loss:0.00030152255931170657 valid_loss:0.0013636541552841663\n",
            "epoch:53 train_loss:0.0005003783630349466 valid_loss:0.00020503342238953337\n",
            "epoch:54 train_loss:0.00020684312969226285 valid_loss:0.00025181370801874436\n",
            "epoch:55 train_loss:8.94922248133096e-05 valid_loss:0.00016749196220189333\n",
            "epoch:56 train_loss:6.471913901704183e-05 valid_loss:0.00010620124339766335\n",
            "epoch:57 train_loss:4.675131534289297e-05 valid_loss:7.708813427598216e-05\n",
            "save best model\n",
            "epoch:58 train_loss:3.542645602768365e-05 valid_loss:9.053538542502793e-05\n",
            "epoch:59 train_loss:5.0213065808040686e-05 valid_loss:0.00010070837197417859\n",
            "epoch:60 train_loss:4.784396792779767e-05 valid_loss:0.00010145384476345498\n",
            "epoch:61 train_loss:6.0787245779970865e-05 valid_loss:0.00013200998728279956\n",
            "epoch:62 train_loss:6.957612206153701e-05 valid_loss:0.00014121364256425295\n",
            "epoch:63 train_loss:8.55616104268443e-05 valid_loss:0.0001735446676320862\n",
            "epoch:64 train_loss:9.140959638090053e-05 valid_loss:0.00015849705596338026\n",
            "epoch:65 train_loss:0.00011247648581047542 valid_loss:0.00017619429127080366\n",
            "epoch:66 train_loss:0.00013238368612494215 valid_loss:0.0002460389368934557\n",
            "epoch:67 train_loss:0.0001281527680071627 valid_loss:0.00042980050784535706\n",
            "epoch:68 train_loss:0.00020651200652031953 valid_loss:0.0006263679679250345\n",
            "epoch:69 train_loss:0.0004099104662600439 valid_loss:0.00042639033927116543\n",
            "epoch:70 train_loss:0.00047450309810099297 valid_loss:0.0007157171639846638\n",
            "epoch:71 train_loss:0.00030801487042077095 valid_loss:0.00014362989168148488\n",
            "epoch:72 train_loss:0.0001453152308386052 valid_loss:0.00014194986761140171\n",
            "epoch:73 train_loss:0.00016677421889552433 valid_loss:0.00018444164379616268\n",
            "epoch:74 train_loss:0.00013094881311796294 valid_loss:0.00011969053048233036\n",
            "epoch:75 train_loss:6.506333506371852e-05 valid_loss:7.971550076035783e-05\n",
            "epoch:76 train_loss:3.4397416988617304e-05 valid_loss:5.3302695050660986e-05\n",
            "save best model\n",
            "epoch:77 train_loss:1.8908390428704377e-05 valid_loss:3.4526367016951554e-05\n",
            "save best model\n",
            "epoch:78 train_loss:1.250859832503516e-05 valid_loss:3.2738268146204064e-05\n",
            "save best model\n",
            "epoch:79 train_loss:1.1328692052201302e-05 valid_loss:3.063159920202452e-05\n",
            "save best model\n",
            "epoch:80 train_loss:1.1386979394956143e-05 valid_loss:2.690336259547621e-05\n",
            "save best model\n",
            "epoch:81 train_loss:8.997427812573733e-06 valid_loss:2.4806774035823764e-05\n",
            "save best model\n",
            "epoch:82 train_loss:8.889224217354138e-06 valid_loss:2.520056932553416e-05\n",
            "epoch:83 train_loss:8.80637843339274e-06 valid_loss:2.2301192075246945e-05\n",
            "save best model\n",
            "epoch:84 train_loss:7.3761226783770125e-06 valid_loss:2.1109571207489353e-05\n",
            "save best model\n",
            "epoch:85 train_loss:6.872516779468343e-06 valid_loss:2.0378283807076514e-05\n",
            "save best model\n",
            "epoch:86 train_loss:6.726616548904632e-06 valid_loss:2.2213871488929726e-05\n",
            "epoch:87 train_loss:7.325310510471657e-06 valid_loss:2.072066627079039e-05\n",
            "epoch:88 train_loss:6.890332795390148e-06 valid_loss:1.9655092728498857e-05\n",
            "save best model\n",
            "epoch:89 train_loss:6.710771951172016e-06 valid_loss:1.8849259959097253e-05\n",
            "save best model\n",
            "epoch:90 train_loss:7.958057722134981e-06 valid_loss:1.7201737136929296e-05\n",
            "save best model\n",
            "epoch:91 train_loss:7.343298711425126e-06 valid_loss:2.2607287519349484e-05\n",
            "epoch:92 train_loss:8.689459188341667e-06 valid_loss:2.5102415747824125e-05\n",
            "epoch:93 train_loss:1.4600129412024722e-05 valid_loss:2.9482142053893767e-05\n",
            "epoch:94 train_loss:1.8692298555025547e-05 valid_loss:3.079670477745822e-05\n",
            "epoch:95 train_loss:1.7161159550798606e-05 valid_loss:5.843853978149127e-05\n",
            "epoch:96 train_loss:4.279753840011027e-05 valid_loss:0.00010544524957367685\n",
            "epoch:97 train_loss:9.458283764413661e-05 valid_loss:5.7369090427528135e-05\n",
            "epoch:98 train_loss:9.936923440060734e-05 valid_loss:0.0001323506330663804\n",
            "epoch:99 train_loss:9.127130124397809e-05 valid_loss:0.0002891267431550659\n",
            "epoch:100 train_loss:0.00021026920795621764 valid_loss:0.0001302484561165329\n",
            "epoch:101 train_loss:0.00021323606476168303 valid_loss:0.0003243556202505715\n",
            "epoch:102 train_loss:0.00017745435717289284 valid_loss:0.00013481763016898185\n",
            "epoch:103 train_loss:0.00018342997686381245 valid_loss:0.00019827939104288816\n",
            "epoch:104 train_loss:0.00011622813316433976 valid_loss:6.590962948394008e-05\n",
            "epoch:105 train_loss:6.576920754418502e-05 valid_loss:0.0001102065452869283\n",
            "epoch:106 train_loss:7.211077399915666e-05 valid_loss:8.406376036873553e-05\n",
            "epoch:107 train_loss:3.926766076902924e-05 valid_loss:3.7263437661749776e-05\n",
            "epoch:108 train_loss:1.858068738632331e-05 valid_loss:2.2238027668208815e-05\n",
            "epoch:109 train_loss:1.662167975761501e-05 valid_loss:3.121673580608331e-05\n",
            "epoch:110 train_loss:1.4958252298432248e-05 valid_loss:2.5104647193074925e-05\n",
            "epoch:111 train_loss:8.311862757182098e-06 valid_loss:1.6668176613165997e-05\n",
            "save best model\n",
            "epoch:112 train_loss:7.368609873184242e-06 valid_loss:2.0062843304913258e-05\n",
            "epoch:113 train_loss:7.559988843139662e-06 valid_loss:1.754937693476677e-05\n",
            "epoch:114 train_loss:5.797421130814149e-06 valid_loss:1.740643756420468e-05\n",
            "epoch:115 train_loss:6.0435776024153e-06 valid_loss:1.38560819777922e-05\n",
            "save best model\n",
            "epoch:116 train_loss:5.367184750563562e-06 valid_loss:1.5815401638974436e-05\n",
            "epoch:117 train_loss:6.112818659352746e-06 valid_loss:1.5079720924404683e-05\n",
            "epoch:118 train_loss:5.334224750994407e-06 valid_loss:1.8169969280279474e-05\n",
            "epoch:119 train_loss:6.001964632357865e-06 valid_loss:1.1597280263231369e-05\n",
            "save best model\n",
            "epoch:120 train_loss:6.194076819257235e-06 valid_loss:1.5446607903868426e-05\n",
            "epoch:121 train_loss:6.203143331933663e-06 valid_loss:1.920593058457598e-05\n",
            "epoch:122 train_loss:1.133671378283907e-05 valid_loss:2.3171854536485625e-05\n",
            "epoch:123 train_loss:1.222485280373399e-05 valid_loss:2.378583940298995e-05\n",
            "epoch:124 train_loss:1.0092437150888145e-05 valid_loss:3.810773432633141e-05\n",
            "epoch:125 train_loss:2.419695483189975e-05 valid_loss:3.884033503709361e-05\n",
            "epoch:126 train_loss:4.053259757104873e-05 valid_loss:2.049898330369615e-05\n",
            "epoch:127 train_loss:3.341404352694452e-05 valid_loss:6.50416604912607e-05\n",
            "epoch:128 train_loss:3.581245851415183e-05 valid_loss:9.735398998600431e-05\n",
            "epoch:129 train_loss:9.946999155848364e-05 valid_loss:0.00014334697334561497\n",
            "epoch:130 train_loss:0.00014273668643404057 valid_loss:7.87685567047447e-05\n",
            "epoch:131 train_loss:8.957199164190872e-05 valid_loss:0.00018598702808958478\n",
            "epoch:132 train_loss:0.0001319782611770077 valid_loss:0.000488242571009323\n",
            "epoch:133 train_loss:0.00027419742683479044 valid_loss:0.00017267907969653606\n",
            "epoch:134 train_loss:0.00016011528108113757 valid_loss:0.0002860795648302883\n",
            "epoch:135 train_loss:0.00018979915391052296 valid_loss:0.00010438163008075207\n",
            "epoch:136 train_loss:0.00017955231649264332 valid_loss:0.000277873215964064\n",
            "epoch:137 train_loss:0.00014161004198993195 valid_loss:7.559314326499589e-05\n",
            "epoch:138 train_loss:6.535439266978453e-05 valid_loss:4.8524037993047386e-05\n",
            "epoch:139 train_loss:4.053172288978304e-05 valid_loss:4.927605277771363e-05\n",
            "epoch:140 train_loss:3.115249976164907e-05 valid_loss:3.312574881420005e-05\n",
            "epoch:141 train_loss:1.4787212825871797e-05 valid_loss:2.0827415937674232e-05\n",
            "epoch:142 train_loss:8.245756640058567e-06 valid_loss:1.4747080285815173e-05\n",
            "epoch:143 train_loss:6.317876429622831e-06 valid_loss:1.3942931218480226e-05\n",
            "epoch:144 train_loss:5.384907107478891e-06 valid_loss:1.2881488146376796e-05\n",
            "epoch:145 train_loss:4.5948599260251894e-06 valid_loss:1.2764924576913472e-05\n",
            "epoch:146 train_loss:4.524361214761383e-06 valid_loss:1.2702950243692612e-05\n",
            "epoch:147 train_loss:4.410359565554245e-06 valid_loss:1.1780565955632483e-05\n",
            "epoch:148 train_loss:4.195047792008053e-06 valid_loss:1.1407113106542965e-05\n",
            "save best model\n",
            "epoch:149 train_loss:4.181518142508543e-06 valid_loss:9.894371942209546e-06\n",
            "save best model\n",
            "epoch:150 train_loss:4.389153259707099e-06 valid_loss:1.3472622640620102e-05\n",
            "epoch:151 train_loss:4.6816397419509786e-06 valid_loss:9.887512533168774e-06\n",
            "save best model\n",
            "epoch:152 train_loss:4.273385453896279e-06 valid_loss:1.1684656556099071e-05\n",
            "epoch:153 train_loss:4.638128568027848e-06 valid_loss:1.0037340643975767e-05\n",
            "epoch:154 train_loss:5.355781569152087e-06 valid_loss:9.66298262028431e-06\n",
            "save best model\n",
            "epoch:155 train_loss:4.727252126536365e-06 valid_loss:1.2419736776791979e-05\n",
            "epoch:156 train_loss:6.047573265277606e-06 valid_loss:1.1501013887027511e-05\n",
            "epoch:157 train_loss:9.602477891550936e-06 valid_loss:1.2384056844894076e-05\n",
            "epoch:158 train_loss:7.869575546869277e-06 valid_loss:2.0899949049635325e-05\n",
            "epoch:159 train_loss:1.0522170643728006e-05 valid_loss:2.522707018215442e-05\n",
            "epoch:160 train_loss:2.2764171717426507e-05 valid_loss:1.7345521655443008e-05\n",
            "epoch:161 train_loss:3.007761837478837e-05 valid_loss:2.1725170881836675e-05\n",
            "epoch:162 train_loss:2.3793468901405707e-05 valid_loss:6.877153646200895e-05\n",
            "epoch:163 train_loss:3.756910372329811e-05 valid_loss:0.00010392029071226716\n",
            "epoch:164 train_loss:8.849686507043468e-05 valid_loss:7.519280006818008e-05\n",
            "epoch:165 train_loss:0.00011036781618006191 valid_loss:6.654709250142332e-05\n",
            "epoch:166 train_loss:7.730028513227201e-05 valid_loss:0.00015430997518706135\n",
            "epoch:167 train_loss:0.00010337562727929455 valid_loss:5.7259438108303584e-05\n",
            "epoch:168 train_loss:0.0001275594155837704 valid_loss:7.273533992702141e-05\n",
            "epoch:169 train_loss:5.455958297615224e-05 valid_loss:9.547375884721987e-05\n",
            "epoch:170 train_loss:9.367669766409865e-05 valid_loss:5.297436109685805e-05\n",
            "epoch:171 train_loss:5.493409268334896e-05 valid_loss:8.687705121701583e-05\n",
            "epoch:172 train_loss:6.367687274178024e-05 valid_loss:4.4375537981977686e-05\n",
            "epoch:173 train_loss:3.321402684580082e-05 valid_loss:3.6561189517669845e-05\n",
            "epoch:174 train_loss:3.0166824975215906e-05 valid_loss:2.9749397072009742e-05\n",
            "epoch:175 train_loss:1.578635950257497e-05 valid_loss:1.8388407170277787e-05\n",
            "epoch:176 train_loss:1.8867101011387098e-05 valid_loss:2.130708207914722e-05\n",
            "epoch:177 train_loss:9.786039981918293e-06 valid_loss:1.68362598742533e-05\n",
            "epoch:178 train_loss:1.0565308457444189e-05 valid_loss:1.241040581589914e-05\n",
            "epoch:179 train_loss:6.712633522612224e-06 valid_loss:1.244861869054148e-05\n",
            "epoch:180 train_loss:9.031497383047179e-06 valid_loss:1.2729608215522603e-05\n",
            "epoch:181 train_loss:6.298691472592408e-06 valid_loss:1.7771197690308327e-05\n",
            "epoch:182 train_loss:6.6822696125099255e-06 valid_loss:1.0246332067254116e-05\n",
            "epoch:183 train_loss:7.114771000892182e-06 valid_loss:1.0779622925838339e-05\n",
            "epoch:184 train_loss:5.310782904012336e-06 valid_loss:9.84380858426448e-06\n",
            "epoch:185 train_loss:7.005104811873429e-06 valid_loss:7.355162779276725e-06\n",
            "save best model\n",
            "epoch:186 train_loss:7.831206365456941e-06 valid_loss:9.18962609830487e-06\n",
            "epoch:187 train_loss:4.8812174276867554e-06 valid_loss:1.341645656793844e-05\n",
            "epoch:188 train_loss:6.41710748065331e-06 valid_loss:1.6843926914589247e-05\n",
            "epoch:189 train_loss:1.3407553246401625e-05 valid_loss:1.3487212072504917e-05\n",
            "epoch:190 train_loss:1.6731836997981493e-05 valid_loss:1.1798540526797296e-05\n",
            "epoch:191 train_loss:1.5056790718719842e-05 valid_loss:2.8056495466444176e-05\n",
            "epoch:192 train_loss:1.7426523603110883e-05 valid_loss:4.2702639802882914e-05\n",
            "epoch:193 train_loss:3.494468023745867e-05 valid_loss:4.858269039687002e-05\n",
            "epoch:194 train_loss:6.251794032626397e-05 valid_loss:3.375251344550634e-05\n",
            "epoch:195 train_loss:7.696068769291742e-05 valid_loss:3.116835569016985e-05\n",
            "epoch:196 train_loss:5.4229837537099636e-05 valid_loss:9.253777170670219e-05\n",
            "epoch:197 train_loss:5.228495001574629e-05 valid_loss:0.00016245853112195618\n",
            "epoch:198 train_loss:0.00010064102914637058 valid_loss:0.00015605094813508913\n",
            "epoch:199 train_loss:0.00019240162772702106 valid_loss:9.781110202311538e-05\n",
            "epoch:200 train_loss:0.0004373879004965096 valid_loss:0.0013708687329199165\n",
            "epoch:201 train_loss:0.0005553952877461496 valid_loss:0.00020329646940808743\n",
            "epoch:202 train_loss:0.0003159134163676451 valid_loss:0.00022752139921067283\n",
            "epoch:203 train_loss:0.00021225790927322427 valid_loss:0.0005028011073591188\n",
            "epoch:204 train_loss:0.00022786347087983612 valid_loss:0.0001767144276527688\n",
            "epoch:205 train_loss:6.246343430878672e-05 valid_loss:4.460364198166644e-05\n",
            "epoch:206 train_loss:3.2595987350861025e-05 valid_loss:2.6649521714716684e-05\n",
            "epoch:207 train_loss:1.5197307473297567e-05 valid_loss:2.2105497919255868e-05\n",
            "epoch:208 train_loss:1.3326297979195564e-05 valid_loss:1.7352771465084516e-05\n",
            "epoch:209 train_loss:1.080150880423187e-05 valid_loss:2.4153080175892683e-05\n",
            "epoch:210 train_loss:8.598180392659237e-06 valid_loss:1.488638167757017e-05\n",
            "epoch:211 train_loss:8.637268036990361e-06 valid_loss:2.1246115466055926e-05\n",
            "epoch:212 train_loss:7.154016859405803e-06 valid_loss:1.6471602975798305e-05\n",
            "epoch:213 train_loss:8.595048749763615e-06 valid_loss:1.9869270090566715e-05\n",
            "epoch:214 train_loss:5.683769662330936e-06 valid_loss:1.663443686084065e-05\n",
            "epoch:215 train_loss:6.32363848277843e-06 valid_loss:1.651972092986398e-05\n",
            "epoch:216 train_loss:5.4432718772861536e-06 valid_loss:1.3239342933957232e-05\n",
            "epoch:217 train_loss:5.490742315335713e-06 valid_loss:1.5625747437297832e-05\n",
            "epoch:218 train_loss:4.5558774799145694e-06 valid_loss:1.2626730949705234e-05\n",
            "epoch:219 train_loss:4.634603113926359e-06 valid_loss:1.2770693956554169e-05\n",
            "epoch:220 train_loss:4.233105174636067e-06 valid_loss:1.1049865861423314e-05\n",
            "epoch:221 train_loss:4.065530718990986e-06 valid_loss:1.1987553989456501e-05\n",
            "epoch:222 train_loss:3.676483901118546e-06 valid_loss:1.0311846153854276e-05\n",
            "epoch:223 train_loss:3.468994514656111e-06 valid_loss:1.029591703627375e-05\n",
            "epoch:224 train_loss:3.4157126896793166e-06 valid_loss:9.544147587803309e-06\n",
            "epoch:225 train_loss:3.232842791097331e-06 valid_loss:9.158263310382608e-06\n",
            "epoch:226 train_loss:3.102622609200504e-06 valid_loss:9.140100246440852e-06\n",
            "epoch:227 train_loss:2.9116423863544897e-06 valid_loss:9.262397952625179e-06\n",
            "epoch:228 train_loss:2.8209484147131056e-06 valid_loss:9.507639333605766e-06\n",
            "epoch:229 train_loss:2.789009771378106e-06 valid_loss:9.586619853507727e-06\n",
            "epoch:230 train_loss:2.6823410621545918e-06 valid_loss:8.11901327324449e-06\n",
            "epoch:231 train_loss:2.6120097010738796e-06 valid_loss:7.207181170088006e-06\n",
            "save best model\n",
            "epoch:232 train_loss:2.791193180782001e-06 valid_loss:6.8340902998897946e-06\n",
            "save best model\n",
            "epoch:233 train_loss:3.1867263411792615e-06 valid_loss:6.268153015298594e-06\n",
            "save best model\n",
            "epoch:234 train_loss:4.417021778459053e-06 valid_loss:7.507591817557113e-06\n",
            "epoch:235 train_loss:3.6601778864072307e-06 valid_loss:7.650956604265957e-06\n",
            "epoch:236 train_loss:2.80152516691285e-06 valid_loss:7.459545486199204e-06\n",
            "epoch:237 train_loss:2.694281975992554e-06 valid_loss:9.41591565606359e-06\n",
            "epoch:238 train_loss:2.8626681809227093e-06 valid_loss:1.3367060091695748e-05\n",
            "epoch:239 train_loss:3.8292371047848265e-06 valid_loss:1.811843185350881e-05\n",
            "epoch:240 train_loss:6.401746418305265e-06 valid_loss:2.5428821572859306e-05\n",
            "epoch:241 train_loss:1.0411411835775652e-05 valid_loss:2.8934959118487313e-05\n",
            "epoch:242 train_loss:1.4409222608770102e-05 valid_loss:2.6730840545496903e-05\n",
            "epoch:243 train_loss:1.706984168473961e-05 valid_loss:2.156583832402248e-05\n",
            "epoch:244 train_loss:1.905348752491894e-05 valid_loss:1.987968562389142e-05\n",
            "epoch:245 train_loss:2.415181994466467e-05 valid_loss:1.7446895071770996e-05\n",
            "epoch:246 train_loss:2.7834835944102248e-05 valid_loss:2.761494579317514e-05\n",
            "epoch:247 train_loss:3.0694967361139585e-05 valid_loss:6.115189353295136e-05\n",
            "epoch:248 train_loss:3.766797175962388e-05 valid_loss:0.00013076883988105692\n",
            "epoch:249 train_loss:7.556522096921172e-05 valid_loss:0.000269992247922346\n",
            "epoch:250 train_loss:0.0001837041738528771 valid_loss:0.00021378470410127193\n",
            "epoch:251 train_loss:0.0002477115501985989 valid_loss:7.114358959370293e-05\n",
            "epoch:252 train_loss:0.00012804426205548225 valid_loss:0.00023411450092680752\n",
            "epoch:253 train_loss:0.00014774381432087265 valid_loss:5.5321967010968365e-05\n",
            "epoch:254 train_loss:5.9111469656474786e-05 valid_loss:4.44509541921434e-05\n",
            "epoch:255 train_loss:2.5643848807198487e-05 valid_loss:2.0214650248817634e-05\n",
            "epoch:256 train_loss:1.0683640564618852e-05 valid_loss:1.3495711755240336e-05\n",
            "epoch:257 train_loss:6.492411052426582e-06 valid_loss:7.681072020204738e-06\n",
            "epoch:258 train_loss:4.785101212847722e-06 valid_loss:8.12979828879179e-06\n",
            "epoch:259 train_loss:3.130038231170652e-06 valid_loss:5.051876541983802e-06\n",
            "save best model\n",
            "epoch:260 train_loss:2.7036933955868235e-06 valid_loss:5.182198037800845e-06\n",
            "epoch:261 train_loss:2.6142210711239186e-06 valid_loss:4.4133870460427715e-06\n",
            "save best model\n",
            "epoch:262 train_loss:2.5499208567857245e-06 valid_loss:4.298330395613448e-06\n",
            "save best model\n",
            "epoch:263 train_loss:2.2359245311539175e-06 valid_loss:4.218358355956298e-06\n",
            "save best model\n",
            "epoch:264 train_loss:2.0289498050058482e-06 valid_loss:3.949965901028918e-06\n",
            "save best model\n",
            "epoch:265 train_loss:1.990447022611382e-06 valid_loss:3.843276545012486e-06\n",
            "save best model\n",
            "epoch:266 train_loss:2.1445625388120484e-06 valid_loss:3.7392431977423257e-06\n",
            "save best model\n",
            "epoch:267 train_loss:2.162425478976123e-06 valid_loss:3.5672812259690545e-06\n",
            "save best model\n",
            "epoch:268 train_loss:2.0448455207618585e-06 valid_loss:4.037048199734272e-06\n",
            "epoch:269 train_loss:1.898873196953193e-06 valid_loss:3.852217844269035e-06\n",
            "epoch:270 train_loss:1.7775555281534455e-06 valid_loss:3.616975334352901e-06\n",
            "epoch:271 train_loss:1.664057524269285e-06 valid_loss:3.5846186960952764e-06\n",
            "epoch:272 train_loss:1.7442291380120878e-06 valid_loss:3.3410400419597863e-06\n",
            "save best model\n",
            "epoch:273 train_loss:1.98766390882257e-06 valid_loss:3.268099533215718e-06\n",
            "save best model\n",
            "epoch:274 train_loss:2.3809699219630906e-06 valid_loss:3.632386437857349e-06\n",
            "epoch:275 train_loss:2.6771298533074314e-06 valid_loss:3.4920680036520935e-06\n",
            "epoch:276 train_loss:2.600140880480871e-06 valid_loss:3.6304174955148483e-06\n",
            "epoch:277 train_loss:2.342944463230702e-06 valid_loss:3.8925745684537105e-06\n",
            "epoch:278 train_loss:2.0074653264146036e-06 valid_loss:4.5145438889449e-06\n",
            "epoch:279 train_loss:1.902703262304486e-06 valid_loss:5.159724878467387e-06\n",
            "epoch:280 train_loss:2.0792526116666622e-06 valid_loss:6.565509806932823e-06\n",
            "epoch:281 train_loss:2.5773244342670096e-06 valid_loss:6.133407509878452e-06\n",
            "epoch:282 train_loss:2.7859170346447272e-06 valid_loss:6.393844728336262e-06\n",
            "epoch:283 train_loss:3.331052943798972e-06 valid_loss:6.543495715050085e-06\n",
            "epoch:284 train_loss:3.837614555221889e-06 valid_loss:6.796352408855455e-06\n",
            "epoch:285 train_loss:4.328472483747545e-06 valid_loss:6.943081643839832e-06\n",
            "epoch:286 train_loss:4.70639702775265e-06 valid_loss:7.331648021136061e-06\n",
            "epoch:287 train_loss:5.171561952010961e-06 valid_loss:7.725163641225663e-06\n",
            "epoch:288 train_loss:5.568364574375866e-06 valid_loss:8.3766033185384e-06\n",
            "epoch:289 train_loss:6.121421007618564e-06 valid_loss:8.915829312172718e-06\n",
            "epoch:290 train_loss:6.418256980901384e-06 valid_loss:9.787605222300044e-06\n",
            "epoch:291 train_loss:6.65037784604768e-06 valid_loss:9.46944874158362e-06\n",
            "epoch:292 train_loss:6.631508218409484e-06 valid_loss:9.92488980955386e-06\n",
            "epoch:293 train_loss:6.885472733605032e-06 valid_loss:1.0095944162458181e-05\n",
            "epoch:294 train_loss:6.933261943231628e-06 valid_loss:1.023915706355183e-05\n",
            "epoch:295 train_loss:7.06917661672277e-06 valid_loss:1.0060953854917898e-05\n",
            "epoch:296 train_loss:6.83051234773302e-06 valid_loss:1.0590735882942681e-05\n",
            "epoch:297 train_loss:7.38373114472779e-06 valid_loss:9.883282245937153e-06\n",
            "epoch:298 train_loss:6.931215138037159e-06 valid_loss:1.0525681773287943e-05\n",
            "epoch:299 train_loss:6.9140477307882975e-06 valid_loss:1.0559694146650145e-05\n",
            "epoch:300 train_loss:6.983218011353327e-06 valid_loss:1.0846826626220718e-05\n",
            "epoch:301 train_loss:6.981091650636194e-06 valid_loss:1.0535323553995113e-05\n",
            "epoch:302 train_loss:6.572166234440778e-06 valid_loss:1.256513155567518e-05\n",
            "epoch:303 train_loss:7.218259447149143e-06 valid_loss:1.1973530263276189e-05\n",
            "epoch:304 train_loss:6.930100981763745e-06 valid_loss:1.2549568282338441e-05\n",
            "epoch:305 train_loss:7.40018667026258e-06 valid_loss:1.366206652164692e-05\n",
            "epoch:306 train_loss:7.3088953437642585e-06 valid_loss:1.4424255823541898e-05\n",
            "epoch:307 train_loss:7.742561314848394e-06 valid_loss:1.5081965557328658e-05\n",
            "epoch:308 train_loss:8.388152688591314e-06 valid_loss:1.4525584447255824e-05\n",
            "epoch:309 train_loss:7.717566000388211e-06 valid_loss:1.779605963747599e-05\n",
            "epoch:310 train_loss:8.454845619275551e-06 valid_loss:1.7521995687275194e-05\n",
            "epoch:311 train_loss:9.4457777019367e-06 valid_loss:1.5424700222865795e-05\n",
            "epoch:312 train_loss:7.88955907814347e-06 valid_loss:2.119802002198412e-05\n",
            "epoch:313 train_loss:8.779603326224282e-06 valid_loss:2.0913292701152386e-05\n",
            "epoch:314 train_loss:9.393445402060428e-06 valid_loss:1.7995580037677428e-05\n",
            "epoch:315 train_loss:8.74679412592943e-06 valid_loss:2.0992913960071746e-05\n",
            "epoch:316 train_loss:8.7384154691487e-06 valid_loss:2.2441911369242007e-05\n",
            "epoch:317 train_loss:8.625282791601623e-06 valid_loss:2.583228570074425e-05\n",
            "epoch:318 train_loss:9.18945014897569e-06 valid_loss:2.085423921016627e-05\n",
            "epoch:319 train_loss:9.455501488749482e-06 valid_loss:2.290220345457783e-05\n",
            "epoch:320 train_loss:9.75576492439561e-06 valid_loss:2.592960481706541e-05\n",
            "epoch:321 train_loss:9.924837159916125e-06 valid_loss:3.3480473121016985e-05\n",
            "epoch:322 train_loss:1.1136938282005656e-05 valid_loss:2.202892028435599e-05\n",
            "epoch:323 train_loss:1.2817689619421597e-05 valid_loss:2.3656054054299602e-05\n",
            "epoch:324 train_loss:1.4772859306807126e-05 valid_loss:1.8719531453825766e-05\n",
            "epoch:325 train_loss:1.8237065205539693e-05 valid_loss:5.600407803285634e-05\n",
            "epoch:326 train_loss:1.79974883091442e-05 valid_loss:4.0284010538016446e-05\n",
            "epoch:327 train_loss:2.001129612633829e-05 valid_loss:6.908995601406787e-05\n",
            "epoch:328 train_loss:3.1304373401831574e-05 valid_loss:7.26637736079283e-05\n",
            "epoch:329 train_loss:7.514213828269728e-05 valid_loss:0.00013929803390055895\n",
            "epoch:330 train_loss:0.00010303716397983307 valid_loss:0.00024191087868530303\n",
            "epoch:331 train_loss:0.00011795917635026854 valid_loss:8.358329432667233e-05\n",
            "epoch:332 train_loss:0.00013663323766700664 valid_loss:0.00025848790392046794\n",
            "epoch:333 train_loss:9.964072018596603e-05 valid_loss:0.00012679045903496444\n",
            "epoch:334 train_loss:0.0001144900844438881 valid_loss:0.00010864831347134896\n",
            "epoch:335 train_loss:6.59802930790142e-05 valid_loss:4.203591925033834e-05\n",
            "epoch:336 train_loss:3.810398852187468e-05 valid_loss:4.027317481813952e-05\n",
            "epoch:337 train_loss:2.5110742727621175e-05 valid_loss:5.159722422831692e-05\n",
            "epoch:338 train_loss:1.4989008781817069e-05 valid_loss:3.468852810328826e-05\n",
            "epoch:339 train_loss:2.219935297236791e-05 valid_loss:3.7129470001673326e-05\n",
            "epoch:340 train_loss:1.9434756571475493e-05 valid_loss:1.6444927041447954e-05\n",
            "epoch:341 train_loss:1.2490963146976557e-05 valid_loss:1.5178322883002693e-05\n",
            "epoch:342 train_loss:9.857006059771973e-06 valid_loss:9.943883924279362e-06\n",
            "epoch:343 train_loss:9.430954997292752e-06 valid_loss:1.1459684856163221e-05\n",
            "epoch:344 train_loss:7.270201978018223e-06 valid_loss:1.1496921388243209e-05\n",
            "epoch:345 train_loss:5.8114093361736095e-06 valid_loss:1.342765267509094e-05\n",
            "epoch:346 train_loss:5.449202098538484e-06 valid_loss:1.551952118461486e-05\n",
            "epoch:347 train_loss:5.287047176554754e-06 valid_loss:1.6062989743659273e-05\n",
            "epoch:348 train_loss:6.649673612931413e-06 valid_loss:1.784416190275806e-05\n",
            "epoch:349 train_loss:7.591909176577853e-06 valid_loss:1.5497184449486667e-05\n",
            "epoch:350 train_loss:7.089155625787195e-06 valid_loss:1.1673189192151767e-05\n",
            "epoch:351 train_loss:7.285719612405552e-06 valid_loss:1.0074037163576577e-05\n",
            "epoch:352 train_loss:7.23781076633006e-06 valid_loss:1.3098998124405625e-05\n",
            "epoch:353 train_loss:6.67407490103263e-06 valid_loss:8.829987336866907e-06\n",
            "epoch:354 train_loss:6.228830165532094e-06 valid_loss:6.750177590220119e-06\n",
            "epoch:355 train_loss:5.83448809265974e-06 valid_loss:7.269284651556518e-06\n",
            "epoch:356 train_loss:5.638349471660655e-06 valid_loss:8.208843610191252e-06\n",
            "epoch:357 train_loss:6.491884088670001e-06 valid_loss:1.0772535688374774e-05\n",
            "epoch:358 train_loss:9.102506889272869e-06 valid_loss:1.314793939855008e-05\n",
            "epoch:359 train_loss:1.0617162982069001e-05 valid_loss:2.0443128050828818e-05\n",
            "epoch:360 train_loss:1.027653337991473e-05 valid_loss:2.820097643052577e-05\n",
            "epoch:361 train_loss:8.820474224396296e-06 valid_loss:2.0963084352842998e-05\n",
            "epoch:362 train_loss:6.969173985756545e-06 valid_loss:1.7935107734956546e-05\n",
            "epoch:363 train_loss:6.086636315356171e-06 valid_loss:2.1820807887706906e-05\n",
            "epoch:364 train_loss:7.258904070618479e-06 valid_loss:2.103227188854362e-05\n",
            "epoch:365 train_loss:8.842234516729755e-06 valid_loss:2.1009908778069075e-05\n",
            "epoch:366 train_loss:1.0571505842765166e-05 valid_loss:3.263283724663779e-05\n",
            "epoch:367 train_loss:1.3589868558483431e-05 valid_loss:6.88732361595612e-05\n",
            "epoch:368 train_loss:2.0758350526901064e-05 valid_loss:5.817423698317725e-05\n",
            "epoch:369 train_loss:3.2763363884037564e-05 valid_loss:4.310342592361849e-05\n",
            "epoch:370 train_loss:2.804618558608733e-05 valid_loss:0.00013709619088331237\n",
            "epoch:371 train_loss:4.025675146597981e-05 valid_loss:0.00012582156341522932\n",
            "epoch:372 train_loss:3.60151398126618e-05 valid_loss:5.0412133532518055e-05\n",
            "epoch:373 train_loss:3.189565915009654e-05 valid_loss:6.837270120740868e-05\n",
            "epoch:374 train_loss:3.513158430400331e-05 valid_loss:3.542446665960597e-05\n",
            "epoch:375 train_loss:5.381445195477378e-05 valid_loss:0.0002401173915131949\n",
            "epoch:376 train_loss:6.828343738460616e-05 valid_loss:2.853208570741117e-05\n",
            "epoch:377 train_loss:3.8678845359956744e-05 valid_loss:0.00011621991143329069\n",
            "epoch:378 train_loss:3.6190691237910265e-05 valid_loss:6.220977957127616e-05\n",
            "epoch:379 train_loss:3.1824007186919014e-05 valid_loss:2.361574706810643e-05\n",
            "epoch:380 train_loss:2.549901607077724e-05 valid_loss:3.6248111427994445e-05\n",
            "epoch:381 train_loss:1.2575940900205751e-05 valid_loss:1.4009127880854066e-05\n",
            "epoch:382 train_loss:9.741880982498211e-06 valid_loss:2.6428088858665433e-05\n",
            "epoch:383 train_loss:1.3977803847511597e-05 valid_loss:1.8108242784364847e-05\n",
            "epoch:384 train_loss:1.4300517856706088e-05 valid_loss:1.4631742487836163e-05\n",
            "epoch:385 train_loss:9.462651910831079e-06 valid_loss:9.044071930475184e-06\n",
            "epoch:386 train_loss:7.432615423870932e-06 valid_loss:9.170470320896129e-06\n",
            "epoch:387 train_loss:8.797801835195665e-06 valid_loss:8.179452834156109e-06\n",
            "epoch:388 train_loss:1.1717066298741782e-05 valid_loss:2.2949540834815707e-05\n",
            "epoch:389 train_loss:1.0916824319590685e-05 valid_loss:3.501942137518199e-05\n",
            "epoch:390 train_loss:9.790615371861753e-06 valid_loss:2.6017180971393827e-05\n",
            "epoch:391 train_loss:1.2314728691207063e-05 valid_loss:0.0001296923255722504\n",
            "epoch:392 train_loss:0.0001281969421648278 valid_loss:0.0003103401613770984\n",
            "epoch:393 train_loss:0.0001986516799661331 valid_loss:0.00030272770527517423\n",
            "epoch:394 train_loss:0.00014805077727133822 valid_loss:0.00015453701053047553\n",
            "epoch:395 train_loss:0.000118656735543886 valid_loss:0.00030400473769987\n",
            "epoch:396 train_loss:7.187105792480806e-05 valid_loss:5.116049032949377e-05\n",
            "epoch:397 train_loss:3.2601498181369e-05 valid_loss:2.1897463739151135e-05\n",
            "epoch:398 train_loss:2.947695394242247e-05 valid_loss:3.7262000660120975e-05\n",
            "epoch:399 train_loss:1.4000051932170107e-05 valid_loss:3.4695623980951495e-05\n",
            "epoch:400 train_loss:1.5807027542299085e-05 valid_loss:2.381556669206475e-05\n",
            "epoch:401 train_loss:1.0455317124069552e-05 valid_loss:1.9687184703798266e-05\n",
            "epoch:402 train_loss:7.376616395049496e-06 valid_loss:1.5663688827771693e-05\n",
            "epoch:403 train_loss:7.5520832625544344e-06 valid_loss:1.8571155123936478e-05\n",
            "epoch:404 train_loss:8.307760102373626e-06 valid_loss:3.233734423702117e-05\n",
            "epoch:405 train_loss:8.338965787718027e-06 valid_loss:2.3709197193966247e-05\n",
            "epoch:406 train_loss:7.955730577830562e-06 valid_loss:2.1120427390997065e-05\n",
            "epoch:407 train_loss:7.473361708636932e-06 valid_loss:2.055185177596286e-05\n",
            "epoch:408 train_loss:7.487193405116462e-06 valid_loss:2.3094583866622997e-05\n",
            "epoch:409 train_loss:7.473424299557034e-06 valid_loss:2.3777074147801613e-05\n",
            "epoch:410 train_loss:7.48838580319797e-06 valid_loss:2.3046976366458694e-05\n",
            "epoch:411 train_loss:7.657719316335311e-06 valid_loss:2.2522430754179368e-05\n",
            "epoch:412 train_loss:7.357869107080559e-06 valid_loss:1.923993568198057e-05\n",
            "epoch:413 train_loss:7.592731549266318e-06 valid_loss:2.118936617989675e-05\n",
            "epoch:414 train_loss:7.390728620117039e-06 valid_loss:1.810780258892919e-05\n",
            "epoch:415 train_loss:7.4491748086479165e-06 valid_loss:1.9733834051294252e-05\n",
            "epoch:416 train_loss:7.524377401245551e-06 valid_loss:1.9891225292667514e-05\n",
            "epoch:417 train_loss:7.319701113475377e-06 valid_loss:1.800697509679594e-05\n",
            "epoch:418 train_loss:7.283987479746025e-06 valid_loss:1.7320462575298734e-05\n",
            "epoch:419 train_loss:6.942012217021127e-06 valid_loss:1.661618216530769e-05\n",
            "epoch:420 train_loss:7.4277519135850726e-06 valid_loss:1.7091248537326464e-05\n",
            "epoch:421 train_loss:6.714391651661976e-06 valid_loss:1.7124824353231816e-05\n",
            "epoch:422 train_loss:6.924606989539623e-06 valid_loss:1.597257414687192e-05\n",
            "epoch:423 train_loss:6.931208657887409e-06 valid_loss:1.5672422932766494e-05\n",
            "epoch:424 train_loss:6.590044790755201e-06 valid_loss:1.528204597889271e-05\n",
            "epoch:425 train_loss:6.433930606261937e-06 valid_loss:1.6424749901489122e-05\n",
            "epoch:426 train_loss:7.097981716065584e-06 valid_loss:1.7663370272202883e-05\n",
            "epoch:427 train_loss:6.90421738151296e-06 valid_loss:1.6561051324970322e-05\n",
            "epoch:428 train_loss:7.062140058325086e-06 valid_loss:1.7909739199239993e-05\n",
            "epoch:429 train_loss:7.096763372121333e-06 valid_loss:1.742694757922436e-05\n",
            "epoch:430 train_loss:7.589692346401635e-06 valid_loss:1.760795112204505e-05\n",
            "epoch:431 train_loss:8.27926623969688e-06 valid_loss:1.5244833321048645e-05\n",
            "epoch:432 train_loss:7.926148302633212e-06 valid_loss:1.1794549664045917e-05\n",
            "epoch:433 train_loss:7.110821671732184e-06 valid_loss:1.1341873914716416e-05\n",
            "epoch:434 train_loss:6.455992396089035e-06 valid_loss:1.7268517694901675e-05\n",
            "epoch:435 train_loss:1.0000867550590758e-05 valid_loss:1.8696240658755414e-05\n",
            "epoch:436 train_loss:1.476988028217521e-05 valid_loss:1.896552157631959e-05\n",
            "epoch:437 train_loss:2.337967154946657e-05 valid_loss:2.2767889277020004e-05\n",
            "epoch:438 train_loss:2.9900216102558057e-05 valid_loss:3.672937964438461e-05\n",
            "epoch:439 train_loss:2.781776720439666e-05 valid_loss:4.220801201881841e-05\n",
            "epoch:440 train_loss:2.7454529319786365e-05 valid_loss:6.398390905815177e-05\n",
            "epoch:441 train_loss:2.881176139150436e-05 valid_loss:0.00014594383901567198\n",
            "epoch:442 train_loss:6.775712922212228e-05 valid_loss:0.00013013076386414468\n",
            "epoch:443 train_loss:8.197772523191007e-05 valid_loss:0.00014093386926106177\n",
            "epoch:444 train_loss:6.751638789460735e-05 valid_loss:4.94170071760891e-05\n",
            "epoch:445 train_loss:2.9988311830998606e-05 valid_loss:2.1366384771681624e-05\n",
            "epoch:446 train_loss:1.7422895072943196e-05 valid_loss:1.0744693554443074e-05\n",
            "epoch:447 train_loss:9.765458015762204e-06 valid_loss:1.1377975170034915e-05\n",
            "epoch:448 train_loss:5.321413810735167e-06 valid_loss:1.3302080560606555e-05\n",
            "epoch:449 train_loss:6.194793109494236e-06 valid_loss:9.349000492875348e-06\n",
            "epoch:450 train_loss:5.367905815647747e-06 valid_loss:6.795662102376809e-06\n",
            "epoch:451 train_loss:4.2198060883593926e-06 valid_loss:5.9150005427e-06\n",
            "epoch:452 train_loss:5.209660533485779e-06 valid_loss:6.680908768430527e-06\n",
            "epoch:453 train_loss:4.577167146635475e-06 valid_loss:7.588992502860492e-06\n",
            "epoch:454 train_loss:3.999812457146214e-06 valid_loss:8.949988568929257e-06\n",
            "epoch:455 train_loss:3.614557404792625e-06 valid_loss:9.598932138032978e-06\n",
            "epoch:456 train_loss:4.0812247511389105e-06 valid_loss:9.172433465209906e-06\n",
            "epoch:457 train_loss:4.338010095731685e-06 valid_loss:7.830284857845982e-06\n",
            "epoch:458 train_loss:4.094819271611212e-06 valid_loss:6.370511187014927e-06\n",
            "epoch:459 train_loss:4.028445055660592e-06 valid_loss:5.2772873004869325e-06\n",
            "epoch:460 train_loss:3.994762702556424e-06 valid_loss:5.438238531496609e-06\n",
            "epoch:461 train_loss:4.825599413986008e-06 valid_loss:5.987298209220171e-06\n",
            "epoch:462 train_loss:5.799518179274956e-06 valid_loss:6.753426760042203e-06\n",
            "epoch:463 train_loss:5.7984354700440436e-06 valid_loss:7.595274155391962e-06\n",
            "epoch:464 train_loss:5.236013243524616e-06 valid_loss:9.51614129007794e-06\n",
            "epoch:465 train_loss:4.62723461522627e-06 valid_loss:1.046335978571733e-05\n",
            "epoch:466 train_loss:4.938314203981362e-06 valid_loss:1.5301179246307584e-05\n",
            "epoch:467 train_loss:7.368523774352474e-06 valid_loss:1.722551178318099e-05\n",
            "epoch:468 train_loss:1.1274121410072743e-05 valid_loss:2.3188342311186716e-05\n",
            "epoch:469 train_loss:1.9896516025457662e-05 valid_loss:6.637082697125152e-05\n",
            "epoch:470 train_loss:3.904405396800333e-05 valid_loss:5.1086566600133665e-05\n",
            "epoch:471 train_loss:3.5142146367029957e-05 valid_loss:8.197028000722639e-05\n",
            "epoch:472 train_loss:4.396035976444384e-05 valid_loss:5.5019430874381214e-05\n",
            "epoch:473 train_loss:2.822082488920488e-05 valid_loss:4.495585926633794e-05\n",
            "epoch:474 train_loss:2.7780275559052825e-05 valid_loss:5.889751082577277e-05\n",
            "epoch:475 train_loss:6.371999198664626e-05 valid_loss:0.00022084044394432567\n",
            "epoch:476 train_loss:0.00010974428753090453 valid_loss:8.987963519757614e-05\n",
            "epoch:477 train_loss:5.7498127716826275e-05 valid_loss:0.00011932218330912292\n",
            "epoch:478 train_loss:4.062769746977008e-05 valid_loss:4.516957324085524e-05\n",
            "epoch:479 train_loss:3.249231111921189e-05 valid_loss:2.2044035631552106e-05\n",
            "epoch:480 train_loss:1.1412392773814241e-05 valid_loss:1.2355783155726385e-05\n",
            "epoch:481 train_loss:6.2695752629022336e-06 valid_loss:5.911102562095039e-06\n",
            "epoch:482 train_loss:4.118146737002664e-06 valid_loss:4.606831907949527e-06\n",
            "epoch:483 train_loss:2.862511296244621e-06 valid_loss:4.845101784667349e-06\n",
            "epoch:484 train_loss:2.7719545793540115e-06 valid_loss:3.754233603103785e-06\n",
            "epoch:485 train_loss:2.2354388420353644e-06 valid_loss:3.6300735928307404e-06\n",
            "epoch:486 train_loss:1.9988762384552197e-06 valid_loss:3.577525319542474e-06\n",
            "epoch:487 train_loss:1.998138126661312e-06 valid_loss:3.6173108810544363e-06\n",
            "epoch:488 train_loss:2.1082867773556145e-06 valid_loss:3.879824589603231e-06\n",
            "epoch:489 train_loss:2.1093440207348776e-06 valid_loss:4.171559623955545e-06\n",
            "epoch:490 train_loss:1.917177014673952e-06 valid_loss:3.3040581683962955e-06\n",
            "epoch:491 train_loss:1.7374847295236073e-06 valid_loss:2.999152172833419e-06\n",
            "save best model\n",
            "epoch:492 train_loss:1.8859354390264748e-06 valid_loss:3.238720239551185e-06\n",
            "epoch:493 train_loss:2.284700801485289e-06 valid_loss:3.667356452297099e-06\n",
            "epoch:494 train_loss:2.657381679051064e-06 valid_loss:4.089613412361359e-06\n",
            "epoch:495 train_loss:2.839696725863582e-06 valid_loss:4.32655309623442e-06\n",
            "epoch:496 train_loss:2.769429455737635e-06 valid_loss:4.28383890493933e-06\n",
            "epoch:497 train_loss:2.484458008211732e-06 valid_loss:4.3265586668894684e-06\n",
            "epoch:498 train_loss:2.237076682515888e-06 valid_loss:4.720943252323195e-06\n",
            "epoch:499 train_loss:2.299637101385896e-06 valid_loss:5.820893079544476e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "hI_LVnSuDV9Q",
        "outputId": "3cbc16c5-e0ab-493f-b738-e4eb602062cd"
      },
      "source": [
        "part2.test()"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Condenser Duty</th>\n",
              "      <td>0.99997</td>\n",
              "      <td>5779.15</td>\n",
              "      <td>0.25491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reboiler Duty</th>\n",
              "      <td>0.999934</td>\n",
              "      <td>7487.57</td>\n",
              "      <td>1.45082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999952</td>\n",
              "      <td>6633.36</td>\n",
              "      <td>0.852863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      R2      MSE      MAPE\n",
              "0                                          \n",
              "Condenser Duty   0.99997  5779.15   0.25491\n",
              "Reboiler Duty   0.999934  7487.57   1.45082\n",
              "AVG             0.999952  6633.36  0.852863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4lmrQEKWDUw"
      },
      "source": [
        "# Part 3：預測操作條件(temp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhGTtrR7TfML",
        "outputId": "09b44b45-a235-4ac9-c54c-317b09a80d01"
      },
      "source": [
        "part3 = part(df,x_col,df.columns[[10,14]])\n",
        "part3.train()"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.04348126485840314 valid_loss:0.03231658227741718\n",
            "save best model\n",
            "epoch:1 train_loss:0.00984770212865745 valid_loss:0.011238415958359838\n",
            "save best model\n",
            "epoch:2 train_loss:0.010271703779128276 valid_loss:0.015181856928393245\n",
            "epoch:3 train_loss:0.005565982978118377 valid_loss:0.00777910026954487\n",
            "save best model\n",
            "epoch:4 train_loss:0.004475884230083061 valid_loss:0.007220234663691372\n",
            "save best model\n",
            "epoch:5 train_loss:0.005950257589574903 valid_loss:0.011524595902301371\n",
            "epoch:6 train_loss:0.004624112525359831 valid_loss:0.006045385845936835\n",
            "save best model\n",
            "epoch:7 train_loss:0.004316484769030164 valid_loss:0.004707692482043058\n",
            "save best model\n",
            "epoch:8 train_loss:0.0034891378244436863 valid_loss:0.005867962958291173\n",
            "epoch:9 train_loss:0.0028869090165244415 valid_loss:0.004472822358366102\n",
            "save best model\n",
            "epoch:10 train_loss:0.0026382624281622055 valid_loss:0.0046858978748787194\n",
            "epoch:11 train_loss:0.0025854513159073475 valid_loss:0.0044030751450918615\n",
            "save best model\n",
            "epoch:12 train_loss:0.002516663578313051 valid_loss:0.0037329566839616746\n",
            "save best model\n",
            "epoch:13 train_loss:0.002378092952211672 valid_loss:0.0034329136251471937\n",
            "save best model\n",
            "epoch:14 train_loss:0.0022489870815560506 valid_loss:0.003449683092185296\n",
            "epoch:15 train_loss:0.002285279895861297 valid_loss:0.0035445313260424882\n",
            "epoch:16 train_loss:0.002308681388159231 valid_loss:0.0037394014070741832\n",
            "epoch:17 train_loss:0.00236520190325488 valid_loss:0.00355051172664389\n",
            "epoch:18 train_loss:0.002314747290963876 valid_loss:0.003366241668118164\n",
            "save best model\n",
            "epoch:19 train_loss:0.0022895957525987695 valid_loss:0.0033924870658665895\n",
            "epoch:20 train_loss:0.00235899509081921 valid_loss:0.00374399172142148\n",
            "epoch:21 train_loss:0.002847837518654867 valid_loss:0.0038361686456482857\n",
            "epoch:22 train_loss:0.00254879318526946 valid_loss:0.003978145658038557\n",
            "epoch:23 train_loss:0.002455715140159656 valid_loss:0.003546732070390135\n",
            "epoch:24 train_loss:0.0023844619944510567 valid_loss:0.0035196992685087025\n",
            "epoch:25 train_loss:0.002322218173503643 valid_loss:0.00357570088817738\n",
            "epoch:26 train_loss:0.0022343372382036047 valid_loss:0.0034816864936146885\n",
            "epoch:27 train_loss:0.0022194712299905303 valid_loss:0.0034149703133152798\n",
            "epoch:28 train_loss:0.0022220872936789724 valid_loss:0.0033340502122882754\n",
            "save best model\n",
            "epoch:29 train_loss:0.002200877001491285 valid_loss:0.0033076967083616182\n",
            "save best model\n",
            "epoch:30 train_loss:0.0021752509366908474 valid_loss:0.0033044907759176567\n",
            "save best model\n",
            "epoch:31 train_loss:0.002162470683793395 valid_loss:0.0032985106663545594\n",
            "save best model\n",
            "epoch:32 train_loss:0.002156112978304413 valid_loss:0.0032897402852540836\n",
            "save best model\n",
            "epoch:33 train_loss:0.0021523504375282857 valid_loss:0.0032834401936270297\n",
            "save best model\n",
            "epoch:34 train_loss:0.002151088150033805 valid_loss:0.003278066753409803\n",
            "save best model\n",
            "epoch:35 train_loss:0.0021511360771708293 valid_loss:0.003276194867794402\n",
            "save best model\n",
            "epoch:36 train_loss:0.0021538077172509576 valid_loss:0.0032758077431935817\n",
            "save best model\n",
            "epoch:37 train_loss:0.002157784493950506 valid_loss:0.00327897300303448\n",
            "epoch:38 train_loss:0.0021684437033400172 valid_loss:0.00327681093767751\n",
            "epoch:39 train_loss:0.0021695846345311212 valid_loss:0.0032821242057252675\n",
            "epoch:40 train_loss:0.0021841522599667464 valid_loss:0.0032904533873079345\n",
            "epoch:41 train_loss:0.0021990822731620735 valid_loss:0.003302014112705365\n",
            "epoch:42 train_loss:0.002226509910138298 valid_loss:0.0033187289373017848\n",
            "epoch:43 train_loss:0.0022309573695464577 valid_loss:0.0033573606342542917\n",
            "epoch:44 train_loss:0.002260110254509426 valid_loss:0.003408704185858369\n",
            "epoch:45 train_loss:0.0022420462794090984 valid_loss:0.0034660918754525483\n",
            "epoch:46 train_loss:0.002230177603956286 valid_loss:0.003492090880172327\n",
            "epoch:47 train_loss:0.002224611855935008 valid_loss:0.003471402480499819\n",
            "epoch:48 train_loss:0.002237726494058734 valid_loss:0.00350938001065515\n",
            "epoch:49 train_loss:0.0016153219799485265 valid_loss:0.0012424073793226853\n",
            "save best model\n",
            "epoch:50 train_loss:0.0004918136227287403 valid_loss:0.0007205777801573277\n",
            "save best model\n",
            "epoch:51 train_loss:0.0005852092783445389 valid_loss:0.000662353661027737\n",
            "save best model\n",
            "epoch:52 train_loss:0.00032951029344177287 valid_loss:0.0005319679039530456\n",
            "save best model\n",
            "epoch:53 train_loss:0.0002422702180208742 valid_loss:0.0005457270162878558\n",
            "epoch:54 train_loss:0.00026864256061445404 valid_loss:0.0004997034338884987\n",
            "save best model\n",
            "epoch:55 train_loss:0.00023923437402117997 valid_loss:0.00033927337790373713\n",
            "save best model\n",
            "epoch:56 train_loss:0.00015681949440072963 valid_loss:0.0002958675322588533\n",
            "save best model\n",
            "epoch:57 train_loss:0.00012571232461292917 valid_loss:0.00029437531338771805\n",
            "save best model\n",
            "epoch:58 train_loss:0.00011042911541557664 valid_loss:0.0002927664463641122\n",
            "save best model\n",
            "epoch:59 train_loss:0.00010153740772188434 valid_loss:0.00027677605248754844\n",
            "save best model\n",
            "epoch:60 train_loss:9.730562497780839e-05 valid_loss:0.00026433332823216915\n",
            "save best model\n",
            "epoch:61 train_loss:9.312522848227268e-05 valid_loss:0.00025192004977725446\n",
            "save best model\n",
            "epoch:62 train_loss:8.875517970510473e-05 valid_loss:0.0002443216217216104\n",
            "save best model\n",
            "epoch:63 train_loss:8.454299141804868e-05 valid_loss:0.0002343702108191792\n",
            "save best model\n",
            "epoch:64 train_loss:8.019102026284802e-05 valid_loss:0.00021920864674029872\n",
            "save best model\n",
            "epoch:65 train_loss:7.398491531300048e-05 valid_loss:0.00019911451454390772\n",
            "save best model\n",
            "epoch:66 train_loss:6.732118809951417e-05 valid_loss:0.00017341500642942265\n",
            "save best model\n",
            "epoch:67 train_loss:5.919717871923543e-05 valid_loss:0.0001477662990509998\n",
            "save best model\n",
            "epoch:68 train_loss:5.1196047833299315e-05 valid_loss:0.00012306139433349017\n",
            "save best model\n",
            "epoch:69 train_loss:4.6512130615560134e-05 valid_loss:0.00010504892270546407\n",
            "save best model\n",
            "epoch:70 train_loss:3.518082500401457e-05 valid_loss:7.9516548794345e-05\n",
            "save best model\n",
            "epoch:71 train_loss:4.519628227070724e-05 valid_loss:0.00011451219324953854\n",
            "epoch:72 train_loss:6.272465210107232e-05 valid_loss:0.00011124562661279924\n",
            "epoch:73 train_loss:5.9427894585597744e-05 valid_loss:0.00017175834000227042\n",
            "epoch:74 train_loss:8.622830238083325e-05 valid_loss:7.73535284679383e-05\n",
            "save best model\n",
            "epoch:75 train_loss:9.330123814126839e-05 valid_loss:0.000123703881399706\n",
            "epoch:76 train_loss:0.00010308764548325498 valid_loss:0.00016214062998187728\n",
            "epoch:77 train_loss:9.433022013480595e-05 valid_loss:0.0001230091293109581\n",
            "epoch:78 train_loss:7.332110059602807e-05 valid_loss:7.058447408780921e-05\n",
            "save best model\n",
            "epoch:79 train_loss:8.194805680735347e-05 valid_loss:0.0001374314888380468\n",
            "epoch:80 train_loss:4.742000126296059e-05 valid_loss:8.202498247555923e-05\n",
            "epoch:81 train_loss:3.0036266606556535e-05 valid_loss:6.134165323601337e-05\n",
            "save best model\n",
            "epoch:82 train_loss:2.615395356365803e-05 valid_loss:4.1296354538644664e-05\n",
            "save best model\n",
            "epoch:83 train_loss:2.184879720819784e-05 valid_loss:4.001331308245426e-05\n",
            "save best model\n",
            "epoch:84 train_loss:2.1453202660066178e-05 valid_loss:3.926443969248794e-05\n",
            "save best model\n",
            "epoch:85 train_loss:2.2780261537668088e-05 valid_loss:5.719231012335513e-05\n",
            "epoch:86 train_loss:2.1362471645463505e-05 valid_loss:5.0739724429149646e-05\n",
            "epoch:87 train_loss:1.6705838776134544e-05 valid_loss:4.590109710989054e-05\n",
            "epoch:88 train_loss:1.5016056598445479e-05 valid_loss:3.112031936325366e-05\n",
            "save best model\n",
            "epoch:89 train_loss:1.3305237606194472e-05 valid_loss:3.0172502192726824e-05\n",
            "save best model\n",
            "epoch:90 train_loss:1.268709848368922e-05 valid_loss:3.0837522444926435e-05\n",
            "epoch:91 train_loss:1.2959509376742062e-05 valid_loss:3.263677081122296e-05\n",
            "epoch:92 train_loss:1.4181194147669077e-05 valid_loss:3.6329573958937544e-05\n",
            "epoch:93 train_loss:1.556714879471757e-05 valid_loss:4.006224844488315e-05\n",
            "epoch:94 train_loss:1.5628933296183175e-05 valid_loss:4.3596813156909775e-05\n",
            "epoch:95 train_loss:1.4670049621498845e-05 valid_loss:4.742649161926238e-05\n",
            "epoch:96 train_loss:1.3478790050511532e-05 valid_loss:4.7659084884799086e-05\n",
            "epoch:97 train_loss:1.2033393242442495e-05 valid_loss:4.5772789235343225e-05\n",
            "epoch:98 train_loss:1.141587010048776e-05 valid_loss:4.194745633867569e-05\n",
            "epoch:99 train_loss:1.1389690548134644e-05 valid_loss:3.9449791074730456e-05\n",
            "epoch:100 train_loss:1.2261095359159905e-05 valid_loss:3.82871730835177e-05\n",
            "epoch:101 train_loss:1.3144328022463014e-05 valid_loss:4.058921149407979e-05\n",
            "epoch:102 train_loss:1.3732292068703424e-05 valid_loss:4.1393854189664125e-05\n",
            "epoch:103 train_loss:1.472426828917782e-05 valid_loss:4.351019288151292e-05\n",
            "epoch:104 train_loss:1.5810642758474893e-05 valid_loss:4.5474777834897395e-05\n",
            "epoch:105 train_loss:1.7343098129963942e-05 valid_loss:4.666252516472014e-05\n",
            "epoch:106 train_loss:1.9037751776017507e-05 valid_loss:4.839829671254847e-05\n",
            "epoch:107 train_loss:2.195800473398574e-05 valid_loss:5.3945574109093286e-05\n",
            "epoch:108 train_loss:2.2411377383630475e-05 valid_loss:5.254551160760457e-05\n",
            "epoch:109 train_loss:2.6708700817026613e-05 valid_loss:5.556937867368106e-05\n",
            "epoch:110 train_loss:2.7737497930502286e-05 valid_loss:5.9024119764217176e-05\n",
            "epoch:111 train_loss:3.690254303971111e-05 valid_loss:6.222497177077457e-05\n",
            "epoch:112 train_loss:4.9551304982742295e-05 valid_loss:6.209977254911792e-05\n",
            "epoch:113 train_loss:7.414499214064563e-05 valid_loss:8.168809836206492e-05\n",
            "epoch:114 train_loss:5.3211375719304975e-05 valid_loss:0.00010899134213104844\n",
            "epoch:115 train_loss:7.656195985974692e-05 valid_loss:8.472944864479359e-05\n",
            "epoch:116 train_loss:6.953400285662308e-05 valid_loss:9.433350351173431e-05\n",
            "epoch:117 train_loss:6.583998846407566e-05 valid_loss:0.00016007110752980225\n",
            "epoch:118 train_loss:6.659535372616827e-05 valid_loss:0.00013615854913950898\n",
            "epoch:119 train_loss:6.362636860204575e-05 valid_loss:0.00010532517990213819\n",
            "epoch:120 train_loss:7.388006330681189e-05 valid_loss:0.00011319888653815724\n",
            "epoch:121 train_loss:6.996021521546127e-05 valid_loss:0.00010386086796643212\n",
            "epoch:122 train_loss:3.712681877409018e-05 valid_loss:4.8877122935664374e-05\n",
            "epoch:123 train_loss:2.910745997218732e-05 valid_loss:3.697094689414371e-05\n",
            "epoch:124 train_loss:2.7049842881549717e-05 valid_loss:4.584736052493099e-05\n",
            "epoch:125 train_loss:2.703979299035887e-05 valid_loss:3.8626954847131856e-05\n",
            "epoch:126 train_loss:1.932729032382162e-05 valid_loss:4.507039511736366e-05\n",
            "epoch:127 train_loss:2.439379184377483e-05 valid_loss:5.174600391910644e-05\n",
            "epoch:128 train_loss:1.7323294451267026e-05 valid_loss:4.015957620140398e-05\n",
            "epoch:129 train_loss:1.567611543072821e-05 valid_loss:2.6724361305241473e-05\n",
            "save best model\n",
            "epoch:130 train_loss:1.0452135623179654e-05 valid_loss:2.283001094838255e-05\n",
            "save best model\n",
            "epoch:131 train_loss:1.0019652159422145e-05 valid_loss:2.5047796043509152e-05\n",
            "epoch:132 train_loss:1.0471150315222783e-05 valid_loss:2.664242992977961e-05\n",
            "epoch:133 train_loss:1.0353549934431308e-05 valid_loss:2.9135589329598588e-05\n",
            "epoch:134 train_loss:1.0740928979026245e-05 valid_loss:3.0459982554020826e-05\n",
            "epoch:135 train_loss:1.0958151847262343e-05 valid_loss:2.9487498068192508e-05\n",
            "epoch:136 train_loss:9.72175456581681e-06 valid_loss:2.458579092490254e-05\n",
            "epoch:137 train_loss:1.067451406318772e-05 valid_loss:2.3324110316025326e-05\n",
            "epoch:138 train_loss:9.84242212275098e-06 valid_loss:2.4260118152596988e-05\n",
            "epoch:139 train_loss:1.1998722129646922e-05 valid_loss:2.3870785071267164e-05\n",
            "epoch:140 train_loss:1.3105632787200091e-05 valid_loss:3.531477614160394e-05\n",
            "epoch:141 train_loss:1.4237516514488865e-05 valid_loss:3.363101177455974e-05\n",
            "epoch:142 train_loss:1.534369803519237e-05 valid_loss:3.312355875095818e-05\n",
            "epoch:143 train_loss:1.5134421017945795e-05 valid_loss:2.9851679528292152e-05\n",
            "epoch:144 train_loss:1.3924326822234434e-05 valid_loss:2.651731620062492e-05\n",
            "epoch:145 train_loss:1.3358580847327377e-05 valid_loss:3.2145682780537754e-05\n",
            "epoch:146 train_loss:1.645381419419007e-05 valid_loss:2.83671743090963e-05\n",
            "epoch:147 train_loss:1.6391434403178413e-05 valid_loss:2.9345546863623895e-05\n",
            "epoch:148 train_loss:1.55572043291209e-05 valid_loss:2.763651764325914e-05\n",
            "epoch:149 train_loss:1.6261765798238532e-05 valid_loss:3.0309357498481404e-05\n",
            "epoch:150 train_loss:1.9486722041822053e-05 valid_loss:2.402629252173938e-05\n",
            "epoch:151 train_loss:1.877562537326109e-05 valid_loss:5.447728563012788e-05\n",
            "epoch:152 train_loss:3.459206244668975e-05 valid_loss:5.636727382807294e-05\n",
            "epoch:153 train_loss:2.5583098199098862e-05 valid_loss:6.861808105895761e-05\n",
            "epoch:154 train_loss:4.2208112113763084e-05 valid_loss:8.134497329592705e-05\n",
            "epoch:155 train_loss:3.645320010845252e-05 valid_loss:0.00010356149141443893\n",
            "epoch:156 train_loss:3.923649622568822e-05 valid_loss:0.0001264231832465157\n",
            "epoch:157 train_loss:3.8128583936567236e-05 valid_loss:0.00013961379590909928\n",
            "epoch:158 train_loss:4.274083145598221e-05 valid_loss:0.00012660972060984932\n",
            "epoch:159 train_loss:5.142257244491096e-05 valid_loss:8.406758570345119e-05\n",
            "epoch:160 train_loss:8.854626715522802e-05 valid_loss:5.2065069212403614e-05\n",
            "epoch:161 train_loss:0.00011805243250111946 valid_loss:0.00022501985949929804\n",
            "epoch:162 train_loss:7.215310152888479e-05 valid_loss:5.7017753533727955e-05\n",
            "epoch:163 train_loss:5.205602034645077e-05 valid_loss:7.181958972068969e-05\n",
            "epoch:164 train_loss:3.387592649535994e-05 valid_loss:4.229834939906141e-05\n",
            "epoch:165 train_loss:1.786895150720132e-05 valid_loss:3.144429820167716e-05\n",
            "epoch:166 train_loss:1.2210407324649472e-05 valid_loss:1.9660841530821926e-05\n",
            "save best model\n",
            "epoch:167 train_loss:1.0831681745710537e-05 valid_loss:2.4151732759492006e-05\n",
            "epoch:168 train_loss:1.3086546687191003e-05 valid_loss:2.7651381515170215e-05\n",
            "epoch:169 train_loss:1.5562949986108128e-05 valid_loss:2.8398177619237686e-05\n",
            "epoch:170 train_loss:1.1217331487185018e-05 valid_loss:2.0303586552472552e-05\n",
            "epoch:171 train_loss:1.0261867291521614e-05 valid_loss:2.162437817787577e-05\n",
            "epoch:172 train_loss:9.620152531574098e-06 valid_loss:2.470191702741431e-05\n",
            "epoch:173 train_loss:1.0132292351904147e-05 valid_loss:2.5102476683969144e-05\n",
            "epoch:174 train_loss:1.0728732541388632e-05 valid_loss:1.796653384644742e-05\n",
            "save best model\n",
            "epoch:175 train_loss:1.1162637899057396e-05 valid_loss:2.1391335621956387e-05\n",
            "epoch:176 train_loss:1.3962018707995108e-05 valid_loss:2.8940719403180992e-05\n",
            "epoch:177 train_loss:1.5691727690460135e-05 valid_loss:2.204161933150317e-05\n",
            "epoch:178 train_loss:1.1352709470379017e-05 valid_loss:2.7880268589797197e-05\n",
            "epoch:179 train_loss:1.2649375523526234e-05 valid_loss:3.675484003906604e-05\n",
            "epoch:180 train_loss:1.176480016814215e-05 valid_loss:2.899714218074223e-05\n",
            "epoch:181 train_loss:9.313844050969541e-06 valid_loss:1.4701308145959047e-05\n",
            "save best model\n",
            "epoch:182 train_loss:1.1338991195467921e-05 valid_loss:1.9282665562059265e-05\n",
            "epoch:183 train_loss:1.3225173991789537e-05 valid_loss:2.221627937615267e-05\n",
            "epoch:184 train_loss:1.4794241198817164e-05 valid_loss:3.260657103965059e-05\n",
            "epoch:185 train_loss:1.5408903386236892e-05 valid_loss:4.3626612750813365e-05\n",
            "epoch:186 train_loss:1.3843740021002304e-05 valid_loss:3.4348611734458245e-05\n",
            "epoch:187 train_loss:1.2451442267370618e-05 valid_loss:1.961056568688946e-05\n",
            "epoch:188 train_loss:1.5654364435451702e-05 valid_loss:2.198212951043388e-05\n",
            "epoch:189 train_loss:2.5043015789884117e-05 valid_loss:6.47776741971029e-05\n",
            "epoch:190 train_loss:2.932964793621472e-05 valid_loss:8.902234731067438e-05\n",
            "epoch:191 train_loss:2.3053782721641863e-05 valid_loss:2.638359046613914e-05\n",
            "epoch:192 train_loss:2.5143226543554596e-05 valid_loss:5.5239068387891166e-05\n",
            "epoch:193 train_loss:2.994890984256118e-05 valid_loss:5.324671838025097e-05\n",
            "epoch:194 train_loss:1.7982159837022966e-05 valid_loss:2.657097547853482e-05\n",
            "epoch:195 train_loss:1.6106339090684843e-05 valid_loss:6.151847810542677e-05\n",
            "epoch:196 train_loss:2.2871031332114297e-05 valid_loss:5.385501117416425e-05\n",
            "epoch:197 train_loss:1.812923675162084e-05 valid_loss:2.2524641735799378e-05\n",
            "epoch:198 train_loss:1.6189829340065546e-05 valid_loss:3.0425374916376313e-05\n",
            "epoch:199 train_loss:1.3932021374785108e-05 valid_loss:2.1708353415306192e-05\n",
            "epoch:200 train_loss:1.0303442902820987e-05 valid_loss:2.1518904304684838e-05\n",
            "epoch:201 train_loss:1.0550884060952134e-05 valid_loss:2.4910173124226276e-05\n",
            "epoch:202 train_loss:1.1186963699098365e-05 valid_loss:1.7413441128155682e-05\n",
            "epoch:203 train_loss:7.323328873098944e-06 valid_loss:1.5164112937782193e-05\n",
            "epoch:204 train_loss:1.1855931865688439e-05 valid_loss:1.746490761433961e-05\n",
            "epoch:205 train_loss:1.341842625556132e-05 valid_loss:2.305124780832557e-05\n",
            "epoch:206 train_loss:1.4956712321792213e-05 valid_loss:2.339497177672456e-05\n",
            "epoch:207 train_loss:1.5520135775659583e-05 valid_loss:4.38087936345255e-05\n",
            "epoch:208 train_loss:2.1132646932326476e-05 valid_loss:4.2353073695267085e-05\n",
            "epoch:209 train_loss:1.5236462458132235e-05 valid_loss:3.427526280574966e-05\n",
            "epoch:210 train_loss:1.595935875937155e-05 valid_loss:2.1033812572568422e-05\n",
            "epoch:211 train_loss:2.2492024123089828e-05 valid_loss:3.290844142611604e-05\n",
            "epoch:212 train_loss:2.04784551998374e-05 valid_loss:4.351793450041441e-05\n",
            "epoch:213 train_loss:2.9930001952986156e-05 valid_loss:0.00010481106073711999\n",
            "epoch:214 train_loss:3.15719545748531e-05 valid_loss:4.710540542873787e-05\n",
            "epoch:215 train_loss:2.989586336197034e-05 valid_loss:8.340319982380606e-05\n",
            "epoch:216 train_loss:4.033143755400993e-05 valid_loss:0.00012117186633986421\n",
            "epoch:217 train_loss:3.087074345684313e-05 valid_loss:7.997918874025345e-05\n",
            "epoch:218 train_loss:2.1921342093062573e-05 valid_loss:3.5966720588476164e-05\n",
            "epoch:219 train_loss:1.551449898013541e-05 valid_loss:3.1044513889355585e-05\n",
            "epoch:220 train_loss:1.0562184178929278e-05 valid_loss:2.0317806956882123e-05\n",
            "epoch:221 train_loss:1.2292276513411101e-05 valid_loss:2.0376407519506756e-05\n",
            "epoch:222 train_loss:1.396003358422604e-05 valid_loss:1.4634058970841579e-05\n",
            "save best model\n",
            "epoch:223 train_loss:2.0457337225505195e-05 valid_loss:1.719621423035278e-05\n",
            "epoch:224 train_loss:2.672456124249341e-05 valid_loss:3.638545695139328e-05\n",
            "epoch:225 train_loss:4.235520939093678e-05 valid_loss:6.66272626403952e-05\n",
            "epoch:226 train_loss:4.3376800830527725e-05 valid_loss:0.0001759861952450592\n",
            "epoch:227 train_loss:4.52350449348968e-05 valid_loss:5.8758179875439964e-05\n",
            "epoch:228 train_loss:2.466683342087587e-05 valid_loss:7.329814616241492e-05\n",
            "epoch:229 train_loss:2.2305141139137657e-05 valid_loss:3.7480143873835914e-05\n",
            "epoch:230 train_loss:1.5073225224821525e-05 valid_loss:2.048783153441036e-05\n",
            "epoch:231 train_loss:1.4202676109360053e-05 valid_loss:1.847027215262642e-05\n",
            "epoch:232 train_loss:1.0241912200904659e-05 valid_loss:2.376393968006596e-05\n",
            "epoch:233 train_loss:1.0839429806866166e-05 valid_loss:1.4725942264703917e-05\n",
            "epoch:234 train_loss:1.3281899201602857e-05 valid_loss:3.2063666367321275e-05\n",
            "epoch:235 train_loss:1.1803620610509017e-05 valid_loss:3.1270137696992606e-05\n",
            "epoch:236 train_loss:1.1678821313883722e-05 valid_loss:2.086438098558574e-05\n",
            "epoch:237 train_loss:1.1201682203439608e-05 valid_loss:2.4425135052297264e-05\n",
            "epoch:238 train_loss:7.506146365206708e-06 valid_loss:8.092092684819363e-06\n",
            "save best model\n",
            "epoch:239 train_loss:5.224005184977108e-06 valid_loss:1.709019034024095e-05\n",
            "epoch:240 train_loss:5.875931410375617e-06 valid_loss:1.2319986353759305e-05\n",
            "epoch:241 train_loss:5.036676245456167e-06 valid_loss:5.791548232991772e-06\n",
            "save best model\n",
            "epoch:242 train_loss:6.337055121245309e-06 valid_loss:2.0184093045827467e-05\n",
            "epoch:243 train_loss:8.731051334759994e-06 valid_loss:1.1949067356908927e-05\n",
            "epoch:244 train_loss:6.3922224424257165e-06 valid_loss:9.159570254269056e-06\n",
            "epoch:245 train_loss:8.094877620755546e-06 valid_loss:3.203276992280735e-05\n",
            "epoch:246 train_loss:9.797042821446666e-06 valid_loss:3.195844965375727e-05\n",
            "epoch:247 train_loss:6.867183186740375e-06 valid_loss:1.1504457006594748e-05\n",
            "epoch:248 train_loss:6.369886199940487e-06 valid_loss:1.2111943078707554e-05\n",
            "epoch:249 train_loss:9.089020623933822e-06 valid_loss:2.5236408873752225e-05\n",
            "epoch:250 train_loss:1.384020285715653e-05 valid_loss:1.9143737972626695e-05\n",
            "epoch:251 train_loss:8.732498523992641e-06 valid_loss:1.8480220660421764e-05\n",
            "epoch:252 train_loss:1.5735051041095478e-05 valid_loss:5.597088784270454e-05\n",
            "epoch:253 train_loss:2.0361625855811224e-05 valid_loss:4.031021489936393e-05\n",
            "epoch:254 train_loss:1.4329961257115227e-05 valid_loss:3.2339572499040514e-05\n",
            "epoch:255 train_loss:1.7954906424064473e-05 valid_loss:4.828718192584347e-05\n",
            "epoch:256 train_loss:1.4400599007381566e-05 valid_loss:2.7718469027604442e-05\n",
            "epoch:257 train_loss:2.319830847833752e-05 valid_loss:4.386516047816258e-05\n",
            "epoch:258 train_loss:3.098651622066326e-05 valid_loss:6.222815954970429e-05\n",
            "epoch:259 train_loss:3.081228189532542e-05 valid_loss:4.185723537375452e-05\n",
            "epoch:260 train_loss:1.992404205945301e-05 valid_loss:2.2566237930732314e-05\n",
            "epoch:261 train_loss:1.6561960945990802e-05 valid_loss:0.00012384886940708384\n",
            "epoch:262 train_loss:3.289504881346753e-05 valid_loss:2.6322366466047242e-05\n",
            "epoch:263 train_loss:1.5877660037707148e-05 valid_loss:1.6435779798484873e-05\n",
            "epoch:264 train_loss:1.8937989630608678e-05 valid_loss:1.0211009794147685e-05\n",
            "epoch:265 train_loss:1.1999818576037393e-05 valid_loss:3.01130858133547e-05\n",
            "epoch:266 train_loss:1.7704376861931654e-05 valid_loss:2.4061958356469404e-05\n",
            "epoch:267 train_loss:1.481325951620723e-05 valid_loss:4.595036261889618e-05\n",
            "epoch:268 train_loss:1.9360314758564022e-05 valid_loss:4.266077758074971e-05\n",
            "epoch:269 train_loss:1.5056523984134805e-05 valid_loss:4.5539927668869495e-05\n",
            "epoch:270 train_loss:1.6329350324263538e-05 valid_loss:6.0070886320318095e-05\n",
            "epoch:271 train_loss:1.9733385948307437e-05 valid_loss:5.4368036217056215e-05\n",
            "epoch:272 train_loss:2.4143115095082772e-05 valid_loss:1.8647548131411895e-05\n",
            "epoch:273 train_loss:3.3792214051370844e-05 valid_loss:3.41379554811283e-05\n",
            "epoch:274 train_loss:4.137908733052124e-05 valid_loss:2.4151202524080873e-05\n",
            "epoch:275 train_loss:3.996859833124391e-05 valid_loss:0.00011180569345015101\n",
            "epoch:276 train_loss:0.00010044787389536698 valid_loss:5.950818467681529e-05\n",
            "epoch:277 train_loss:0.024240765784169425 valid_loss:0.04999044584110379\n",
            "epoch:278 train_loss:0.020062019505227607 valid_loss:0.052109161391854286\n",
            "epoch:279 train_loss:0.013826817125340717 valid_loss:0.00793639849871397\n",
            "epoch:280 train_loss:0.002946429268275905 valid_loss:0.002070818212814629\n",
            "epoch:281 train_loss:0.0009896486153593287 valid_loss:0.001302801800193265\n",
            "epoch:282 train_loss:0.0006072464295559459 valid_loss:0.0009604968945495784\n",
            "epoch:283 train_loss:0.00043930860233053356 valid_loss:0.0008093532087514177\n",
            "epoch:284 train_loss:0.00035851200300385244 valid_loss:0.0007442906644428149\n",
            "epoch:285 train_loss:0.0003030835097080045 valid_loss:0.0006312662735581398\n",
            "epoch:286 train_loss:0.00025840421545176976 valid_loss:0.0005821567465318367\n",
            "epoch:287 train_loss:0.00023277862540756664 valid_loss:0.0005516907112905756\n",
            "epoch:288 train_loss:0.00021487959505369267 valid_loss:0.0005051707485108636\n",
            "epoch:289 train_loss:0.00020053420101046667 valid_loss:0.0004967392596881837\n",
            "epoch:290 train_loss:0.0001828378012255093 valid_loss:0.0004267892800271511\n",
            "epoch:291 train_loss:0.00016434616473917331 valid_loss:0.00038673102972097695\n",
            "epoch:292 train_loss:0.0001489299366868282 valid_loss:0.0003384556548553519\n",
            "epoch:293 train_loss:0.00013609512582964575 valid_loss:0.00031504157959716395\n",
            "epoch:294 train_loss:0.00012624327003625999 valid_loss:0.00028648002626141533\n",
            "epoch:295 train_loss:0.00011798452679714601 valid_loss:0.00025535168970236555\n",
            "epoch:296 train_loss:0.00010985275144371876 valid_loss:0.00023000474539003335\n",
            "epoch:297 train_loss:0.00010240079730768532 valid_loss:0.0002224840245617088\n",
            "epoch:298 train_loss:9.639239013065687e-05 valid_loss:0.00020639873036998324\n",
            "epoch:299 train_loss:8.78418836186433e-05 valid_loss:0.00018549147353041917\n",
            "epoch:300 train_loss:8.039224141814177e-05 valid_loss:0.00016126682021422312\n",
            "epoch:301 train_loss:6.967502667976078e-05 valid_loss:0.00013537611448555253\n",
            "epoch:302 train_loss:6.258957970809813e-05 valid_loss:0.00011770475975936279\n",
            "epoch:303 train_loss:5.6375665230411367e-05 valid_loss:0.00010167368964175694\n",
            "epoch:304 train_loss:5.005917116957587e-05 valid_loss:9.132267041422892e-05\n",
            "epoch:305 train_loss:4.495535328411885e-05 valid_loss:7.064163401082624e-05\n",
            "epoch:306 train_loss:3.890291898440207e-05 valid_loss:6.809848673583474e-05\n",
            "epoch:307 train_loss:3.735700829565758e-05 valid_loss:5.795255765406182e-05\n",
            "epoch:308 train_loss:3.343374388956969e-05 valid_loss:5.4522267419088166e-05\n",
            "epoch:309 train_loss:3.110710607264385e-05 valid_loss:5.1841498134308495e-05\n",
            "epoch:310 train_loss:3.192713236583384e-05 valid_loss:4.9456017222837545e-05\n",
            "epoch:311 train_loss:2.7517270761260686e-05 valid_loss:4.257359705661656e-05\n",
            "epoch:312 train_loss:2.6834870419002578e-05 valid_loss:4.293534539101529e-05\n",
            "epoch:313 train_loss:3.0106150259396396e-05 valid_loss:4.780614017363405e-05\n",
            "epoch:314 train_loss:2.7021510100490155e-05 valid_loss:4.030516902275849e-05\n",
            "epoch:315 train_loss:2.671024630116234e-05 valid_loss:3.840463068627287e-05\n",
            "epoch:316 train_loss:2.880443399691204e-05 valid_loss:4.654501026379876e-05\n",
            "epoch:317 train_loss:2.6068300283239092e-05 valid_loss:3.822475628112443e-05\n",
            "epoch:318 train_loss:2.3502563180954894e-05 valid_loss:3.501319952192716e-05\n",
            "epoch:319 train_loss:2.3052984463194865e-05 valid_loss:4.115867977816379e-05\n",
            "epoch:320 train_loss:2.114176080188675e-05 valid_loss:3.471772652119398e-05\n",
            "epoch:321 train_loss:1.912743960019725e-05 valid_loss:3.227264096494764e-05\n",
            "epoch:322 train_loss:1.8773401683978995e-05 valid_loss:3.135708993795561e-05\n",
            "epoch:323 train_loss:1.7785428023368393e-05 valid_loss:3.40574661095161e-05\n",
            "epoch:324 train_loss:1.669076085717178e-05 valid_loss:3.0132581287034554e-05\n",
            "epoch:325 train_loss:1.7482294222443467e-05 valid_loss:2.8068290248484118e-05\n",
            "epoch:326 train_loss:1.682868363180508e-05 valid_loss:3.039536841242807e-05\n",
            "epoch:327 train_loss:1.593955322378962e-05 valid_loss:2.9538364287873264e-05\n",
            "epoch:328 train_loss:1.5607443932215876e-05 valid_loss:2.7038490316044772e-05\n",
            "epoch:329 train_loss:1.4705891746618565e-05 valid_loss:2.612298158055637e-05\n",
            "epoch:330 train_loss:1.3944127380859249e-05 valid_loss:2.5820659629971487e-05\n",
            "epoch:331 train_loss:1.3518190371542005e-05 valid_loss:2.5157986328849802e-05\n",
            "epoch:332 train_loss:1.3253090022165756e-05 valid_loss:2.4260439204226714e-05\n",
            "epoch:333 train_loss:1.3450312306102003e-05 valid_loss:2.40786794165615e-05\n",
            "epoch:334 train_loss:1.4039151235718034e-05 valid_loss:2.4058819235506235e-05\n",
            "epoch:335 train_loss:1.4297825070267814e-05 valid_loss:2.3997931748453993e-05\n",
            "epoch:336 train_loss:1.5372164802506126e-05 valid_loss:2.631788674989366e-05\n",
            "epoch:337 train_loss:1.6442323865501545e-05 valid_loss:2.4363241664104862e-05\n",
            "epoch:338 train_loss:1.7102921522867593e-05 valid_loss:2.5770443244255148e-05\n",
            "epoch:339 train_loss:1.8559698370760696e-05 valid_loss:2.8095298148400616e-05\n",
            "epoch:340 train_loss:1.947105874933186e-05 valid_loss:2.800529591695522e-05\n",
            "epoch:341 train_loss:1.9553782319942708e-05 valid_loss:2.61388995568268e-05\n",
            "epoch:342 train_loss:1.8149849615333045e-05 valid_loss:2.307972317794338e-05\n",
            "epoch:343 train_loss:2.6221192494328232e-05 valid_loss:3.451838347245939e-05\n",
            "epoch:344 train_loss:1.7692927081548583e-05 valid_loss:2.5326161903649336e-05\n",
            "epoch:345 train_loss:1.8382176929460708e-05 valid_loss:2.339812181162415e-05\n",
            "epoch:346 train_loss:1.5612571107542157e-05 valid_loss:2.6208746930933557e-05\n",
            "epoch:347 train_loss:1.5195245901446066e-05 valid_loss:2.446093913022196e-05\n",
            "epoch:348 train_loss:1.21065819990286e-05 valid_loss:2.1148061932763085e-05\n",
            "epoch:349 train_loss:1.168754642498647e-05 valid_loss:1.844526786953793e-05\n",
            "epoch:350 train_loss:1.2291442228868416e-05 valid_loss:1.736609397084976e-05\n",
            "epoch:351 train_loss:1.764051585774319e-05 valid_loss:2.0517993107205257e-05\n",
            "epoch:352 train_loss:1.4952550069817031e-05 valid_loss:2.7709158985089744e-05\n",
            "epoch:353 train_loss:1.5030254316014987e-05 valid_loss:1.9594308014347916e-05\n",
            "epoch:354 train_loss:1.3101544204295755e-05 valid_loss:1.7270081571041374e-05\n",
            "epoch:355 train_loss:1.0623706442755873e-05 valid_loss:1.710838569124462e-05\n",
            "epoch:356 train_loss:1.0511624560017986e-05 valid_loss:1.9644032363430597e-05\n",
            "epoch:357 train_loss:9.394653084705675e-06 valid_loss:2.1376784388849046e-05\n",
            "epoch:358 train_loss:1.2780186390652185e-05 valid_loss:2.423146361252293e-05\n",
            "epoch:359 train_loss:1.8944516493017243e-05 valid_loss:2.4351879801542964e-05\n",
            "epoch:360 train_loss:2.4093409630647027e-05 valid_loss:3.327884041937068e-05\n",
            "epoch:361 train_loss:3.356680586976937e-05 valid_loss:3.898695194948232e-05\n",
            "epoch:362 train_loss:4.859832127597959e-05 valid_loss:3.979315169999609e-05\n",
            "epoch:363 train_loss:4.5131125716579845e-05 valid_loss:6.720665442117024e-05\n",
            "epoch:364 train_loss:4.256678653291601e-05 valid_loss:5.18123615620425e-05\n",
            "epoch:365 train_loss:7.543953466261478e-05 valid_loss:0.00011228264338569716\n",
            "epoch:366 train_loss:4.8838579156533037e-05 valid_loss:4.540818463283358e-05\n",
            "epoch:367 train_loss:3.959519856127574e-05 valid_loss:7.624965837749187e-05\n",
            "epoch:368 train_loss:3.567122267769365e-05 valid_loss:5.5361565500788856e-05\n",
            "epoch:369 train_loss:4.379614943496158e-05 valid_loss:0.00012632391371880658\n",
            "epoch:370 train_loss:4.269760115170761e-05 valid_loss:8.524279564880999e-05\n",
            "epoch:371 train_loss:6.350832205094371e-05 valid_loss:0.00021143199410289526\n",
            "epoch:372 train_loss:8.790869312886368e-05 valid_loss:0.0001988123040064238\n",
            "epoch:373 train_loss:0.00017243218462681398 valid_loss:0.0005254262214293703\n",
            "epoch:374 train_loss:0.0001929265797823771 valid_loss:0.00018089763761963695\n",
            "epoch:375 train_loss:0.00012412960263140526 valid_loss:0.00022699544206261635\n",
            "epoch:376 train_loss:6.579226944975542e-05 valid_loss:6.264837884373264e-05\n",
            "epoch:377 train_loss:3.1217529340210604e-05 valid_loss:5.280192999634892e-05\n",
            "epoch:378 train_loss:2.4685410784918025e-05 valid_loss:4.9207949814444873e-05\n",
            "epoch:379 train_loss:2.2443400439442485e-05 valid_loss:3.6404610000317916e-05\n",
            "epoch:380 train_loss:2.2573444488848003e-05 valid_loss:3.2791485864436254e-05\n",
            "epoch:381 train_loss:2.356796974507031e-05 valid_loss:3.164253575960174e-05\n",
            "epoch:382 train_loss:2.415478022360023e-05 valid_loss:3.515535263431957e-05\n",
            "epoch:383 train_loss:2.3302397443735066e-05 valid_loss:3.217995345039526e-05\n",
            "epoch:384 train_loss:2.1103799023573327e-05 valid_loss:2.990326811413979e-05\n",
            "epoch:385 train_loss:1.835838821130488e-05 valid_loss:2.5400428057764657e-05\n",
            "epoch:386 train_loss:1.620161356186145e-05 valid_loss:2.4016144379856996e-05\n",
            "epoch:387 train_loss:1.4319778099686826e-05 valid_loss:2.230755580967525e-05\n",
            "epoch:388 train_loss:1.336617467333983e-05 valid_loss:2.1854465558135416e-05\n",
            "epoch:389 train_loss:1.2266073301563867e-05 valid_loss:2.0452156604733318e-05\n",
            "epoch:390 train_loss:1.1553062601403022e-05 valid_loss:2.0444218534976244e-05\n",
            "epoch:391 train_loss:1.0939805343291988e-05 valid_loss:1.9815103314613225e-05\n",
            "epoch:392 train_loss:1.0514404860057564e-05 valid_loss:1.9955466996179894e-05\n",
            "epoch:393 train_loss:1.0112475971861082e-05 valid_loss:1.9371350390429143e-05\n",
            "epoch:394 train_loss:9.79841258362689e-06 valid_loss:1.9427360257395776e-05\n",
            "epoch:395 train_loss:9.410729477268534e-06 valid_loss:1.9436097318248358e-05\n",
            "epoch:396 train_loss:9.233464715584381e-06 valid_loss:1.902969825096079e-05\n",
            "epoch:397 train_loss:8.754752191938072e-06 valid_loss:1.8254935184813803e-05\n",
            "epoch:398 train_loss:8.440581862285197e-06 valid_loss:1.8326426015846664e-05\n",
            "epoch:399 train_loss:8.260655009608956e-06 valid_loss:1.837439413066022e-05\n",
            "epoch:400 train_loss:8.203373125878796e-06 valid_loss:1.8440344774717232e-05\n",
            "epoch:401 train_loss:8.109391097200893e-06 valid_loss:1.8114542399416678e-05\n",
            "epoch:402 train_loss:7.662135178381706e-06 valid_loss:1.7234428923984524e-05\n",
            "epoch:403 train_loss:7.480615244680343e-06 valid_loss:1.703509997241781e-05\n",
            "epoch:404 train_loss:7.27806426918202e-06 valid_loss:1.6767244233051315e-05\n",
            "epoch:405 train_loss:7.0038581472747155e-06 valid_loss:1.646401369725936e-05\n",
            "epoch:406 train_loss:6.836654342300284e-06 valid_loss:1.6161244730028557e-05\n",
            "epoch:407 train_loss:6.692466399726982e-06 valid_loss:1.59698188326729e-05\n",
            "epoch:408 train_loss:6.536490319477808e-06 valid_loss:1.5170272035902599e-05\n",
            "epoch:409 train_loss:6.303929391530498e-06 valid_loss:1.50284049595939e-05\n",
            "epoch:410 train_loss:6.232205313002244e-06 valid_loss:1.5009618209660402e-05\n",
            "epoch:411 train_loss:6.173580996144463e-06 valid_loss:1.4360905879584607e-05\n",
            "epoch:412 train_loss:6.161608376310647e-06 valid_loss:1.4290631042968016e-05\n",
            "epoch:413 train_loss:6.105043976529285e-06 valid_loss:1.3954278074379545e-05\n",
            "epoch:414 train_loss:5.9967372989275545e-06 valid_loss:1.3789389186058543e-05\n",
            "epoch:415 train_loss:6.014625948106793e-06 valid_loss:1.372064230054093e-05\n",
            "epoch:416 train_loss:5.933807124670744e-06 valid_loss:1.3314514944795519e-05\n",
            "epoch:417 train_loss:5.739264976354106e-06 valid_loss:1.3127678357705008e-05\n",
            "epoch:418 train_loss:5.753576923931784e-06 valid_loss:1.280777109968767e-05\n",
            "epoch:419 train_loss:5.733072820627664e-06 valid_loss:1.2768696251441725e-05\n",
            "epoch:420 train_loss:5.649258955347452e-06 valid_loss:1.3028787634539185e-05\n",
            "epoch:421 train_loss:5.622564591097519e-06 valid_loss:1.2641870853258297e-05\n",
            "epoch:422 train_loss:5.560732732748066e-06 valid_loss:1.252548554475652e-05\n",
            "epoch:423 train_loss:5.448417975154977e-06 valid_loss:1.266276944988931e-05\n",
            "epoch:424 train_loss:5.309017303210971e-06 valid_loss:1.2197992646179046e-05\n",
            "epoch:425 train_loss:5.326597185254893e-06 valid_loss:1.1958434470216162e-05\n",
            "epoch:426 train_loss:5.1483984483032446e-06 valid_loss:1.2122122370783472e-05\n",
            "epoch:427 train_loss:5.053189672329002e-06 valid_loss:1.2054282478857203e-05\n",
            "epoch:428 train_loss:5.182056232418593e-06 valid_loss:1.2431388540790067e-05\n",
            "epoch:429 train_loss:5.168527012402693e-06 valid_loss:1.2408350812620483e-05\n",
            "epoch:430 train_loss:4.780373242536169e-06 valid_loss:1.1361815268173814e-05\n",
            "epoch:431 train_loss:4.597637342840244e-06 valid_loss:1.1418056601542048e-05\n",
            "epoch:432 train_loss:4.768873256782374e-06 valid_loss:1.2464219707908342e-05\n",
            "epoch:433 train_loss:4.6033918642428435e-06 valid_loss:1.0705279919420718e-05\n",
            "epoch:434 train_loss:4.704040457505067e-06 valid_loss:1.2130099548812723e-05\n",
            "epoch:435 train_loss:4.841474426105681e-06 valid_loss:1.1299159950795001e-05\n",
            "epoch:436 train_loss:5.303461301132807e-06 valid_loss:1.3251846894490882e-05\n",
            "epoch:437 train_loss:5.842567569895134e-06 valid_loss:1.2660196489377995e-05\n",
            "epoch:438 train_loss:9.266480004852281e-06 valid_loss:1.8912700852524722e-05\n",
            "epoch:439 train_loss:1.0311651029345134e-05 valid_loss:2.05675187316956e-05\n",
            "epoch:440 train_loss:1.7257965295256225e-05 valid_loss:3.297135799584794e-05\n",
            "epoch:441 train_loss:3.146210999855409e-05 valid_loss:7.139292392821517e-05\n",
            "epoch:442 train_loss:5.0299839535404724e-05 valid_loss:7.350929809035733e-05\n",
            "epoch:443 train_loss:4.3616373608933325e-05 valid_loss:7.105655004124856e-05\n",
            "epoch:444 train_loss:5.050141751578647e-05 valid_loss:0.00010713731444411678\n",
            "epoch:445 train_loss:2.9777946413863294e-05 valid_loss:2.1017978269810556e-05\n",
            "epoch:446 train_loss:1.8847693000781066e-05 valid_loss:4.57974779237702e-05\n",
            "epoch:447 train_loss:1.4968993102431543e-05 valid_loss:1.2971901014680043e-05\n",
            "epoch:448 train_loss:9.832468397992974e-06 valid_loss:2.3619689272891264e-05\n",
            "epoch:449 train_loss:8.273959603381323e-06 valid_loss:1.2416614026733441e-05\n",
            "epoch:450 train_loss:7.474753715541738e-06 valid_loss:1.6654406863381155e-05\n",
            "epoch:451 train_loss:6.4432913531062595e-06 valid_loss:1.1617804602792603e-05\n",
            "epoch:452 train_loss:5.940621090556104e-06 valid_loss:1.388717100780923e-05\n",
            "epoch:453 train_loss:5.017036225278086e-06 valid_loss:1.3817672879667953e-05\n",
            "epoch:454 train_loss:4.881292404156233e-06 valid_loss:1.4158914382278454e-05\n",
            "epoch:455 train_loss:5.041937659674052e-06 valid_loss:1.3691661933989963e-05\n",
            "epoch:456 train_loss:5.768304226371078e-06 valid_loss:1.3894592711949372e-05\n",
            "epoch:457 train_loss:6.39975650705714e-06 valid_loss:1.4119112620392116e-05\n",
            "epoch:458 train_loss:7.510278578592988e-06 valid_loss:1.3416931778920116e-05\n",
            "epoch:459 train_loss:8.334911386656233e-06 valid_loss:1.3201731690060114e-05\n",
            "epoch:460 train_loss:8.633462104828343e-06 valid_loss:1.2219292557347217e-05\n",
            "epoch:461 train_loss:1.0042299234353575e-05 valid_loss:1.42417857205146e-05\n",
            "epoch:462 train_loss:1.0302372958095577e-05 valid_loss:1.5214588074741187e-05\n",
            "epoch:463 train_loss:1.1295912802072255e-05 valid_loss:2.0353010313556297e-05\n",
            "epoch:464 train_loss:1.2808875958904133e-05 valid_loss:2.8496378035924863e-05\n",
            "epoch:465 train_loss:1.3636345000931113e-05 valid_loss:3.345228014950408e-05\n",
            "epoch:466 train_loss:1.5282349194320785e-05 valid_loss:2.985011724376818e-05\n",
            "epoch:467 train_loss:1.6936582015761007e-05 valid_loss:1.7960971035790863e-05\n",
            "epoch:468 train_loss:2.0467282183744828e-05 valid_loss:1.9460156181594357e-05\n",
            "epoch:469 train_loss:1.8250566881761188e-05 valid_loss:3.10805344270193e-05\n",
            "epoch:470 train_loss:1.3968824153683576e-05 valid_loss:1.3930871318734717e-05\n",
            "epoch:471 train_loss:1.0471444940978674e-05 valid_loss:1.7166139969049254e-05\n",
            "epoch:472 train_loss:1.3307666879174778e-05 valid_loss:1.782403205652372e-05\n",
            "epoch:473 train_loss:1.6675620044124014e-05 valid_loss:1.9319173588883132e-05\n",
            "epoch:474 train_loss:1.856633166931311e-05 valid_loss:2.6614037778927013e-05\n",
            "epoch:475 train_loss:2.1134411352047915e-05 valid_loss:1.9620737020886736e-05\n",
            "epoch:476 train_loss:2.3180714075958047e-05 valid_loss:4.205120330880163e-05\n",
            "epoch:477 train_loss:2.3757251458139057e-05 valid_loss:3.1255608519131783e-05\n",
            "epoch:478 train_loss:3.471765679326685e-05 valid_loss:7.018207088549389e-05\n",
            "epoch:479 train_loss:3.91234406783446e-05 valid_loss:5.3624025895260274e-05\n",
            "epoch:480 train_loss:4.713485319977432e-05 valid_loss:8.071646607277216e-05\n",
            "epoch:481 train_loss:4.281050961354696e-05 valid_loss:7.120814461814007e-05\n",
            "epoch:482 train_loss:5.726352062790991e-05 valid_loss:9.867586413747631e-05\n",
            "epoch:483 train_loss:3.104835013800766e-05 valid_loss:3.6132678360445425e-05\n",
            "epoch:484 train_loss:2.2075440332021874e-05 valid_loss:3.3620123758737464e-05\n",
            "epoch:485 train_loss:1.4873243875020611e-05 valid_loss:1.2650826647586655e-05\n",
            "epoch:486 train_loss:8.98575463755454e-06 valid_loss:1.5631013411621097e-05\n",
            "epoch:487 train_loss:8.633296248363978e-06 valid_loss:1.306895183006418e-05\n",
            "epoch:488 train_loss:7.5869572810916e-06 valid_loss:1.4854289020149736e-05\n",
            "epoch:489 train_loss:6.888714804315694e-06 valid_loss:1.4227916381059913e-05\n",
            "epoch:490 train_loss:6.515955861788017e-06 valid_loss:1.3542060514737386e-05\n",
            "epoch:491 train_loss:5.458271238644051e-06 valid_loss:1.1673669860101654e-05\n",
            "epoch:492 train_loss:4.7783007630641805e-06 valid_loss:1.1399886489016353e-05\n",
            "epoch:493 train_loss:4.294480832969485e-06 valid_loss:1.0559597512838081e-05\n",
            "epoch:494 train_loss:4.057829458916886e-06 valid_loss:9.816357987801894e-06\n",
            "epoch:495 train_loss:3.858041045153489e-06 valid_loss:9.148407116299495e-06\n",
            "epoch:496 train_loss:3.848095104785898e-06 valid_loss:8.93895798981248e-06\n",
            "epoch:497 train_loss:3.746939765076402e-06 valid_loss:8.433632729065721e-06\n",
            "epoch:498 train_loss:3.5755988392338622e-06 valid_loss:8.121366818159004e-06\n",
            "epoch:499 train_loss:3.504465717519957e-06 valid_loss:7.860720870667137e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "eIlqZ-vJTr4D",
        "outputId": "bfd5a245-75f9-4a0c-86a0-6c533317f4ab"
      },
      "source": [
        "part3.test()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Condenser Temperature</th>\n",
              "      <td>0.999951</td>\n",
              "      <td>0.000109068</td>\n",
              "      <td>0.00828698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reboiler Temp</th>\n",
              "      <td>0.999967</td>\n",
              "      <td>0.00123659</td>\n",
              "      <td>0.0214112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999959</td>\n",
              "      <td>0.00067283</td>\n",
              "      <td>0.0148491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             R2          MSE        MAPE\n",
              "0                                                       \n",
              "Condenser Temperature  0.999951  0.000109068  0.00828698\n",
              "Reboiler Temp          0.999967   0.00123659   0.0214112\n",
              "AVG                    0.999959   0.00067283   0.0148491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0KrxJx4MjpL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}