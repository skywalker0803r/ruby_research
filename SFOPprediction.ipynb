{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SFOPprediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gwQbv_YPWDTt",
        "v4lmrQEKWDUw"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/ruby_research/blob/main/SFOPprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTXRNj8PW-8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001332ab-c44d-4b33-d7cf-aa4d10b668d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3MtssUy6CPq"
      },
      "source": [
        "#!pip install git+https://github.com/jonbarron/robust_loss_pytorch\n",
        "import robust_loss_pytorch\n",
        "from torch.utils.data import TensorDataset,DataLoader\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ha0h4_WQWDSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee46e692-de07-4091-87fb-5bf415dd11a7"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import tensor\n",
        "from torch.nn import Linear,ReLU,Sigmoid,Tanh\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from math import sqrt\n",
        "import joblib\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import warnings;warnings.simplefilter('ignore')\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "from sklearn.utils import shuffle\n",
        "import random\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "root = '/gdrive/My Drive/for Ruby'\n",
        "excel_list=os.listdir(root)\n",
        "excel_list"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['淡水河流域.csv', '淡水河流域final_0429.ipynb', '驗證淡水河流域03_15.ipynb', '2.xlsx']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlDEZklNW89Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25835c8d-c0ab-43de-a626-d059ed6b181d"
      },
      "source": [
        "with open('/gdrive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/foo.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BnkYQueWDSj"
      },
      "source": [
        "# some function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzVD6cnCWDSj"
      },
      "source": [
        "def mape(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "def get_group_col(df,name):\n",
        "    condition = df.columns.str.contains(name)\n",
        "    return df.columns[condition].tolist()\n",
        "\n",
        "def split_data(df,x_col,y_col):\n",
        "  df = shuffle(df).astype('float32')\n",
        "  X,Y = df[x_col],df[y_col]\n",
        "  sp1 = int(len(df)*0.8)\n",
        "  sp2 = int(len(df)*0.9)\n",
        "  data = {}\n",
        "  data['X_train'],data['Y_train'] = X.iloc[:sp1,:],Y.iloc[:sp1,:]\n",
        "  data['X_vaild'],data['Y_vaild'] = X.iloc[sp1:sp2,:],Y.iloc[sp1:sp2,:]\n",
        "  data['X_test'],data['Y_test'] = X.iloc[sp2:,:],Y.iloc[sp2:,:]\n",
        "  return data\n",
        "\n",
        "def show_metrics(y_pred,y_real):\n",
        "  res = pd.DataFrame(index=y_pred.columns,columns=['R2','MSE','MAPE'])\n",
        "  for i in y_pred.columns:\n",
        "    res.loc[i,'R2'] = r2_score(y_real[i],y_pred[i])\n",
        "    res.loc[i,'MSE'] = mean_squared_error(y_real[i],y_pred[i])\n",
        "    res.loc[i,'MAPE'] = mape(y_real[i],y_pred[i])\n",
        "  res.loc['AVG'] = res.mean(axis=0)\n",
        "  return res\n",
        "\n",
        "def init_weights(m):\n",
        "  if hasattr(m,'weight'):\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "  if hasattr(m,'bias'):\n",
        "    m.bias.data.fill_(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFNtBmqeWDSm"
      },
      "source": [
        "# Part1：預測塔頂塔底組成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AtQ4T0aWDSn"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EFZLabUWDSn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "a00c2554-5953-49d0-826a-766811b1706e"
      },
      "source": [
        "df = pd.read_excel(root+'/2.xlsx') #讀取excel檔\n",
        "df = df.drop(['Unnamed: 1', 'Unnamed: 2'], axis=1)\n",
        "df = df.drop(index=1)\n",
        "col_name = df.iloc[0,:]\n",
        "df.columns = col_name\n",
        "df = df.iloc[1:,:] \n",
        "df.index = df.iloc[:,0].values\n",
        "df = df.drop(df.columns[0],axis=1)\n",
        "print(df.shape)\n",
        "for i in df.columns:\n",
        "    df[i] = pd.to_numeric(df[i],errors='coerce')\n",
        "\n",
        "df['Condenser Duty'] = df['Condenser Duty'].apply(lambda x: x*-1)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1458, 18)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F.TEMP.MIXED</th>\n",
              "      <th>Feed Flow</th>\n",
              "      <th>F.FLOW.BENZENE</th>\n",
              "      <th>F.FLOW.TOLUENE</th>\n",
              "      <th>Total stage</th>\n",
              "      <th>Reflux ratio</th>\n",
              "      <th>D/F</th>\n",
              "      <th>Feed stage</th>\n",
              "      <th>Stage-2 Efficiencies</th>\n",
              "      <th>Stage-45 Efficiencies</th>\n",
              "      <th>Condenser Temperature</th>\n",
              "      <th>Condenser Duty</th>\n",
              "      <th>D stream BENZENE</th>\n",
              "      <th>D stream TOLUENE</th>\n",
              "      <th>Reboiler Temp</th>\n",
              "      <th>Reboiler Duty</th>\n",
              "      <th>W stream BENZENE</th>\n",
              "      <th>W stream TOLUENE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Case 1</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>40</td>\n",
              "      <td>60</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.961772</td>\n",
              "      <td>5712.749075</td>\n",
              "      <td>0.991645</td>\n",
              "      <td>0.008355</td>\n",
              "      <td>112.480976</td>\n",
              "      <td>5503.283448</td>\n",
              "      <td>0.146149</td>\n",
              "      <td>0.853851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 2</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.990896</td>\n",
              "      <td>5809.514269</td>\n",
              "      <td>0.989946</td>\n",
              "      <td>0.010054</td>\n",
              "      <td>106.774195</td>\n",
              "      <td>3042.561970</td>\n",
              "      <td>0.284634</td>\n",
              "      <td>0.715366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 3</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>14</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>83.029809</td>\n",
              "      <td>5906.674859</td>\n",
              "      <td>0.987682</td>\n",
              "      <td>0.012318</td>\n",
              "      <td>101.915000</td>\n",
              "      <td>593.089652</td>\n",
              "      <td>0.425427</td>\n",
              "      <td>0.574573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 4</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>40</td>\n",
              "      <td>60</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>19</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.845927</td>\n",
              "      <td>5708.665107</td>\n",
              "      <td>0.998416</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>112.594861</td>\n",
              "      <td>5500.205696</td>\n",
              "      <td>0.143621</td>\n",
              "      <td>0.856379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Case 5</th>\n",
              "      <td>103</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>46</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.33</td>\n",
              "      <td>19</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.7</td>\n",
              "      <td>82.851761</td>\n",
              "      <td>5804.515753</td>\n",
              "      <td>0.998074</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>106.894313</td>\n",
              "      <td>3038.549282</td>\n",
              "      <td>0.281451</td>\n",
              "      <td>0.718549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0       F.TEMP.MIXED  Feed Flow  ...  W stream BENZENE  W stream TOLUENE\n",
              "Case 1           103         50  ...          0.146149          0.853851\n",
              "Case 2           103         50  ...          0.284634          0.715366\n",
              "Case 3           103         50  ...          0.425427          0.574573\n",
              "Case 4           103         50  ...          0.143621          0.856379\n",
              "Case 5           103         50  ...          0.281451          0.718549\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvKtkQ773Vu3"
      },
      "source": [
        "class part(object):\n",
        "  def __init__(self,df,x_col,y_col,hidden_size=256,lr=0.01,max_epochs=500,robust_loss=False,log_interval=1):\n",
        "    \n",
        "    # config\n",
        "    self.log_interval = log_interval\n",
        "    self.robust_loss = robust_loss\n",
        "    self.x_col = x_col\n",
        "    self.y_col = y_col\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lr = lr\n",
        "    self.max_epochs = max_epochs\n",
        "    self.ss_x = MinMaxScaler().fit(df[x_col])\n",
        "    self.ss_y = MinMaxScaler().fit(df[y_col])\n",
        "    \n",
        "    # model\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(len(self.x_col),self.hidden_size),nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size,self.hidden_size),nn.ReLU(),\n",
        "        nn.Linear(self.hidden_size,len(self.y_col)),nn.Sigmoid(),\n",
        "                  ).apply(init_weights)\n",
        "    \n",
        "    # loss_function\n",
        "    if self.robust_loss == True:\n",
        "      adaptive = robust_loss_pytorch.adaptive.AdaptiveLossFunction(\n",
        "          num_dims = len(self.y_col),\n",
        "          float_dtype = np.float32,\n",
        "          device = 'cpu')\n",
        "      params = list(self.net.parameters())+list(adaptive.parameters())\n",
        "      self.loss_fn = lambda y_i,y:torch.mean(adaptive.lossfun((y_i - y)))\n",
        "    else:\n",
        "      params = list(self.net.parameters())\n",
        "      self.loss_fn = lambda y_i,y:torch.mean((y_i-y)**2)\n",
        "    \n",
        "    # optimizer\n",
        "    self.optimizer = torch.optim.Adam(params,lr=self.lr)\n",
        "    \n",
        "    # dataset\n",
        "    self.data = split_data(df,self.x_col,self.y_col)\n",
        "    \n",
        "    # data_iter\n",
        "    self.train_data = TensorDataset(\n",
        "        torch.FloatTensor(self.ss_x.transform(self.data['X_train'])),\n",
        "        torch.FloatTensor(self.ss_y.transform(self.data['Y_train'])),\n",
        "        )\n",
        "    self.train_iter = DataLoader(self.train_data,batch_size=64)\n",
        "    \n",
        "    self.vaild_data = TensorDataset(\n",
        "        torch.FloatTensor(self.ss_x.transform(self.data['X_vaild'])),\n",
        "        torch.FloatTensor(self.ss_y.transform(self.data['Y_vaild'])),\n",
        "        )\n",
        "    self.vaild_iter = DataLoader(self.vaild_data,batch_size=64)\n",
        "\n",
        "  def train_step(self):\n",
        "    self.net.train()\n",
        "    total_loss = 0\n",
        "    for t,(x,y) in enumerate(self.train_iter):\n",
        "      y_hat = self.net(x)\n",
        "      loss = self.loss_fn(y_hat,y)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      self.optimizer.zero_grad()\n",
        "      total_loss += loss.item()\n",
        "    return total_loss/t\n",
        "  \n",
        "  def valid_step(self):\n",
        "    self.net.eval()\n",
        "    total_loss = 0\n",
        "    for t,(x,y) in enumerate(self.vaild_iter):\n",
        "      y_hat = self.net(x)\n",
        "      loss = self.loss_fn(y_hat,y)\n",
        "      total_loss += loss.item()\n",
        "    return total_loss/t\n",
        "\n",
        "  \n",
        "  def train(self):\n",
        "    '''\n",
        "    train and eval model many epochs\n",
        "    return best model and plot train_history\n",
        "    '''   \n",
        "    history = {\n",
        "        'train_loss':[],\n",
        "        'valid_loss':[]\n",
        "        }\n",
        "    current_loss = np.inf\n",
        "    best_model = None\n",
        "    \n",
        "    for i in range(self.max_epochs):\n",
        "      history['train_loss'].append(self.train_step())\n",
        "      history['valid_loss'].append(self.valid_step())\n",
        "      \n",
        "      # pring info\n",
        "      if i%self.log_interval == 0:\n",
        "       print(\"epoch:{} train_loss:{:.4f} valid_loss:{:.4f}\".format(\n",
        "           i,\n",
        "           history['train_loss'][-1],\n",
        "           history['valid_loss'][-1]))\n",
        "      \n",
        "      # keep the best model\n",
        "      if history['valid_loss'][-1] <= current_loss:\n",
        "        best_model = deepcopy(self.net.eval())\n",
        "        current_loss = history['valid_loss'][-1]\n",
        "        print('save best model')\n",
        "    \n",
        "    # plot history and return best_model\n",
        "    self.net = deepcopy(best_model.eval())\n",
        "    plt.plot(history['train_loss'],label='train_loss')\n",
        "    plt.plot(history['valid_loss'],label='valid_loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return best_model\n",
        "\n",
        "  def test(self):\n",
        "    '''\n",
        "    show model metrics\n",
        "    '''\n",
        "    predict = self.get_predict(self.data['X_test'])\n",
        "    res = show_metrics(predict,self.data['Y_test'])\n",
        "    return res\n",
        "\n",
        "  def get_predict(self,x):\n",
        "    '''\n",
        "    input :pandas.DataFrame()\n",
        "    return :pandas.DataFrame()\n",
        "    '''\n",
        "    data_index = x.index\n",
        "    predict = self.net(torch.FloatTensor(self.ss_x.transform(x)))\n",
        "    predict = self.ss_y.inverse_transform(predict.detach().numpy())\n",
        "    predict = pd.DataFrame(predict,index=data_index,columns=self.y_col)\n",
        "    return predict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBMLJH3e8YNC"
      },
      "source": [
        "# PART1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c2A5AzvG9i-7",
        "outputId": "d163ce32-e477-4e9c-8e12-e98f748ce25c"
      },
      "source": [
        "part1 = part(df,df.columns[:10],df.columns[[12,13,16,17]])\n",
        "part1.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.0570 valid_loss:0.0223\n",
            "save best model\n",
            "epoch:1 train_loss:0.0111 valid_loss:0.0180\n",
            "save best model\n",
            "epoch:2 train_loss:0.0080 valid_loss:0.0065\n",
            "save best model\n",
            "epoch:3 train_loss:0.0046 valid_loss:0.0071\n",
            "epoch:4 train_loss:0.0049 valid_loss:0.0094\n",
            "epoch:5 train_loss:0.0059 valid_loss:0.0058\n",
            "save best model\n",
            "epoch:6 train_loss:0.0040 valid_loss:0.0045\n",
            "save best model\n",
            "epoch:7 train_loss:0.0041 valid_loss:0.0050\n",
            "epoch:8 train_loss:0.0039 valid_loss:0.0039\n",
            "save best model\n",
            "epoch:9 train_loss:0.0033 valid_loss:0.0039\n",
            "epoch:10 train_loss:0.0031 valid_loss:0.0037\n",
            "save best model\n",
            "epoch:11 train_loss:0.0030 valid_loss:0.0035\n",
            "save best model\n",
            "epoch:12 train_loss:0.0029 valid_loss:0.0034\n",
            "save best model\n",
            "epoch:13 train_loss:0.0028 valid_loss:0.0034\n",
            "save best model\n",
            "epoch:14 train_loss:0.0028 valid_loss:0.0034\n",
            "save best model\n",
            "epoch:15 train_loss:0.0028 valid_loss:0.0033\n",
            "save best model\n",
            "epoch:16 train_loss:0.0027 valid_loss:0.0034\n",
            "epoch:17 train_loss:0.0027 valid_loss:0.0034\n",
            "epoch:18 train_loss:0.0027 valid_loss:0.0034\n",
            "epoch:19 train_loss:0.0027 valid_loss:0.0030\n",
            "save best model\n",
            "epoch:20 train_loss:0.0023 valid_loss:0.0016\n",
            "save best model\n",
            "epoch:21 train_loss:0.0012 valid_loss:0.0014\n",
            "save best model\n",
            "epoch:22 train_loss:0.0007 valid_loss:0.0008\n",
            "save best model\n",
            "epoch:23 train_loss:0.0008 valid_loss:0.0009\n",
            "epoch:24 train_loss:0.0005 valid_loss:0.0008\n",
            "save best model\n",
            "epoch:25 train_loss:0.0003 valid_loss:0.0005\n",
            "save best model\n",
            "epoch:26 train_loss:0.0002 valid_loss:0.0003\n",
            "save best model\n",
            "epoch:27 train_loss:0.0002 valid_loss:0.0003\n",
            "save best model\n",
            "epoch:28 train_loss:0.0002 valid_loss:0.0003\n",
            "save best model\n",
            "epoch:29 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:30 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:31 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:32 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:33 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:34 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:35 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:36 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:37 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:38 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:39 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:40 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:41 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:42 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:43 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:44 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:45 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:46 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:47 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:48 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:49 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:50 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:51 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:52 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:53 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:54 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:55 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:56 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:57 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:58 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:59 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:60 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:61 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:62 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:63 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:64 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:65 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:66 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:67 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:68 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:69 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:70 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:71 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:72 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:73 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:74 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:75 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:76 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:77 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:78 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:79 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:80 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:81 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:82 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:83 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:84 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:85 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:86 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:87 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:88 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:89 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:90 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:91 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:92 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:93 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:94 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:95 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:96 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:97 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:98 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:99 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:100 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:101 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:102 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:103 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:104 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:105 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:106 train_loss:0.0000 valid_loss:0.0003\n",
            "epoch:107 train_loss:0.0001 valid_loss:0.0004\n",
            "epoch:108 train_loss:0.0002 valid_loss:0.0001\n",
            "epoch:109 train_loss:0.0001 valid_loss:0.0004\n",
            "epoch:110 train_loss:0.0012 valid_loss:0.0280\n",
            "epoch:111 train_loss:0.0366 valid_loss:0.0354\n",
            "epoch:112 train_loss:0.0084 valid_loss:0.0188\n",
            "epoch:113 train_loss:0.0027 valid_loss:0.0014\n",
            "epoch:114 train_loss:0.0009 valid_loss:0.0007\n",
            "epoch:115 train_loss:0.0005 valid_loss:0.0004\n",
            "epoch:116 train_loss:0.0003 valid_loss:0.0003\n",
            "epoch:117 train_loss:0.0002 valid_loss:0.0002\n",
            "epoch:118 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:119 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:120 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:121 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:122 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:123 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:124 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:125 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:126 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:127 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:128 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:129 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:130 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:131 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:132 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:133 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:134 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:135 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:136 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:137 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:138 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:139 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:140 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:141 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:142 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:143 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:144 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:145 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:146 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:147 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:148 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:149 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:150 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:151 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:152 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:153 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:154 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:155 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:156 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:157 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:158 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:159 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:160 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:161 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:162 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:163 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:164 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:165 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:166 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:167 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:168 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:169 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:170 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:171 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:172 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:173 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:174 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:175 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:176 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:177 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:178 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:179 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:180 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:181 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:182 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:183 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:184 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:185 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:186 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:187 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:188 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:189 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:190 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:191 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:192 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:193 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:194 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:195 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:196 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:197 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:198 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:199 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:200 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:201 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:202 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:203 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:204 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:205 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:206 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:207 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:208 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:209 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:210 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:211 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:212 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:213 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:214 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:215 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:216 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:217 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:218 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:219 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:220 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:221 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:222 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:223 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:224 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:225 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:226 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:227 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:228 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:229 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:230 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:231 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:232 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:233 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:234 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:235 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:236 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:237 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:238 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:239 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:240 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:241 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:242 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:243 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:244 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:245 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:246 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:247 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:248 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:249 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:250 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:251 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:252 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:253 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:254 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:255 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:256 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:257 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:258 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:259 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:260 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:261 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:262 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:263 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:264 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:265 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:266 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:267 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:268 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:269 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:270 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:271 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:272 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:273 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:274 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:275 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:276 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:277 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:278 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:279 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:280 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:281 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:282 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:283 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:284 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:285 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:286 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:287 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:288 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:289 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:290 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:291 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:292 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:293 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:294 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:295 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:296 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:297 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:298 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:299 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:300 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:301 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:302 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:303 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:304 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:305 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:306 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:307 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:308 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:309 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:310 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:311 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:312 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:313 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:314 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:315 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:316 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:317 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:318 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:319 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:320 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:321 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:322 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:323 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:324 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:325 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:326 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:327 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:328 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:329 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:330 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:331 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:332 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:333 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:334 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:335 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:336 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:337 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:338 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:339 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:340 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:341 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:342 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:343 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:344 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:345 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:346 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:347 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:348 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:349 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:350 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:351 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:352 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:353 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:354 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:355 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:356 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:357 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:358 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:359 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:360 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:361 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:362 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:363 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:364 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:365 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:366 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:367 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:368 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:369 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:370 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:371 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:372 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:373 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:374 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:375 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:376 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:377 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:378 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:379 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:380 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:381 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:382 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:383 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:384 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:385 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:386 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:387 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:388 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:389 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:390 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:391 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:392 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:393 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:394 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:395 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:396 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:397 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:398 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:399 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:400 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:401 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:402 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:403 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:404 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:405 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:406 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:407 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:408 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:409 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:410 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:411 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:412 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:413 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:414 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:415 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:416 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:417 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:418 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:419 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:420 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:421 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:422 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:423 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:424 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:425 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:426 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:427 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:428 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:429 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:430 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:431 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:432 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:433 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:434 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:435 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:436 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:437 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:438 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:439 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:440 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:441 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:442 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:443 train_loss:0.0001 valid_loss:0.0000\n",
            "epoch:444 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:445 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:446 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:447 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:448 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:449 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:450 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:451 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:452 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:453 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:454 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:455 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:456 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:457 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:458 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:459 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:460 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:461 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:462 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:463 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:464 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:465 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:466 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:467 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:468 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:469 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:470 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:471 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:472 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:473 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:474 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:475 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:476 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:477 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:478 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:479 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:480 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:481 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:482 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:483 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:484 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:485 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:486 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:487 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:488 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:489 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:490 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:491 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:492 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:493 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:494 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:495 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:496 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:497 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:498 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:499 train_loss:0.0000 valid_loss:0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=4, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "4ud5NnbW-pOM",
        "outputId": "88d37356-b19c-4fb2-9df9-8547f5e4880e"
      },
      "source": [
        "res = part1.test()\n",
        "res"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D stream BENZENE</th>\n",
              "      <td>0.999946</td>\n",
              "      <td>2.97125e-07</td>\n",
              "      <td>0.039486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D stream TOLUENE</th>\n",
              "      <td>0.999944</td>\n",
              "      <td>3.07414e-07</td>\n",
              "      <td>89.6697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W stream BENZENE</th>\n",
              "      <td>0.999986</td>\n",
              "      <td>3.19484e-07</td>\n",
              "      <td>9731.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>W stream TOLUENE</th>\n",
              "      <td>0.999987</td>\n",
              "      <td>3.07255e-07</td>\n",
              "      <td>0.0520538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999966</td>\n",
              "      <td>3.0782e-07</td>\n",
              "      <td>2455.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        R2          MSE       MAPE\n",
              "0                                                 \n",
              "D stream BENZENE  0.999946  2.97125e-07   0.039486\n",
              "D stream TOLUENE  0.999944  3.07414e-07    89.6697\n",
              "W stream BENZENE  0.999986  3.19484e-07    9731.85\n",
              "W stream TOLUENE  0.999987  3.07255e-07  0.0520538\n",
              "AVG               0.999966   3.0782e-07     2455.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aadwibjClcc"
      },
      "source": [
        "# PART2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "udm6e1rUC4LO",
        "outputId": "ffb53585-c683-4db0-9aaa-08e588ec5e61"
      },
      "source": [
        "part2 = part(df,df.columns[:10],df.columns[[11,15]])\n",
        "part2.train()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.0279 valid_loss:0.0115\n",
            "save best model\n",
            "epoch:1 train_loss:0.0045 valid_loss:0.0042\n",
            "save best model\n",
            "epoch:2 train_loss:0.0017 valid_loss:0.0013\n",
            "save best model\n",
            "epoch:3 train_loss:0.0008 valid_loss:0.0008\n",
            "save best model\n",
            "epoch:4 train_loss:0.0004 valid_loss:0.0006\n",
            "save best model\n",
            "epoch:5 train_loss:0.0003 valid_loss:0.0005\n",
            "save best model\n",
            "epoch:6 train_loss:0.0002 valid_loss:0.0004\n",
            "save best model\n",
            "epoch:7 train_loss:0.0002 valid_loss:0.0003\n",
            "save best model\n",
            "epoch:8 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:9 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:10 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:11 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:12 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:13 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:14 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:15 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:16 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:17 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:18 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:19 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:20 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:21 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:22 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:23 train_loss:0.0002 valid_loss:0.0004\n",
            "epoch:24 train_loss:0.0002 valid_loss:0.0005\n",
            "epoch:25 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:26 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:27 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:28 train_loss:0.0003 valid_loss:0.0003\n",
            "epoch:29 train_loss:0.0003 valid_loss:0.0007\n",
            "epoch:30 train_loss:0.0002 valid_loss:0.0004\n",
            "epoch:31 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:32 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:33 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:34 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:35 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:36 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:37 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:38 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:39 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:40 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:41 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:42 train_loss:0.0000 valid_loss:0.0003\n",
            "epoch:43 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:44 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:45 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:46 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:47 train_loss:0.0001 valid_loss:0.0008\n",
            "epoch:48 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:49 train_loss:0.0002 valid_loss:0.0001\n",
            "epoch:50 train_loss:0.0001 valid_loss:0.0007\n",
            "epoch:51 train_loss:0.0002 valid_loss:0.0006\n",
            "epoch:52 train_loss:0.0002 valid_loss:0.0010\n",
            "epoch:53 train_loss:0.0004 valid_loss:0.0015\n",
            "epoch:54 train_loss:0.0007 valid_loss:0.0006\n",
            "epoch:55 train_loss:0.0007 valid_loss:0.0010\n",
            "epoch:56 train_loss:0.0005 valid_loss:0.0005\n",
            "epoch:57 train_loss:0.0002 valid_loss:0.0001\n",
            "epoch:58 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:59 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:60 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:61 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:62 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:63 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:64 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:65 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:66 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:67 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:68 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:69 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:70 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:71 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:72 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:73 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:74 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:75 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:76 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:77 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:78 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:79 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:80 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:81 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:82 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:83 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:84 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:85 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:86 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:87 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:88 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:89 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:90 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:91 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:92 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:93 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:94 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:95 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:96 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:97 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:98 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:99 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:100 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:101 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:102 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:103 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:104 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:105 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:106 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:107 train_loss:0.0002 valid_loss:0.0007\n",
            "epoch:108 train_loss:0.0003 valid_loss:0.0013\n",
            "epoch:109 train_loss:0.0005 valid_loss:0.0010\n",
            "epoch:110 train_loss:0.0006 valid_loss:0.0007\n",
            "epoch:111 train_loss:0.0005 valid_loss:0.0007\n",
            "epoch:112 train_loss:0.0002 valid_loss:0.0003\n",
            "epoch:113 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:114 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:115 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:116 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:117 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:118 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:119 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:120 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:121 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:122 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:123 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:124 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:125 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:126 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:127 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:128 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:129 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:130 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:131 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:132 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:133 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:134 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:135 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:136 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:137 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:138 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:139 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:140 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:141 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:142 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:143 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:144 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:145 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:146 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:147 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:148 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:149 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:150 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:151 train_loss:0.0002 valid_loss:0.0002\n",
            "epoch:152 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:153 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:154 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:155 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:156 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:157 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:158 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:159 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:160 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:161 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:162 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:163 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:164 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:165 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:166 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:167 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:168 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:169 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:170 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:171 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:172 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:173 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:174 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:175 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:176 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:177 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:178 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:179 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:180 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:181 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:182 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:183 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:184 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:185 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:186 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:187 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:188 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:189 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:190 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:191 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:192 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:193 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:194 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:195 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:196 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:197 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:198 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:199 train_loss:0.0001 valid_loss:0.0000\n",
            "epoch:200 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:201 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:202 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:203 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:204 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:205 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:206 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:207 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:208 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:209 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:210 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:211 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:212 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:213 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:214 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:215 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:216 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:217 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:218 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:219 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:220 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:221 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:222 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:223 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:224 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:225 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:226 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:227 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:228 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:229 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:230 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:231 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:232 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:233 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:234 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:235 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:236 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:237 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:238 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:239 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:240 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:241 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:242 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:243 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:244 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:245 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:246 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:247 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:248 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:249 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:250 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:251 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:252 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:253 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:254 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:255 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:256 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:257 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:258 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:259 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:260 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:261 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:262 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:263 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:264 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:265 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:266 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:267 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:268 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:269 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:270 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:271 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:272 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:273 train_loss:0.0001 valid_loss:0.0004\n",
            "epoch:274 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:275 train_loss:0.0002 valid_loss:0.0002\n",
            "epoch:276 train_loss:0.0002 valid_loss:0.0001\n",
            "epoch:277 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:278 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:279 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:280 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:281 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:282 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:283 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:284 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:285 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:286 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:287 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:288 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:289 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:290 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:291 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:292 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:293 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:294 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:295 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:296 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:297 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:298 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:299 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:300 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:301 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:302 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:303 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:304 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:305 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:306 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:307 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:308 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:309 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:310 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:311 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:312 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:313 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:314 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:315 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:316 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:317 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:318 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:319 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:320 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:321 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:322 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:323 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:324 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:325 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:326 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:327 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:328 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:329 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:330 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:331 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:332 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:333 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:334 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:335 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:336 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:337 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:338 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:339 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:340 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:341 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:342 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:343 train_loss:0.0001 valid_loss:0.0004\n",
            "epoch:344 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:345 train_loss:0.0002 valid_loss:0.0003\n",
            "epoch:346 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:347 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:348 train_loss:0.0001 valid_loss:0.0000\n",
            "epoch:349 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:350 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:351 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:352 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:353 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:354 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:355 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:356 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:357 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:358 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:359 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:360 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:361 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:362 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:363 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:364 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:365 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:366 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:367 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:368 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:369 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:370 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:371 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:372 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:373 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:374 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:375 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:376 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:377 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:378 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:379 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:380 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:381 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:382 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:383 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:384 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:385 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:386 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:387 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:388 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:389 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:390 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:391 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:392 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:393 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:394 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:395 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:396 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:397 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:398 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:399 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:400 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:401 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:402 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:403 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:404 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:405 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:406 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:407 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:408 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:409 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:410 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:411 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:412 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:413 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:414 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:415 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:416 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:417 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:418 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:419 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:420 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:421 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:422 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:423 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:424 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:425 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:426 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:427 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:428 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:429 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:430 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:431 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:432 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:433 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:434 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:435 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:436 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:437 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:438 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:439 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:440 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:441 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:442 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:443 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:444 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:445 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:446 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:447 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:448 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:449 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:450 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:451 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:452 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:453 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:454 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:455 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:456 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:457 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:458 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:459 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:460 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:461 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:462 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:463 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:464 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:465 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:466 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:467 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:468 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:469 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:470 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:471 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:472 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:473 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:474 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:475 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:476 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:477 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:478 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:479 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:480 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:481 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:482 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:483 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:484 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:485 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:486 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:487 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:488 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:489 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:490 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:491 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:492 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:493 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:494 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:495 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:496 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:497 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:498 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:499 train_loss:0.0000 valid_loss:0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "hI_LVnSuDV9Q",
        "outputId": "01538732-c027-4dd1-9f13-37359a6e7627"
      },
      "source": [
        "part2.test()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Condenser Duty</th>\n",
              "      <td>0.999968</td>\n",
              "      <td>7224.8</td>\n",
              "      <td>0.363492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reboiler Duty</th>\n",
              "      <td>0.99992</td>\n",
              "      <td>9126.36</td>\n",
              "      <td>1.43084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999944</td>\n",
              "      <td>8175.58</td>\n",
              "      <td>0.897163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      R2      MSE      MAPE\n",
              "0                                          \n",
              "Condenser Duty  0.999968   7224.8  0.363492\n",
              "Reboiler Duty    0.99992  9126.36   1.43084\n",
              "AVG             0.999944  8175.58  0.897163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4lmrQEKWDUw"
      },
      "source": [
        "# Part 3：預測操作條件(temp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yhGTtrR7TfML",
        "outputId": "50d69e43-bc3f-4e62-fd68-e0cef5b6d29c"
      },
      "source": [
        "part3 = part(df,df.columns[:10],df.columns[[10,14]])\n",
        "part3.train()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0 train_loss:0.0544 valid_loss:0.0269\n",
            "save best model\n",
            "epoch:1 train_loss:0.0102 valid_loss:0.0080\n",
            "save best model\n",
            "epoch:2 train_loss:0.0051 valid_loss:0.0070\n",
            "save best model\n",
            "epoch:3 train_loss:0.0046 valid_loss:0.0082\n",
            "epoch:4 train_loss:0.0043 valid_loss:0.0062\n",
            "save best model\n",
            "epoch:5 train_loss:0.0041 valid_loss:0.0089\n",
            "epoch:6 train_loss:0.0046 valid_loss:0.0086\n",
            "epoch:7 train_loss:0.0055 valid_loss:0.0108\n",
            "epoch:8 train_loss:0.0055 valid_loss:0.0085\n",
            "epoch:9 train_loss:0.0068 valid_loss:0.0077\n",
            "epoch:10 train_loss:0.0054 valid_loss:0.0074\n",
            "epoch:11 train_loss:0.0050 valid_loss:0.0072\n",
            "epoch:12 train_loss:0.0041 valid_loss:0.0079\n",
            "epoch:13 train_loss:0.0044 valid_loss:0.0141\n",
            "epoch:14 train_loss:0.0108 valid_loss:0.0328\n",
            "epoch:15 train_loss:0.0135 valid_loss:0.0079\n",
            "epoch:16 train_loss:0.0058 valid_loss:0.0072\n",
            "epoch:17 train_loss:0.0061 valid_loss:0.0074\n",
            "epoch:18 train_loss:0.0044 valid_loss:0.0059\n",
            "save best model\n",
            "epoch:19 train_loss:0.0035 valid_loss:0.0062\n",
            "epoch:20 train_loss:0.0033 valid_loss:0.0058\n",
            "save best model\n",
            "epoch:21 train_loss:0.0033 valid_loss:0.0060\n",
            "epoch:22 train_loss:0.0036 valid_loss:0.0076\n",
            "epoch:23 train_loss:0.0047 valid_loss:0.0086\n",
            "epoch:24 train_loss:0.0045 valid_loss:0.0073\n",
            "epoch:25 train_loss:0.0038 valid_loss:0.0056\n",
            "save best model\n",
            "epoch:26 train_loss:0.0032 valid_loss:0.0055\n",
            "save best model\n",
            "epoch:27 train_loss:0.0029 valid_loss:0.0054\n",
            "save best model\n",
            "epoch:28 train_loss:0.0028 valid_loss:0.0053\n",
            "save best model\n",
            "epoch:29 train_loss:0.0027 valid_loss:0.0052\n",
            "save best model\n",
            "epoch:30 train_loss:0.0026 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:31 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:32 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:33 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:34 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:35 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:36 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:37 train_loss:0.0025 valid_loss:0.0051\n",
            "save best model\n",
            "epoch:38 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:39 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:40 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:41 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:42 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:43 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:44 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:45 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:46 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:47 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:48 train_loss:0.0025 valid_loss:0.0050\n",
            "save best model\n",
            "epoch:49 train_loss:0.0024 valid_loss:0.0046\n",
            "save best model\n",
            "epoch:50 train_loss:0.0018 valid_loss:0.0014\n",
            "save best model\n",
            "epoch:51 train_loss:0.0007 valid_loss:0.0007\n",
            "save best model\n",
            "epoch:52 train_loss:0.0004 valid_loss:0.0004\n",
            "save best model\n",
            "epoch:53 train_loss:0.0002 valid_loss:0.0003\n",
            "save best model\n",
            "epoch:54 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:55 train_loss:0.0002 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:56 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:57 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:58 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:59 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:60 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:61 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:62 train_loss:0.0001 valid_loss:0.0002\n",
            "save best model\n",
            "epoch:63 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:64 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:65 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:66 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:67 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:68 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:69 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:70 train_loss:0.0001 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:71 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:72 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:73 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:74 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:75 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:76 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:77 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:78 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:79 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:80 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:81 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:82 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:83 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:84 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:85 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:86 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:87 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:88 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:89 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:90 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:91 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:92 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:93 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:94 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:95 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:96 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:97 train_loss:0.0000 valid_loss:0.0001\n",
            "save best model\n",
            "epoch:98 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:99 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:100 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:101 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:102 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:103 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:104 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:105 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:106 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:107 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:108 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:109 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:110 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:111 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:112 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:113 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:114 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:115 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:116 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:117 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:118 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:119 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:120 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:121 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:122 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:123 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:124 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:125 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:126 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:127 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:128 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:129 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:130 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:131 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:132 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:133 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:134 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:135 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:136 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:137 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:138 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:139 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:140 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:141 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:142 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:143 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:144 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:145 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:146 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:147 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:148 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:149 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:150 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:151 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:152 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:153 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:154 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:155 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:156 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:157 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:158 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:159 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:160 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:161 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:162 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:163 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:164 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:165 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:166 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:167 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:168 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:169 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:170 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:171 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:172 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:173 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:174 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:175 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:176 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:177 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:178 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:179 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:180 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:181 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:182 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:183 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:184 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:185 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:186 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:187 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:188 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:189 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:190 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:191 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:192 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:193 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:194 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:195 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:196 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:197 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:198 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:199 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:200 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:201 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:202 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:203 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:204 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:205 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:206 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:207 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:208 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:209 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:210 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:211 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:212 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:213 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:214 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:215 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:216 train_loss:0.0001 valid_loss:0.0005\n",
            "epoch:217 train_loss:0.0001 valid_loss:0.0002\n",
            "epoch:218 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:219 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:220 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:221 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:222 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:223 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:224 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:225 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:226 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:227 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:228 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:229 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:230 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:231 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:232 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:233 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:234 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:235 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:236 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:237 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:238 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:239 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:240 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:241 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:242 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:243 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:244 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:245 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:246 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:247 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:248 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:249 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:250 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:251 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:252 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:253 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:254 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:255 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:256 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:257 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:258 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:259 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:260 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:261 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:262 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:263 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:264 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:265 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:266 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:267 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:268 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:269 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:270 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:271 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:272 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:273 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:274 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:275 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:276 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:277 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:278 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:279 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:280 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:281 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:282 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:283 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:284 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:285 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:286 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:287 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:288 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:289 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:290 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:291 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:292 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:293 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:294 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:295 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:296 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:297 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:298 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:299 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:300 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:301 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:302 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:303 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:304 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:305 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:306 train_loss:0.0000 valid_loss:0.0000\n",
            "save best model\n",
            "epoch:307 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:308 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:309 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:310 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:311 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:312 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:313 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:314 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:315 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:316 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:317 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:318 train_loss:0.0001 valid_loss:0.0003\n",
            "epoch:319 train_loss:0.0002 valid_loss:0.0009\n",
            "epoch:320 train_loss:0.0062 valid_loss:0.0319\n",
            "epoch:321 train_loss:0.0056 valid_loss:0.0028\n",
            "epoch:322 train_loss:0.0011 valid_loss:0.0009\n",
            "epoch:323 train_loss:0.0004 valid_loss:0.0003\n",
            "epoch:324 train_loss:0.0002 valid_loss:0.0003\n",
            "epoch:325 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:326 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:327 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:328 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:329 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:330 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:331 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:332 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:333 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:334 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:335 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:336 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:337 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:338 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:339 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:340 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:341 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:342 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:343 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:344 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:345 train_loss:0.0001 valid_loss:0.0001\n",
            "epoch:346 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:347 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:348 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:349 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:350 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:351 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:352 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:353 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:354 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:355 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:356 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:357 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:358 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:359 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:360 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:361 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:362 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:363 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:364 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:365 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:366 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:367 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:368 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:369 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:370 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:371 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:372 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:373 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:374 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:375 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:376 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:377 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:378 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:379 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:380 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:381 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:382 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:383 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:384 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:385 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:386 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:387 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:388 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:389 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:390 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:391 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:392 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:393 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:394 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:395 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:396 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:397 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:398 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:399 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:400 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:401 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:402 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:403 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:404 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:405 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:406 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:407 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:408 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:409 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:410 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:411 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:412 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:413 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:414 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:415 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:416 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:417 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:418 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:419 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:420 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:421 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:422 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:423 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:424 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:425 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:426 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:427 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:428 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:429 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:430 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:431 train_loss:0.0000 valid_loss:0.0002\n",
            "epoch:432 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:433 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:434 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:435 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:436 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:437 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:438 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:439 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:440 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:441 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:442 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:443 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:444 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:445 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:446 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:447 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:448 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:449 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:450 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:451 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:452 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:453 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:454 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:455 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:456 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:457 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:458 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:459 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:460 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:461 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:462 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:463 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:464 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:465 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:466 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:467 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:468 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:469 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:470 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:471 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:472 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:473 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:474 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:475 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:476 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:477 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:478 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:479 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:480 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:481 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:482 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:483 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:484 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:485 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:486 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:487 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:488 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:489 train_loss:0.0000 valid_loss:0.0001\n",
            "epoch:490 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:491 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:492 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:493 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:494 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:495 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:496 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:497 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:498 train_loss:0.0000 valid_loss:0.0000\n",
            "epoch:499 train_loss:0.0000 valid_loss:0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=256, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "eIlqZ-vJTr4D",
        "outputId": "55e3e839-5f92-4cc7-b498-8f48a83045f6"
      },
      "source": [
        "part3.test()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>MSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Condenser Temperature</th>\n",
              "      <td>0.999945</td>\n",
              "      <td>0.000108861</td>\n",
              "      <td>0.00854232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reboiler Temp</th>\n",
              "      <td>0.999923</td>\n",
              "      <td>0.00269463</td>\n",
              "      <td>0.0234649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVG</th>\n",
              "      <td>0.999934</td>\n",
              "      <td>0.00140175</td>\n",
              "      <td>0.0160036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             R2          MSE        MAPE\n",
              "0                                                       \n",
              "Condenser Temperature  0.999945  0.000108861  0.00854232\n",
              "Reboiler Temp          0.999923   0.00269463   0.0234649\n",
              "AVG                    0.999934   0.00140175   0.0160036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0KrxJx4MjpL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}